[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Regen_Notes",
    "section": "",
    "text": "git add .\ngit commit -m “comment”\ngit push origin main\nquarto publish gh-pages\ngit remote set-url origin https://github.com/KingBlkMouth/Regen.git\ngit remote -v"
  },
  {
    "objectID": "index.html#these-are-git-commands-that-i-need",
    "href": "index.html#these-are-git-commands-that-i-need",
    "title": "Regen_Notes",
    "section": "",
    "text": "git add .\ngit commit -m “comment”\ngit push origin main\nquarto publish gh-pages\ngit remote set-url origin https://github.com/KingBlkMouth/Regen.git\ngit remote -v"
  },
  {
    "objectID": "index.html#contents",
    "href": "index.html#contents",
    "title": "Regen_Notes",
    "section": "Contents",
    "text": "Contents\nThere are many absolute paths in plot selection.\n\nPlot Selection\n\nPlot selection\n\nSelect eco-regions and associated plots\n\nCh 4\n\nRemove artificial, unsampled, non-forest, and periodic plots\n\nCh 5\n\nSelect subplots from plots,\nControl for equal conditions.\nClean FPAGs.\nSelect FVS ready data from subplot list\nWrite an input FVS database and standlist.\n\nCh 6\n\nSet: run name, input database, & standlist\nRun plots in FVS to get canopy cover.\n\nImputation Prep\n\nOrganizing the data like yaImpute did in the St.Joe example.\nSaving the clean data.\n\n\nImputation\n\nRepeat of first set of imputations done on expanded set of plots\n\n3 vs 6 variables\nfull set vs set w/o seedlings\nPretty much the same results.\n\nRandom Forest on fpa, where fpa is CDS.\n\nThis isn’t much different than before, almost the same number of plots.\n\nRandom Forest on plots w/ seedlings only. No empty plots.\nTest Imp on full set\n\nRF on full set not fpas.\n\nStoch dist\n\nLooking at how to get the full set of CNs to pull a plot at random\n\nRF w/ Categoricals.\n\nAdding FPAG as a predictor.\nThis was the best plot so far. The imputed vs observed came off the axis.\n\n\nImputation 2\n\nExploring different categorical predictors.\n\nVisualization\n\nFor now this is just where I am keeping a to-do list."
  },
  {
    "objectID": "index.html#plot-selection",
    "href": "index.html#plot-selection",
    "title": "Regen_Notes",
    "section": "Plot Selection",
    "text": "Plot Selection\nPlot Selection, Starting from a set of stands clipped from the study area in Arc Pro, Pull all of the ecoregions in the study area, then pull all stands with those ecoregions from the WA fia database.\nCh4, Pull the plot and condition tables from FIA. Control for artificial regen, unsampled CNs, non-forest conditions, and periodic plot designs. Check the ecoregion codes for mistakes and unwanted codes. Remove the condition CNs that are there only to indicate a site condition.\nCh5, Pull in the subplot’s plot and condition tables. Select only those subplots that have the same conditions on the microplot and subplot. Join the sub conditions table to with those plots that have the same conditions. Select those subplots that are at least 97.5% covered by the same conditions. Remove and habitat types that are coded as admin, non-veg, or water. Manually correct any mislabeled habitat types.\nFVS Prep, Pull in the FVS_Ready tables. Create a column for FPAG. Compare some stats with Kralicek. Write the FVS_Ready and FPAG tables to a .db. Write a standlist for FVS.\nCh6, Run the standlist and the new database in FVS to get Canopy Cover."
  },
  {
    "objectID": "index.html#imputation",
    "href": "index.html#imputation",
    "title": "Regen_Notes",
    "section": "Imputation",
    "text": "Imputation"
  },
  {
    "objectID": "7_FVS.html#notes",
    "href": "7_FVS.html#notes",
    "title": "FVS",
    "section": "Notes",
    "text": "Notes"
  },
  {
    "objectID": "7_FVS.html#fvs",
    "href": "7_FVS.html#fvs",
    "title": "FVS",
    "section": "FVS",
    "text": "FVS"
  },
  {
    "objectID": "5_Model_Eval.html#notes",
    "href": "5_Model_Eval.html#notes",
    "title": "Model Eval",
    "section": "Notes",
    "text": "Notes\nyaImpute Paper\nyaImpute package info\nBreiman L (2001). “Random Forests.” Machine Learning, Breiman L 2001\nClassification and Regression by randomForest Liam & Wiener, p.18\n\nThoughts\nObviously, we want to reduce rmsd. However, rmsd alone tells me nothing. I think the difference is the y values of the nearest neighbor to each reference plot minus the y values of that plot. RMSD is then the sum of squared differences divided by n.  So for total_TD, rmsd is average difference in the number of total trees. When I ran the errorStats in impuation 2, msn.rmsd for PSME without zeroes was 261, with zeroes it was 265. When I ran the imputation, it was on the full set of data without subsetting a reference set. So, the difference is between all plots and the nearest 10 plots. I am pretty sure setting k to 10 makes it average each y variable.\nOn average, there were 4 more or less PSME in the targets vs references when comparing imputations with and without zeroes. However, both sets were on average different by about 263 trees. There is more variation between plots than there is between imputations.\nFor the same two sets of imputations, total_TD was 757 & 803. On average, the imputations were different by 46, but the plots were different by 775. That is a lot of trees, too many in my opinion. I don’t know enough about forestry to really say, but reasonable TPAs for non-seedlings is between 300 and 900. Having a difference in seedlings that high may be normal, but I can’t say and it doesn’t seem normal.\nI could try and figure out an appropriate metric based off the mean and sd. In the set imp_zx, there are on average about 64 PSME seedlings on plots that have an over story. Standard deviation is about 225. These data are almost distributed exponentially. A log transformation doesn’t make it normal. I cannot figure out how to deal with the distribution. So, I am going to treat it as if it were. I could try and bootstrap the mean and sd. That would at least smooth out the oddballs.\nBootstrapping it may have been a waste of time. For the full dataset, On average total_TD is 364 trees per acre plus or minus 64. 95% confidence interval is between 300 and 428 TPA. SD 95% is between 300 and 1194. So, we will get negative numbers often. For the subset without numbers over 10k and w/o zeroes, Without the outliers and zeroes, mean trees are 652 trees plus or minus 31. The true sd is 975 plus or minus 73.\nSo, there is too much variation in the whole set for anything to really make sense. I do not know how to model a log-normal distribution problem. I do not want zero in the confidence intervals. I can’t find anything straightforward about modeling this problem. It isn’t really an exponential distribution. The log transformations aren’t perfect.\nAll that being said, I think it is time that I got a little bit more info about RF. The variability issue could be fixed within RF. I would like to subset the data an dlook at variability within fpags, but I think RF will do well enough. I can go back and check a sampling of them, if I want to.\n\n\nyaImpute\nPaper I’ve spent so much time trying to understand the stage and Crookston error stats paper. That time wasn’t a waste, but it isn’t how error works for random forests. In random forests, observation s are condsidered similar if they tend to end up in the same terminal node (in a suitably constructed collection of classification and regression trees.) Liam & Wiener, p.18\nIn RF, distance is based on a proximity matrix. There is a col and row for every observation. Inside the matrix is the number the proportion of trees where “plots” are in the same terminal node.\nThat matrix is too big though so the package uses an n by n_tree matrix. There are two, one for the references and one for the targets. For multivariate Ys, there is a separate forest for each Y. The node matrices for wach Y are joined at the end.\nrmsd can never be zero. Notably distant finds references that aren’t as close as others. They are outside the range of variation of the references or they fall in large gaps. Specify a threshold distance by visualizing the frequency distribution. Hold the treshold constant when adding new data to fill the gaps.\n\nyaiVatImp is for variable importance.\nrfSUmmary builds summary data."
  },
  {
    "objectID": "5_Model_Eval.html#setup",
    "href": "5_Model_Eval.html#setup",
    "title": "Model Eval",
    "section": "Setup",
    "text": "Setup\n\n\nCode\n# Data tidying and access\nlibrary(tidyverse, quietly = T)\nlibrary(RSQLite)\n# library(readxl)\n# library(writexl)\n\n# yaImpute and related \nlibrary(yaImpute)\nlibrary(vegan)\nlibrary(randomForest)\n\n# plots and tables\nlibrary(esquisse)\nlibrary(knitr)\n\n# No sci-notation. \noptions(scipen = 999)\n\n\nSetup yai\n\n\nCode\nKEEP &lt;- c(\"KEEP\")\nrm(list = ls()[!ls() %in% KEEP])\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n# sp_prev was saved from imutation 1\nload(\"sp_prevalence.Rdata\")\n\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nimp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n  common = rowSums(imp_data_FPA[,sp_prevalence$common]),\n  uncommon = rowSums(imp_data_FPA[,sp_prevalence$uncommon]),\n  rare = rowSums(imp_data_FPA[,sp_prevalence$rare]),\n  total_TD = rowSums(imp_data_FPA[grep(\"_TD\", names(imp_data_FPA))])\n) |&gt;\n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common)\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; \n  relocate(fpa, .after = FPAG)\n\n# I am removing the extra rows to speed up the imputation test. \nfpas &lt;- imp_data_FPA |&gt; \n  filter(\n    total_TD &gt; 0\n  )\n\n# refs &lt;- rownames(fpas[1:(3*nrow(fpas)/4),])\n# \n# x &lt;- fpas |&gt; select(1:5)\n# x &lt;- remove_rownames(x)\n# x &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n# \n# yfull &lt;- fpas |&gt; select(1, 7:ncol(fpas))\n# y &lt;- yfull[refs,]\n# y &lt;- remove_rownames(y)\n# y &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\n# yfull &lt;- remove_rownames(yfull)\n# yfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n# \n# k = 10\n# \n# yrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n# \n# names(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\n# Removing the fpas with less than 120 plots. \nt &lt;- fpas |&gt; group_by(FPAG) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n)) |&gt; \n  filter(n &gt; 120)\n\nkeep &lt;- t$FPAG\n\nt2 &lt;- fpas |&gt; \n  filter(FPAG %in% keep)\n\nt2$FPAG &lt;- as.factor(t2$FPAG)\n\n\nRun yai\nI am tires right now, but this section looks weird Double check the imputation I have been doing for trf and check the above code.\n\n\nCode\nrefs &lt;- rownames(t2[1:(3*nrow(t2)/4),])\n\nx &lt;- t2 |&gt; select(1:5)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- t2 |&gt; select(1, 7:ncol(t2))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n# trf &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n\n# save(trf, file = \"trf.Rdata\")\nload(\"trf.Rdata\")\n\ntrf_i &lt;- impute(trf, ancillaryData = y)"
  },
  {
    "objectID": "5_Model_Eval.html#warning-threshold-zero-distances",
    "href": "5_Model_Eval.html#warning-threshold-zero-distances",
    "title": "Model Eval",
    "section": "Warning threshold zero distances",
    "text": "Warning threshold zero distances\nI noticed at levels argument to msn in the yaImpute webstie, There may still be away to get that to work. It’s not really important right now because we have mostly decided to go with random forests.\nThe warning about zero distances is in reference to plots that have the same predictors. For example, if two or more plots share cc = 1, ba = 2, sdi = 10, they are separated by zero distance. Given the way this data was made, I am surprised that there aren’t more sets with the same predictors.\n\n# summary(imp_data[, 2:4])\nkable(summary(imp_data[, 2:4]))\n\n\n\n\n\nCC\nBA\nSDI\n\n\n\n\n\nMin. : 0.00\nMin. : 0.00\nMin. : 0.00\n\n\n\n1st Qu.: 9.00\n1st Qu.: 15.36\n1st Qu.: 35.00\n\n\n\nMedian :18.00\nMedian : 33.84\nMedian : 75.00\n\n\n\nMean :20.28\nMean : 40.11\nMean : 86.91\n\n\n\n3rd Qu.:29.00\n3rd Qu.: 58.47\n3rd Qu.:126.00\n\n\n\nMax. :97.00\nMax. :226.84\nMax. :497.00\n\n\n\n\n\nCanopy cover is an integer from 0:100, SDI is an int from 0 to 500 (in this set). Just them being integers makes them more likely to overlap.\n\nhist(imp_data$CC, breaks = 100)\nhist(imp_data$BA, breaks = 100)\nhist(imp_data$SDI, breaks = 100)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll of them skew right and have lots of zeroes.\n\nTest removing zero distances.\nHere, I was trying to figure out some code to pull the sets of data with zero distance between predictors out of the data. The correct answer was to use unique on the set of predictors after setting standplot_cn to rownames.\n\n\nCode\n# 527 zero distances of 1884\nimp_zx &lt;- imp_data_FPA |&gt; \n  filter(CC != 0 & BA != 0 & SDI &gt; 1)\n# 40 zero distances. It isn't in the ancillary data, but that did help.\nimp_zx &lt;- imp_zx |&gt; \n  filter(total_TD &gt; 0)\n#  15\nimp_zx &lt;- imp_zx |&gt; \n  filter(CC &gt; 1 & BA &gt; 1 & SDI &gt; 1)\n\nimp_zx &lt;- imp_data_FPA |&gt; \n  filter(CC != BA & CC != SDI & BA != SDI)\n\nimp_zx &lt;- imp_data_FPA |&gt; \n  filter(!near(CC, BA, tol = .01) & !near(CC, SDI, tol = .01))\n\n\nOf the 1884 zero distances:\n\nAll but 15, of the zero distances are where CC, BA, and SDI are all less than one.\nAll but 40 are accounted for in the set where total tree density is zero.\n\nThis is the code to run the imputation as usual, with all the data.\nIt gives the errors, 1884 zero distances of 24621 references were set to 0.0…\n\nimp_ztest &lt;- imp_data_FPA\n\n\nX &lt;- imp_ztest |&gt; select(STANDPLOT_CN, CC, BA, SDI)\nX &lt;- remove_rownames(X)\nX &lt;- column_to_rownames(X, \"STANDPLOT_CN\")\n\nY &lt;- imp_ztest  |&gt; select(STANDPLOT_CN, PSME_TD, common, total_TD)\nY &lt;- remove_rownames(Y)\nY &lt;- column_to_rownames(Y, \"STANDPLOT_CN\")\n\nmal &lt;- yai(x = X, y = Y, method = \"mahalanobis\", k = k)\nmsn &lt;- yai(x = X, y = Y, method = \"msn\", k = k)\n\newz &lt;- errorStats(mal, msn)\nscaled_ewz &lt;- errorStats(mal, msn, scale = T)\n\nHere I am extracting the plots where there is zero distance in the predictors from the yai object, then joining the imputation data to those plots.\n\n# msn$neiDstRefs rows of references with the distance to k neighbors\n## This run is had everything as a reference. \nmsn_0dist &lt;- msn$neiDstRefs |&gt; as.data.frame()\n# Selecting only distances for the k = 1 neighbor. \nmsn_0dist &lt;- msn_0dist[msn_0dist$Dst.k1 == 0,]\n\n# Getting the cns of those NN. \nmsn_0dist$STANDPLOT_CN &lt;- row.names(msn_0dist)\ncns_0d &lt;- msn_0dist |&gt; select(STANDPLOT_CN)\n# Joining the imp data to the zero dist NN\ntest_all0s &lt;- left_join(cns_0d, imp_ztest, by = \"STANDPLOT_CN\")\n\ntest_all0s |&gt; arrange(desc(BA)) |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTANDPLOT_CN\nCC\nBA\nSDI\nFPAG\nfpa\nPSME_TD\nABLA_TD\nABAM_TD\nTSHE_TD\ncommon\nuncommon\nrare\ntotal_TD\n\n\n\n\n346864308489998_1\n6\n17.66684\n23\nCDS7\nCDS\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n40220510010497_1\n6\n17.66684\n23\nCPG2\nCPG\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n22827756010497_1\n8\n17.36355\n23\nCPS2\nCPS\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n24208121010900_3\n8\n17.36355\n23\nCERR\nCER\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n484819578489998_2\n5\n15.31406\n21\nCCF2\nCCF\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n8625909010901_2\n5\n15.31406\n21\nCD\nCD\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n# summary(test_all0s[,2:4])\nkable(summary(test_all0s[,2:4]))\n\n\n\n\n\nCC\nBA\nSDI\n\n\n\n\n\nMin. :0.0000\nMin. : 0.000000\nMin. : 0.000\n\n\n\n1st Qu.:0.0000\n1st Qu.: 0.000000\n1st Qu.: 0.000\n\n\n\nMedian :0.0000\nMedian : 0.008177\nMedian : 0.000\n\n\n\nMean :0.6279\nMean : 1.057479\nMean : 1.739\n\n\n\n3rd Qu.:1.0000\n3rd Qu.: 1.029340\n3rd Qu.: 2.000\n\n\n\nMax. :8.0000\nMax. :17.666840\nMax. :34.000\n\n\n\n\n\nThe above data frame shows that the zero distances are where the 3-D vector of\npredictors overlap. Adding more predictors would help.\nI will now run the imputation data without those zero dist. NN.\nThis code runs the distance matrices without zero distances by using unique().\n\nimp_ztest &lt;- imp_data_FPA\nb &lt;- nrow(imp_ztest)\n# selecting predictors only\nX &lt;- imp_ztest |&gt; select(STANDPLOT_CN, CC, BA, SDI)\n# Moving cns to get unique predictors\nX &lt;- remove_rownames(X)\nX &lt;- column_to_rownames(X, \"STANDPLOT_CN\")\nX &lt;- X |&gt; unique()\na &lt;- nrow(X)\n# Before and after unique\nb\n\n[1] 24621\n\na\n\n[1] 22969\n\nprint(str_c(\"before minus after unique = \", (b-a)))\n\n[1] \"before minus after unique = 1652\"\n\n# Finding cns where predictors are unique\nx &lt;- X \nx &lt;- rownames_to_column(x, \"STANDPLOT_CN\") |&gt; select(STANDPLOT_CN)\n\n# Filtering out the zero distances. \nimp_zx &lt;- left_join(x, imp_ztest, by = \"STANDPLOT_CN\")\n# Selecting ancillary data. \nY &lt;- imp_zx |&gt; select(STANDPLOT_CN, PSME_TD, common, total_TD)\nY &lt;- remove_rownames(Y)\nY &lt;- column_to_rownames(Y, \"STANDPLOT_CN\")\n\ntY &lt;- imp_zx |&gt; select(STANDPLOT_CN, PSME_TD, ABLA_TD, ABAM_TD, TSHE_TD, common, uncommon, rare, total_TD)\ntY &lt;- remove_rownames(tY)\ntY &lt;- column_to_rownames(tY, \"STANDPLOT_CN\")\n\n\nmal &lt;- yai(x = X, y = Y, method = \"mahalanobis\", k = k)\nmsn &lt;- yai(x = X, y = Y, method = \"msn\", k = k)\ntmal &lt;- yai(x = X, y = tY, method = \"mahalanobis\", k = k)\ntmsn &lt;- yai(x = X, y = tY, method = \"msn\", k = k)\n\newoz &lt;- errorStats(mal, msn)\nscaled_ewoz &lt;- errorStats(mal, msn, scale = T)\n\nKEEP &lt;- KEEP |&gt; append(c(\"tmsn\", \"tmal\"))\n\n\n\n\n\n\n\n\nmal.see\nmal.rmmsd0\nmal.mlf\n\n\n\n\nPSME_TD\n221.8865\n151.03480\n194.4938\n\n\ncommon\n477.7440\n621.49559\n187.3791\n\n\ntotal_TD\n842.9472\n71.48992\n841.4301\n\n\n\n\n\n\n\n\n\n\n\nmal.rmsd\nmal.rmsdlg\nmal.sei\nmal.dstc\n\n\n\n\nPSME_TD\n321.9114\n398.3118\n303.6794\n284.2806\n\n\ncommon\n523.8155\n596.5675\n285.0513\nNA\n\n\ntotal_TD\n428.8956\n534.1788\n425.9061\n422.8955\n\n\n\n\n\n\n\n\n\n\n\nmsn.rmsd\nmsn.rmsdlg\nmsn.sei\nmsn.dstc\n\n\n\n\nPSME_TD\n261.1057\n330.3856\n238.2654\n212.9898\n\n\ncommon\n575.4805\n679.7284\n371.5500\nNA\n\n\ntotal_TD\n756.9970\n944.6343\n755.3073\n753.6138\n\n\n\n\n\n\nOf the 1884 zero distances of 24621 references in the original data, 1652 of those rows were not unique.\n\nt &lt;- test_all0s |&gt; mutate(t = round(CC + BA + SDI, 4))\nhist(t$t, breaks = 209)\n\n\n\n\nDistribution of t, the sum of CC, BA, and SDI. Trying to see where the values of matching matching vectors exist. Most of the overlap is below 10 and zero. Meaning the values of CC + are low.\n\nt2 &lt;- t |&gt; filter(CC == 0 & BA == 0 & SDI == 0)\n# tt &lt;- t |&gt; filter(CC != 0 & BA != 0 & SDI != 0)\nt &lt;- t |&gt; filter(t&gt;0)\nn_distinct(t$t)\n\n[1] 224\n\nhist(t$t, breaks = 50)\n\n\n\n\nThere are 224 distinct values (above zero) on 1205 plots. The rest of the 1884 plots were zero across the board, no BA, no trees in the over story or seedlings.\n\nt3 &lt;- t |&gt; group_by(t) |&gt; \n  summarise(\n    n_plots_per_t = n()) |&gt; \n  arrange(desc(n_plots_per_t)) \n\n# summary(t[t$t &lt; 1, c(1:4, 14:15)])\nkable(summary(t[t$t &lt; 1, c(1:4, 14:15)]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTANDPLOT_CN\nCC\nBA\nSDI\ntotal_TD\nt\n\n\n\n\n\nLength:591\nMin. :0\nMin. :0.004089\nMin. :0\nMin. : 74.97\nMin. :0.00410\n\n\n\nClass :character\n1st Qu.:0\n1st Qu.:0.004089\n1st Qu.:0\n1st Qu.: 74.97\n1st Qu.:0.00410\n\n\n\nMode :character\nMedian :0\nMedian :0.008177\nMedian :0\nMedian :149.93\nMedian :0.00820\n\n\n\nNA\nMean :0\nMean :0.012418\nMean :0\nMean :227.69\nMean :0.01243\n\n\n\nNA\n3rd Qu.:0\n3rd Qu.:0.016355\n3rd Qu.:0\n3rd Qu.:299.86\n3rd Qu.:0.01640\n\n\n\nNA\nMax. :0\nMax. :0.040887\nMax. :0\nMax. :749.65\nMax. :0.04090\n\n\n\n\n\nIn the set of 1205 where the combined preds are above zero and less than one, there are 591 plots and only BA has values.\n\n# The number of rows\nnrow(t[t$t &lt; 1, c(2:4, 14:15)])\n\n[1] 591\n\n\nThe number of rows between 0 and 1 is 591.\n\n# head(t3, n  = 10)\nkable(head(t3, n  = 10))\n\n\n\n\nt\nn_plots_per_t\n\n\n\n\n0.0041\n230\n\n\n0.0082\n96\n\n\n0.0123\n64\n\n\n0.0164\n54\n\n\n0.0204\n51\n\n\n0.0245\n32\n\n\n0.0286\n25\n\n\n0.0327\n18\n\n\n0.0368\n11\n\n\n1.0450\n11\n\n\n\n\n\nThere are 230 plots where t == 0.0041. 0.0368 & 1.0450 both have 11 plots. For each set of t’s that match, like 0.0368 & 1.0450, there are n_ts_per_nplots.\n\nplot(t3$n_plots_per_t, t3$t)\n\n\n\n\nThe majority of zero distances plots only share a small number of values.\n\ntt &lt;- t3 |&gt; group_by(n_plots_per_t) |&gt; \n  summarize(n_ts_per_nplots = n()) |&gt; \n  mutate(n_that_match = n_ts_per_nplots * n_plots_per_t) |&gt; \n  arrange(desc(n_that_match))\nhead(tt, n = 10)\n\n\n\n\n\nn_plots_per_t\nn_ts_per_nplots\nn_that_match\n\n\n\n\n2\n128\n256\n\n\n230\n1\n230\n\n\n3\n38\n114\n\n\n96\n1\n96\n\n\n4\n20\n80\n\n\n5\n15\n75\n\n\n64\n1\n64\n\n\n54\n1\n54\n\n\n51\n1\n51\n\n\n6\n7\n42\n\n\n\n\n\nsum(tt$n_that_match)\n\n[1] 1205\n\n\n\nThere are 256 plots that match 2 times, on 128 different values of t.\nThere are 230 plots that match 230 times, on 1 value of t.\n\n\ndf &lt;- t |&gt; filter(t == 0.0041)\nsummary(df)\n\n STANDPLOT_CN             CC          BA                SDI   \n Length:230         Min.   :0   Min.   :0.004089   Min.   :0  \n Class :character   1st Qu.:0   1st Qu.:0.004089   1st Qu.:0  \n Mode  :character   Median :0   Median :0.004089   Median :0  \n                    Mean   :0   Mean   :0.004089   Mean   :0  \n                    3rd Qu.:0   3rd Qu.:0.004089   3rd Qu.:0  \n                    Max.   :0   Max.   :0.004089   Max.   :0  \n     FPAG               fpa               PSME_TD         ABLA_TD      \n Length:230         Length:230         Min.   : 0.00   Min.   : 0.000  \n Class :character   Class :character   1st Qu.: 0.00   1st Qu.: 0.000  \n Mode  :character   Mode  :character   Median : 0.00   Median : 0.000  \n                                       Mean   :14.67   Mean   : 6.193  \n                                       3rd Qu.: 0.00   3rd Qu.: 0.000  \n                                       Max.   :74.97   Max.   :74.965  \n    ABAM_TD          TSHE_TD            common         uncommon    \n Min.   : 0.000   Min.   : 0.0000   Min.   : 0.00   Min.   : 0.00  \n 1st Qu.: 0.000   1st Qu.: 0.0000   1st Qu.: 0.00   1st Qu.: 0.00  \n Median : 0.000   Median : 0.0000   Median : 0.00   Median : 0.00  \n Mean   : 1.956   Mean   : 0.3259   Mean   :34.22   Mean   : 8.80  \n 3rd Qu.: 0.000   3rd Qu.: 0.0000   3rd Qu.:74.97   3rd Qu.: 0.00  \n Max.   :74.965   Max.   :74.9653   Max.   :74.97   Max.   :74.97  \n      rare          total_TD           t         \n Min.   : 0.00   Min.   :74.97   Min.   :0.0041  \n 1st Qu.: 0.00   1st Qu.:74.97   1st Qu.:0.0041  \n Median : 0.00   Median :74.97   Median :0.0041  \n Mean   : 8.80   Mean   :74.97   Mean   :0.0041  \n 3rd Qu.: 0.00   3rd Qu.:74.97   3rd Qu.:0.0041  \n Max.   :74.97   Max.   :74.97   Max.   :0.0041  \n\n\nOf those 230 that share one value of t, there is no variation in predictors. There is variation at the species level, but not at the total tree level. These three predictors seem to be good at predicting the total tree density, but not the species present.\n\nFollowing are comparisons between the yai objects and distances for a yai with zeros and one without.\n\n# ewoz is the second row\nmalw &lt;- rbind(ewz$mal, ewoz$mal)\n# malw\nmsnw &lt;- rbind(ewz$msn, ewoz$msn)\ncommonw &lt;- rbind(ewz$common, ewoz$common)\nrow.names(malw) &lt;- c(\"PSME_TD\", \"common\", \"total_TD\", \"PSME_TD_wo0\", \"common_wo0\", \"total_TD_wo0\")\nmalw &lt;- rownames_to_column(malw, \"source\")\nrow.names(msnw) &lt;- c(\"PSME_TD\", \"common\", \"total_TD\", \"PSME_TD_wo0\", \"common_wo0\", \"total_TD_wo0\")\nmsnw &lt;- rownames_to_column(msnw, \"source\")\nrow.names(commonw) &lt;- c(\"PSME_TD\", \"common\", \"total_TD\", \"PSME_TD_wo0\", \"common_wo0\", \"total_TD_wo0\")\ncommonw &lt;- rownames_to_column(commonw, \"source\")\n\n\nmalw |&gt; arrange(source)\n\n\n\n\n\nsource\nmal.rmsd\nmal.rmsdlg\nmal.sei\nmal.dstc\n\n\n\n\nPSME_TD\n312.0201\n338.3963\n297.0426\n281.2686\n\n\nPSME_TD_wo0\n321.9114\n398.3118\n303.6794\n284.2806\n\n\ncommon\n510.7842\n524.6831\n472.1028\n429.9554\n\n\ncommon_wo0\n523.8155\n596.5675\n285.0513\nNA\n\n\ntotal_TD\n413.7486\n455.0015\n413.7486\n413.7486\n\n\ntotal_TD_wo0\n428.8956\n534.1788\n425.9061\n422.8955\n\n\n\n\n\n\nFor mahalonobis (read as euclidian distance), the yai without zeroes was higher in all categories except for common trees standard error of imputation. I don’t know why the distance component is NA.\n\nmsnw |&gt; arrange(source)\n\n\n\n\n\nsource\nmsn.rmsd\nmsn.rmsdlg\nmsn.sei\nmsn.dstc\n\n\n\n\nPSME_TD\n264.9361\n285.4914\n247.1212\n227.9180\n\n\nPSME_TD_wo0\n261.1057\n330.3856\n238.2654\n212.9898\n\n\ncommon\n625.0536\n676.6855\n593.8624\n560.9394\n\n\ncommon_wo0\n575.4805\n679.7284\n371.5500\nNA\n\n\ntotal_TD\n803.3972\n869.4654\n803.3972\n803.3972\n\n\ntotal_TD_wo0\n756.9970\n944.6343\n755.3073\n753.6138\n\n\n\n\n\n\nFor msn (canonical correlation) without zeros was generally lower, except root mean square error of the observations with larger distances (rmsdlg) and common trees SEI.\n\ncommonw |&gt; arrange(source)\n\n\n\n\n\nsource\nmal.see\nmal.rmmsd0\nmal.mlf\n\n\n\n\nPSME_TD\n215.3464\n135.0722786\n193.0073\n\n\nPSME_TD_wo0\n221.8865\n151.0348025\n194.4938\n\n\ncommon\n466.4442\n275.7514975\n423.7343\n\n\ncommon_wo0\n477.7440\n621.4955878\n187.3791\n\n\ntotal_TD\n819.0953\n0.0000003\n819.0953\n\n\ntotal_TD_wo0\n842.9472\n71.4899191\n841.4301\n\n\n\n\n\n\nFor the common stats that are used to compute the others, model lack of fit is much better for common trees. There is also an expectedly large difference for rmsd near 0. rmmsd0 is a measure of variability, pure error, measurement error, and bias. Bias is the squraed average distance compoents in that group.\n\nThis was a test to see what they look like when scaled.\nWith zeroes\nWithout zeroes\n\n\n\n\n\n\n\nmal.see\nmal.rmmsd0\nmal.mlf\n\n\n\n\nPSME_TD\n0.9878199\n0.6195928\n0.8853476\n\n\ncommon\n0.9762440\n0.5771339\n0.8868543\n\n\ntotal_TD\n0.8234868\n0.0000000\n0.8234868\n\n\n\n\n\n\n\n\n\n\n\nmal.see\nmal.rmmsd0\nmal.mlf\n\n\n\n\nPSME_TD\n0.9872021\n0.6719737\n0.8653286\n\n\ncommon\n0.9756580\n1.2692303\n0.3826693\n\n\ntotal_TD\n0.8230136\n0.0697994\n0.8215324"
  },
  {
    "objectID": "5_Model_Eval.html#yaimpute-model-evaluation",
    "href": "5_Model_Eval.html#yaimpute-model-evaluation",
    "title": "Model Eval",
    "section": "yaImpute model evaluation",
    "text": "yaImpute model evaluation\nFor each set, the total_TDs are the same. That is interesting. Explore the tree values for combinations of cc, ba, and sdi. Do the predictors do well at finding total td, but not per species.\n\nVariable Selection.\nVariable Selection\nPerformance based approaches select variables based on changes in the prediction accuracy when variables are added or deleted from models, and include methods by Svetnik and Jiang, varSelRF, caret, RRF, SRC and VSURF.\nThey are using area under the curve as an indicator of fit/performance.\nRegular RF had the highest OOB error rate. I think that yaImpute uses regular RF.\nJiang looks worth checking out. SVETNIK too. These two performed best for error, comp time, and accuracy.\n\nkable(scaled_ewz$mal)\n\n\n\n\n\nmal.rmsd\nmal.rmsdlg\nmal.sei\nmal.dstc\n\n\n\n\nPSME_TD\n1.4312740\n1.552265\n1.3625703\n1.2902132\n\n\ncommon\n1.0690455\n1.098135\n0.9880873\n0.8998749\n\n\ntotal_TD\n0.4159669\n0.457441\n0.4159669\n0.4159669\n\n\n\n\nkable(scaled_ewoz$mal)\n\n\n\n\n\nmal.rmsd\nmal.rmsdlg\nmal.sei\nmal.dstc\n\n\n\n\nPSME_TD\n1.4322261\n1.7721414\n1.3511096\n1.2648015\n\n\ncommon\n1.0697461\n1.2183216\n0.5821373\nNA\n\n\ntotal_TD\n0.4187533\n0.5215468\n0.4158345\n0.4128951\n\n\n\n\n\n\nkable(scaled_ewz$msn)\n\n\n\n\n\nmsn.rmsd\nmsn.rmsdlg\nmsn.sei\nmsn.dstc\n\n\n\n\nPSME_TD\n1.2152940\n1.309583\n1.1335748\n1.0454876\n\n\ncommon\n1.3082054\n1.416268\n1.2429238\n1.1740178\n\n\ntotal_TD\n0.8077045\n0.874127\n0.8077045\n0.8077045\n\n\n\n\nkable(scaled_ewoz$msn)\n\n\n\n\n\nmsn.rmsd\nmsn.rmsdlg\nmsn.sei\nmsn.dstc\n\n\n\n\nPSME_TD\n1.161693\n1.4699291\n1.0600742\n0.9476197\n\n\ncommon\n1.175257\n1.3881544\n0.7587867\nNA\n\n\ntotal_TD\n0.739096\n0.9222961\n0.7374462\n0.7357927\n\n\n\n\n\n\nNote to self, the magrittr pipe and native pipe are different. The magrittr pipe allows for substituting the position of the left hand side argument on the right with a “.”. The native pipe doesn’t. Curly braces overide the lhs to first argument rule. There is also an pipe called the exposition pipe, %$%."
  },
  {
    "objectID": "5_Model_Eval.html#end-of-3-28",
    "href": "5_Model_Eval.html#end-of-3-28",
    "title": "Model Eval",
    "section": "End of 3-28",
    "text": "End of 3-28\nI am trying to figure out how to decide on a reasonable model. I accidentally wasted a day trying to figure out what is going on with the zero distances. It feels important to know that but it also doesn’t. I don’t know how RF is comparable with mal or msn. I need to get an idea of what to compare then run some tests to decide if we are close enough."
  },
  {
    "objectID": "5_Model_Eval.html#bootstap-mean",
    "href": "5_Model_Eval.html#bootstap-mean",
    "title": "Model Eval",
    "section": "Bootstap mean",
    "text": "Bootstap mean\n\nmean(imp_zx$total_TD)\n\n[1] 363.6415\n\nsd(imp_zx$total_TD)\n\n[1] 1024.22\n\nmean(imp_zx$PSME_TD)\n\n[1] 34.41634\n\nsd(imp_zx$PSME_TD)\n\n[1] 224.763\n\n\n\nmany_means &lt;- replicate(10000, mean(sample(x = imp_zx$total_TD, size = 1000, replace = T)))\n\nhist(many_means, breaks = 100, \n     xlab = paste(\n       \"mean is \", round(mean(many_means)), \" sd is \", round(sd(many_means))\n       ))\nabline(v = mean(many_means), col = \"red\")\nabline(v = (mean(many_means)-2*sd(many_means)), col = \"blue\")\nabline(v = (mean(many_means)+2*sd(many_means)), col = \"blue\")\n\n\n\n\nOn average total_TD is 364 trees per acre plus or minus 64. 95% confidence interval is between 300 and 428 TPA.\n\nmean(many_means) + 2*sd(many_means)\n\n[1] 428.9608\n\nmean(many_means) - 2*sd(many_means)\n\n[1] 298.3632\n\n\n\nplot(density(imp_zx$total_TD))\n\n\n\n\n\nimp_zxx &lt;- imp_zx |&gt; filter(total_TD &lt; 10000)\nmany_sds &lt;- replicate(100000, sd(sample(x = imp_zxx$total_TD, size = 100, replace = T)))\n\nhist(many_sds, breaks = 100, \n     xlab = paste(\n       \"mean is \", round(mean(many_sds)), \" sd is \", round(sd(many_sds))\n       ))\nabline(v = mean(many_sds), col = \"red\")\nabline(v = (mean(many_sds)-2*sd(many_sds)), col = \"blue\")\nabline(v = (mean(many_sds)+2*sd(many_sds)), col = \"blue\")\n\n\n\n\nSD 95% is between 300 and 1194.\n\nmean(many_sds) + 2*sd(many_sds)\n\n[1] 1196.989\n\nmean(many_sds) - 2*sd(many_sds)\n\n[1] 299.1858\n\n\nOn average total_TD is 364 trees per acre plus or minus 64. 95% confidence interval is between 300 and 428 TPA. SD 95% is between 300 and 1194. So, we will get negative numbers often.\n\nt &lt;- rnorm(10, mean = mean(many_means), sd = mean(many_sds))\nsummary(t)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n -296.3   204.7   596.3   788.7  1619.7  1654.2 \n\n\n\nB2 log mean\nChecking it out without the outliers and zeroes.\n\nimp_zxx &lt;- imp_zx |&gt; filter(total_TD &lt; 10000 & total_TD != 0)\n\nmany_means &lt;- replicate(10000, log(mean(sample(x = imp_zxx$total_TD, size = 1000, replace = T))))\n\n\nmean(imp_zxx$total_TD)\n\n[1] 651.0511\n\nsd(imp_zxx$total_TD)\n\n[1] 979.7399\n\nplot(\n  density(\n    log(imp_zxx$total_TD)\n    ))\n\n\n\nlog(mean(imp_zxx$total_TD)) |&gt; exp()\n\n[1] 651.0511\n\nlog(sd(imp_zxx$total_TD)) |&gt; exp()\n\n[1] 979.7399\n\n\n\nhist(\n  exp(many_means), breaks = 100, \n  xlab = paste(\n    \"mean is \", round(\n      exp(mean(many_means))\n      ), \" sd is \", round(\n        sd(exp(many_means)),2\n        )\n    ))\nabline(v = exp(mean(many_means)), col = \"red\")\n\nabline(\n  v = exp(mean(many_means)) - 2*sd(\n    exp(many_means)), \n  col = \"blue\")\n\nabline(\n  v = exp(mean(many_means)) + 2*sd(\n    exp(many_means)), \n  col = \"blue\")\n\n\n\n\n\nimp_zxx &lt;- imp_zx |&gt; filter(total_TD &lt; 10000 & total_TD != 0)\n\nmany_sds &lt;- replicate(10000, log(sd(sample(x = imp_zxx$total_TD, size = 1000, replace = T))))\n\n\nhist(\n  exp(many_sds), breaks = 100, \n  xlab = paste(\n    \"mean is \", round(\n      mean(exp(many_sds)),2\n      ), \" sd is \", round(\n        sd(exp(many_sds)),2\n        )\n    ))\n\nabline(v = exp(mean(many_sds)), col = \"red\")\n\nabline(\n  v = exp(mean(many_sds)) - 2*sd(\n    exp(many_sds)), \n  col = \"blue\")\n\nabline(\n  v = exp(mean(many_sds)) + 2*sd(\n    exp(many_sds)), \n  col = \"blue\")\n\n\n\n\n\nmean(exp(many_means))\n\n[1] 651.1479\n\nsd(exp(many_means))\n\n[1] 30.81219\n\nmean(exp(many_sds))\n\n[1] 977.0395\n\nsd(exp(many_sds))\n\n[1] 73.35294\n\n\nWithout the outliers and zeroes, mean trees are 652 trees plus or minus 31. The true sd is 975 plus or minus 73.\n\nmany_sds &lt;- exp(many_sds)"
  },
  {
    "objectID": "5_Model_Eval.html#rf",
    "href": "5_Model_Eval.html#rf",
    "title": "Model Eval",
    "section": "RF",
    "text": "RF\n**This is copied from imp 2. It makes the rf with physcd and adds data to trf, test rf for fpag.\n\n\nCode\nrm(list = ls()[!ls() %in% KEEP])\n\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n\nload(\"sp_prevalence.Rdata\")\n\npred_topo &lt;- plots |&gt; select(\n  STANDPLOT_CN, ELEVFT, SLOPE, ASPECT\n)\npred_Kral &lt;- imp_data |&gt; select(\n  STANDPLOT_CN, CC, BA, SDI, FPAG\n)\n\nresponse &lt;- imp_data |&gt; select(\n  -c(CC, BA, SDI, FPAG)\n)\n\npredictors &lt;- left_join(pred_Kral, pred_topo, join_by(STANDPLOT_CN))|&gt; \n  relocate(FPAG, .after = STANDPLOT_CN)\n\n\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"../../Data/_FIADB_WA.db\")\ncond &lt;- dbGetQuery(con, \"select PLT_CN, CONDID, PHYSCLCD from cond\")\ndbDisconnect(con)\n\nKEEP &lt;- append(KEEP, c(\"cond\"))\n\ng &lt;- read_csv(\"./good_SUB_plots2.csv\", \n              col_types = c(\"cccci\"))\n\ng &lt;- left_join(g, cond, join_by(PLT_CN, CONDID))\ng &lt;- g |&gt; mutate(\n  STANDPLOT_CN = str_c(PLT_CN, \"_\", SUBP)\n) |&gt; \n  select(-SUBPLOT_CN)\n\nx &lt;- left_join(plots, g, join_by(STANDPLOT_CN))\ny &lt;- x |&gt; select(STANDPLOT_CN, PHYSCLCD)\n\nimp_data &lt;- left_join(imp_data, y, join_by(STANDPLOT_CN))\nimp_data &lt;- imp_data |&gt; relocate(PHYSCLCD, .after = FPAG)\n\ny &lt;- predictors |&gt; select(STANDPLOT_CN, ELEVFT, SLOPE, ASPECT)\nimp_data &lt;- left_join(imp_data, y, join_by(STANDPLOT_CN))\nimp_data &lt;- imp_data |&gt; relocate(ELEVFT, SLOPE, ASPECT, .after = SDI)\n\n\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nKEEP &lt;- append(KEEP, \"imp_data_FPA\")\n\nimp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n  common = rowSums(imp_data_FPA[,sp_prevalence$common]),\n  uncommon = rowSums(imp_data_FPA[,sp_prevalence$uncommon]),\n  rare = rowSums(imp_data_FPA[,sp_prevalence$rare]),\n  total_TD = rowSums((imp_data_FPA[grep(\"_TD\", names(imp_data_FPA))]))\n) |&gt;\n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common)\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; \n  relocate(fpa, .after = FPAG)\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; relocate(PHYSCLCD, .before = FPAG)\n\n# I am removing the extra rows to speed up the imputation test. \nfpas &lt;- imp_data_FPA |&gt; \n  filter(\n    total_TD &gt; 0\n  )\n\nKEEP &lt;- append(KEEP, \"fpas\")\n\n# This is here to keep the categories to less than 53 for RF. \nt &lt;- fpas |&gt; group_by(FPAG) |&gt;\n  summarise(n = n()) |&gt;\n  arrange(desc(n)) |&gt;\n  filter(n &gt; 40)\nkeep &lt;- t$FPAG |&gt; as.character()\n# length(keep)\n\nfpas &lt;- fpas |&gt;\n  filter(FPAG %in% keep)\n\n# I am not sure this is the way to set levels. \nfpas$FPAG &lt;- factor(fpas$FPAG, levels = keep)\nfpas$fpa &lt;- as.factor(fpas$fpa)\nfpas$PHYSCLCD &lt;- as.factor(fpas$PHYSCLCD)\n\n\n\nrm(list = ls()[!ls() %in% KEEP])\n\nrefs &lt;- rownames(fpas[1:(3*nrow(fpas)/4),])\n# names(fpas)\n\n# x &lt;- fpas |&gt; select(1:9)\nx &lt;- fpas |&gt; select(STANDPLOT_CN, CC, BA, SDI, ELEVFT, SLOPE, ASPECT, FPAG) #PHYSCLCD,\n\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- fpas |&gt; select(1, 11:ncol(fpas))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\n# rf_all_ps2 &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n\n# save(rf_all_ps2, file = \"rf_all_ps2.Rdata\")\n\nload(\"rf_phys.Rdata\")\nload(\"trf.Rdata\")\nload(\"rf_all_ps.Rdata\")\nload(\"rf_all_ps2.Rdata\")\n\nrf_all_ps2_i &lt;- impute(rf_all_ps2, ancillaryData = y)\nrf_all_ps_i &lt;- impute(rf_all_ps, ancillaryData = y)\ntrf_i &lt;- impute(trf, ancillaryData = y)\nrf_phys_i &lt;- impute(rf_phys, ancillaryData = y)\n\nKEEP &lt;- append(KEEP, c(\"rf_phys\", \"rf_phys_i\", \n                       \"trf\", \"trf_i\", \n                       \"rf_all_ps\", \"rf_all_ps_i\", \n                       \"rf_all_ps2\",  \"rf_all_ps2_i\"))\nKEEP &lt;- KEEP |&gt; unique() |&gt; sort()\nKEEP\n\n [1] \"cond\"         \"fpas\"         \"imp_data_FPA\" \"KEEP\"         \"rf_all_ps\"   \n [6] \"rf_all_ps_i\"  \"rf_all_ps2\"   \"rf_all_ps2_i\" \"rf_phys\"      \"rf_phys_i\"   \n[11] \"tmal\"         \"tmsn\"         \"trf\"          \"trf_i\"       \n\n\n\nyaiVatImp is for variable importance.\nrfSUmmary builds summary data.\n\n\nyaiVarImp(rf_all_ps)\n\n\n\nyaiRFsummary(rf_all_ps)\n\n$forestAttributes\n          ntree       error         errtag levels           type\nMax_SP      166 0.340995647 OOB error rate      7 classification\nsp_max_TD   166 0.008569097 OOB error rate      7 classification\ntotal_TD    166 0.011425462 OOB error rate      7 classification\n\n$scaledImportance\n                   BA        SDI         CC        FPAG     ELEVFT      SLOPE\nMax_SP    -0.09804926 0.04201951 -0.5668497  1.88086175  1.0872913 -0.5087380\nsp_max_TD  1.34163672 1.26761289  0.6381319 -0.12173191 -0.2529331 -0.5583848\ntotal_TD   1.65899078 0.89617704  0.5641649  0.03317348 -0.2197486 -0.7021302\n              ASPECT   PHYSCLCD\nMax_SP    -0.9515318 -0.8850038\nsp_max_TD -0.9149850 -1.3993467\ntotal_TD  -0.8961013 -1.3345261\n\n\n\nyaiVarImp(rf_phys)\n\n\n\nyaiRFsummary(rf_phys)\n\n$forestAttributes\n          ntree       error         errtag levels           type\nMax_SP      166 0.273750753 OOB error rate      8 classification\nsp_max_TD   166 0.004154124 OOB error rate      7 classification\ntotal_TD    166 0.005237809 OOB error rate      7 classification\n\n$scaledImportance\n                BA       SDI         CC       FPAG  PHYSCLCD\nMax_SP    1.128922 0.9682485 -0.6065932 -0.3521191 -1.138458\nsp_max_TD 1.109901 0.8976865 -0.1966440 -0.5287400 -1.282203\ntotal_TD  1.225553 0.8347193 -0.2947947 -0.6035393 -1.161938\n\n\n\nyaiVarImp(trf)\n\n\n\nyaiRFsummary(trf)\n\n$forestAttributes\n          ntree      error         errtag levels           type\nMax_SP      166 0.40590557 OOB error rate      7 classification\nsp_max_TD   166 0.00789223 OOB error rate      7 classification\ntotal_TD    166 0.01020547 OOB error rate      7 classification\n\n$scaledImportance\n                  BA        SDI         CC      FPAG\nMax_SP    -0.3703799 -0.4028081 -0.7092286  1.482417\nsp_max_TD  0.8999042  0.8072323 -0.6518370 -1.055300\ntotal_TD   1.0415167  0.6546549 -0.6928911 -1.003281\n\n\n\nCompare.yai\nmsn and mal on line 420\n\nt &lt;- compare.yai(trf_i, rf_phys_i, rf_all_ps_i, rf_all_ps2_i, tmsn, tmal, scale = F)\nt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrf_i.rmsdS\nrf_phys_i.rmsdS\nrf_all_ps_i.rmsdS\nrf_all_ps2_i.rmsdS\ntmsn.rmsdS\ntmal.rmsdS\n\n\n\n\nPSME_TD\n271.1789\n336.1017\n309.3401\n327.3302\n305.4749\n321.9114\n\n\nABLA_TD\n361.0530\n382.2773\n378.5865\n382.6228\n347.9692\n355.7878\n\n\nABAM_TD\n365.1812\n391.3115\n390.9319\n355.4670\n475.8688\n462.6914\n\n\nTSHE_TD\n683.9745\n730.3227\n708.8734\n645.2229\n537.9215\n558.0709\n\n\ncommon\n676.1598\n726.6772\n701.0854\n691.0965\n523.8103\n523.8155\n\n\nuncommon\n435.6503\n441.7134\n422.4027\n401.4130\n267.3106\n288.0414\n\n\nrare\n221.4940\n232.8179\n205.6853\n213.5311\n213.1674\n213.0985\n\n\ntotal_TD\n1001.8081\n1126.3157\n1234.6532\n1172.8672\n485.4703\n428.8956\n\n\n\n\n\n\n\nt |&gt; apply(2, mean)\n\n       trf_i.rmsdS    rf_phys_i.rmsdS  rf_all_ps_i.rmsdS rf_all_ps2_i.rmsdS \n          502.0625           545.9422           543.9448           523.6938 \n        tmsn.rmsdS         tmal.rmsdS \n          394.6241           394.0391 \n\n\nOn average, tmal had the lowest rmsd, rf_phys the highest.\nPer category, trf did best for PSME and tmal best for total TD.\nI am going to go dig for the cds and cds6 error rates. The error rates are lower for CDS, but I did fix the outliers. I was checking the rmsds as scaled before. I don’t think that could be an issue, but it’s easy enough to check. The rf.Rdata & zrf.Rdata files are from the CDS imputation. z is for the one containing only plots with seedlings, total_td &gt; 0.\n\nt2 &lt;- compare.yai(trf_i, rf_phys_i, rf_all_ps_i, rf_all_ps2_i, tmsn, tmal)\n\nWarning in compare.yai(trf_i, rf_phys_i, rf_all_ps_i, rf_all_ps2_i, tmsn, : not\nall scale factors are the same.\n\nt2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrf_i.rmsdS\nrf_phys_i.rmsdS\nrf_all_ps_i.rmsdS\nrf_all_ps2_i.rmsdS\ntmsn.rmsdS\ntmal.rmsdS\n\n\n\n\nPSME_TD\n0.8432504\n1.0451324\n0.9619155\n1.0178568\n1.3590978\n1.4322261\n\n\nABLA_TD\n0.8463645\n0.8961176\n0.8874658\n0.8969274\n1.2214544\n1.2488993\n\n\nABAM_TD\n0.8646500\n0.9265196\n0.9256206\n0.8416495\n1.1328106\n1.1014418\n\n\nTSHE_TD\n1.0136530\n1.0823413\n1.0505533\n0.9562230\n0.9491315\n0.9846839\n\n\ncommon\n0.8915471\n0.9581565\n0.9244126\n0.9112419\n1.0697356\n1.0697461\n\n\nuncommon\n1.1550078\n1.1710823\n1.1198855\n1.0642369\n1.1171709\n1.2038110\n\n\nrare\n1.0730305\n1.1278893\n0.9964451\n1.0344541\n1.3354140\n1.3349825\n\n\ntotal_TD\n0.7611412\n0.8557381\n0.9380494\n0.8911064\n0.4739902\n0.4187533\n\n\n\n\n\nt2 |&gt; apply(2, mean)\n\n       trf_i.rmsdS    rf_phys_i.rmsdS  rf_all_ps_i.rmsdS rf_all_ps2_i.rmsdS \n         0.9310806          1.0078721          0.9755435          0.9517120 \n        tmsn.rmsdS         tmal.rmsdS \n         1.0823506          1.0993180 \n\n\nI guess that I need to go read about scaling.\n\nplot(t[,1:4])\nplot(t[,3:6])\n\n\n\n\n\n\n\n\n\n\n\n\nplot(t)\n\n\n\n\n\nplot(t2[,1:4])\nplot(t[,1:4])\n\n\n\n\n\n\n\n\n\n\n\nThe yaImpute website says: The RMSD values can be scaled to afford comparisons among variables.\nIt is putting them all on the same scale so that they show the same shape but on the same scale.\nBy default, RMSD is computed using standard formula for its related statistic, RMSE. When scale=TRUE, or set of values is supplied, RMSD is divided by the scaling factor. The scaling factor is the standard deviation of the reference observations under the assumption that they are representative of the population.\n\nt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrf_i.rmsdS\nrf_phys_i.rmsdS\nrf_all_ps_i.rmsdS\nrf_all_ps2_i.rmsdS\ntmsn.rmsdS\ntmal.rmsdS\n\n\n\n\nPSME_TD\n271.1789\n336.1017\n309.3401\n327.3302\n305.4749\n321.9114\n\n\nABLA_TD\n361.0530\n382.2773\n378.5865\n382.6228\n347.9692\n355.7878\n\n\nABAM_TD\n365.1812\n391.3115\n390.9319\n355.4670\n475.8688\n462.6914\n\n\nTSHE_TD\n683.9745\n730.3227\n708.8734\n645.2229\n537.9215\n558.0709\n\n\ncommon\n676.1598\n726.6772\n701.0854\n691.0965\n523.8103\n523.8155\n\n\nuncommon\n435.6503\n441.7134\n422.4027\n401.4130\n267.3106\n288.0414\n\n\nrare\n221.4940\n232.8179\n205.6853\n213.5311\n213.1674\n213.0985\n\n\ntotal_TD\n1001.8081\n1126.3157\n1234.6532\n1172.8672\n485.4703\n428.8956\n\n\n\n\n\nt2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrf_i.rmsdS\nrf_phys_i.rmsdS\nrf_all_ps_i.rmsdS\nrf_all_ps2_i.rmsdS\ntmsn.rmsdS\ntmal.rmsdS\n\n\n\n\nPSME_TD\n0.8432504\n1.0451324\n0.9619155\n1.0178568\n1.3590978\n1.4322261\n\n\nABLA_TD\n0.8463645\n0.8961176\n0.8874658\n0.8969274\n1.2214544\n1.2488993\n\n\nABAM_TD\n0.8646500\n0.9265196\n0.9256206\n0.8416495\n1.1328106\n1.1014418\n\n\nTSHE_TD\n1.0136530\n1.0823413\n1.0505533\n0.9562230\n0.9491315\n0.9846839\n\n\ncommon\n0.8915471\n0.9581565\n0.9244126\n0.9112419\n1.0697356\n1.0697461\n\n\nuncommon\n1.1550078\n1.1710823\n1.1198855\n1.0642369\n1.1171709\n1.2038110\n\n\nrare\n1.0730305\n1.1278893\n0.9964451\n1.0344541\n1.3354140\n1.3349825\n\n\ntotal_TD\n0.7611412\n0.8557381\n0.9380494\n0.8911064\n0.4739902\n0.4187533\n\n\n\n\n\nrf_phys_i$PSME_TD.o |&gt; sd(na.rm = T)\n\n[1] 325.5573\n\n\n\n# The real rmsd for psme is 336.1016\nt$rf_phys_i.rmsdS[1]\n\n[1] 336.1016\n\n# Scaled it's 1.045132\nt2$rf_phys_i.rmsdS[1]\n\n[1] 1.045132\n\n# If I understand, sd should be 321.5876. \nt$rf_phys_i.rmsdS[1]/t2$rf_phys_i.rmsdS[1]\n\n[1] 321.5876\n\n\n\nsd(rf_phys_i$PSME_TD.o, na.rm = T)\n\n[1] 325.5573\n\nsd(rf_phys_i$PSME_TD.o, na.rm = T)/t$rf_phys_i.rmsdS[1]\n\n[1] 0.9686275\n\n\n\nnrow(rf_phys_i)\n\n[1] 22147\n\nrf_phys_i$total_TD.o |&gt; is.na() |&gt;  sum()\n\n[1] 13640\n\nrf_phys_i$total_TD.o |&gt; is.na() |&gt;  sum()/nrow(rf_phys_i)\n\n[1] 0.6158848"
  },
  {
    "objectID": "5_Model_Eval.html#red-flag",
    "href": "5_Model_Eval.html#red-flag",
    "title": "Model Eval",
    "section": "Red Flag",
    "text": "Red Flag\nThere shouldn’t be NAs in the predicted columns. Something phishy is going on.\n\nrf_phys$xRefs |&gt; head()\n\n\n\n\n\n\nCC\nBA\nSDI\nPHYSCLCD\nFPAG\n\n\n\n\n12964130010497_1\n27\n65.68756\n113\n23\nCWF4\n\n\n12964130010497_2\n16\n40.77580\n66\n23\nCWF4\n\n\n12964130010497_3\n22\n45.24877\n101\n23\nCWF4\n\n\n12964130010497_4\n61\n111.67963\n277\n23\nCWF4\n\n\n12964449010497_1\n13\n35.05209\n49\n12\nCDS6\n\n\n12964449010497_2\n0\n0.00000\n0\n12\nCDS6\n\n\n\n\n\n\nScaled vs not for RFs.\n\nplot(t2[,3:6])\nplot(t[,3:6])\n\n\n\n\n\n\n\n\n\n\n\nThe plots I have from before that are comparable are scaled and on CDS. They are in my older notebook in ch 14. Plots w/o zero in the predictors is similar to what I did here, except instead of unique I removed them.\nI do/did get a warning that the imputations use different scaling factors. Off the top of my head, I don’t know where I get those errors. The issue here is that I think the scaled rmsd is showing the true relationship, but the unscaled one is showing the true difference and that says that mal & msn are better. It doesn’t make sence unless they are scaled by different sds. That shouldn’t be the case."
  },
  {
    "objectID": "5_Model_Eval.html#leaving-on-april-fools-day.",
    "href": "5_Model_Eval.html#leaving-on-april-fools-day.",
    "title": "Model Eval",
    "section": "Leaving on april fools day.",
    "text": "Leaving on april fools day.\nI am surprised by this, it looks like the 7 is not better. I need to check these out and figure out what is going on.\nLooking back at the msn, mal, and older RFs to see what the rmsds were. I misread the dataframe. Adding physclcd made it worse, which is what we see here. That isn’t great. I thought I was getting closer.\nLooking back at the distance matrices in warning threshold distance; the rmsds were less. I am confused, the plots indicated that RF was generally better as far as rmsd. The tables I am reading now indicate that is not the case. I am adding bits above to check it out."
  },
  {
    "objectID": "3_imputation_2.html",
    "href": "3_imputation_2.html",
    "title": "Imputation 2",
    "section": "",
    "text": "The last imputation qmd was getting too long. This is a continuation.\nI intend to explore using categorical variables. It was discussed that I try Ecoregion. I also found a variable for soil moisture, PHYSCLCD. It’s in the cond table.\nThere is also probably a better way to summarize species. I used species prevalence before, but it wasn’t a great tool. Some species are common in one FPAG and not in another. I’d like to use them all, but it’s not working. There are too many potential spp. There’s about 49 in the new full set. Most of those are rare species. At least when viewed from the full set.\nI could play with the idea of using total TD and k = 100 to pull a set of probabilities if regen occurs. Prob being the number of plots with regen out of 100.\nI have also not done much to visualize the seedlings vs predictors. I have a different qmd set up for that, but I might combine it here.\nI have a pretty good handle on what this data can do. I need to decide what is good enough. At what point can this setup be said to be reasonable."
  },
  {
    "objectID": "3_imputation_2.html#intro",
    "href": "3_imputation_2.html#intro",
    "title": "Imputation 2",
    "section": "",
    "text": "The last imputation qmd was getting too long. This is a continuation.\nI intend to explore using categorical variables. It was discussed that I try Ecoregion. I also found a variable for soil moisture, PHYSCLCD. It’s in the cond table.\nThere is also probably a better way to summarize species. I used species prevalence before, but it wasn’t a great tool. Some species are common in one FPAG and not in another. I’d like to use them all, but it’s not working. There are too many potential spp. There’s about 49 in the new full set. Most of those are rare species. At least when viewed from the full set.\nI could play with the idea of using total TD and k = 100 to pull a set of probabilities if regen occurs. Prob being the number of plots with regen out of 100.\nI have also not done much to visualize the seedlings vs predictors. I have a different qmd set up for that, but I might combine it here.\nI have a pretty good handle on what this data can do. I need to decide what is good enough. At what point can this setup be said to be reasonable."
  },
  {
    "objectID": "3_imputation_2.html#summary",
    "href": "3_imputation_2.html#summary",
    "title": "Imputation 2",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "3_imputation_2.html#notes",
    "href": "3_imputation_2.html#notes",
    "title": "Imputation 2",
    "section": "Notes",
    "text": "Notes\nThis is copied from Imputation It is the code to imput with FPAG.\n\n\nCode\nlibrary(tidyverse, quietly = T)\nlibrary(esquisse)\nlibrary(yaImpute)\nlibrary(RSQLite)\nlibrary(vegan)\nlibrary(randomForest)\nlibrary(RSQLite)\nlibrary(knitr)\n\noptions(scipen = 999)\n\n\nSetup yai\n\n\nCode\nKEEP &lt;- NULL\nrm(list = ls()[!ls() %in% KEEP])\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n\nload(\"sp_prevalence.Rdata\")\n\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nimp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n  common = rowSums(imp_data_FPA[,sp_prevalence$common]),\n  uncommon = rowSums(imp_data_FPA[,sp_prevalence$uncommon]),\n  rare = rowSums(imp_data_FPA[,sp_prevalence$rare]),\n  total_TD = rowSums(imp_data_FPA[grep(\"_TD\", names(imp_data_FPA))])\n) |&gt;\n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common)\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; \n  relocate(fpa, .after = FPAG)\n\n# I am removing the extra rows to speed up the imputation test. \nfpas &lt;- imp_data_FPA |&gt; \n  filter(\n    total_TD &gt; 0\n  )\n\nrefs &lt;- rownames(fpas[1:(3*nrow(fpas)/4),])\n\nx &lt;- fpas |&gt; select(1:5)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- fpas |&gt; select(1, 7:ncol(fpas))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\nt &lt;- fpas |&gt; group_by(FPAG) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n)) |&gt; \n  filter(n &gt; 120)\n\nkeep &lt;- t$FPAG\n\nt2 &lt;- fpas |&gt; \n  filter(FPAG %in% keep)\n\nt2$FPAG &lt;- as.factor(t2$FPAG)\n\n\nRun yai\n\n\nCode\nrefs &lt;- rownames(t2[1:(3*nrow(t2)/4),])\n\nx &lt;- t2 |&gt; select(1:5)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- t2 |&gt; select(1, 7:ncol(t2))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n# trf &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n\n# save(trf, file = \"trf.Rdata\")\nload(\"trf.Rdata\")\n\ntrf_i &lt;- impute(trf, ancillaryData = y)\n\n\nPlot imputed\nReminder that this is the plot from the last page, the last imputation. It is here for reference.\n\n\nCode\npar(mar = c(1,2,3.2,1))\nplot(trf_i)\n\n\n\n\n\nCode\n# plot(frf2_set)\n# xlim = c(1,10)\n\n\n\nAside to do some tree math\nThe highest total_TD in our area is 47827.850. That is just the seedlings. How many tree per square foot are in there?\n\nmax_tpa &lt;- 47828 \nsqft_ac &lt;- 43560\n\nmax_tpa/sqft_ac\n\n[1] 1.09798\n\n\nI guess 1.09798 trees per square foot isn’t insane. There is going to be a lot of die off. I wonder how many per year FVS will predict?\nCheck plot 22399018010497_3 the next time I run FVS. This stand is new, it’s not in the last sets I ran."
  },
  {
    "objectID": "3_imputation_2.html#physclcd",
    "href": "3_imputation_2.html#physclcd",
    "title": "Imputation 2",
    "section": "PHYSCLCD",
    "text": "PHYSCLCD\nNote to self to add condid to the database next time\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"../../Data/_FIADB_WA.db\")\n# dbExecute(con, \"delete from cond where length(PLT_CN) &lt; 7\")\ncond &lt;- dbGetQuery(con, \"select PLT_CN, CONDID, PHYSCLCD from cond\")\ndbDisconnect(con)\n\ng &lt;- read_csv(\"./good_SUB_plots2.csv\", \n              col_types = c(\"cccci\"))\n\ng &lt;- left_join(g, cond, join_by(PLT_CN, CONDID))\ng &lt;- g |&gt; mutate(\n  STANDPLOT_CN = str_c(PLT_CN, \"_\", SUBP)\n) |&gt; \n  select(-SUBPLOT_CN)\n\nx &lt;- left_join(plots, g, join_by(STANDPLOT_CN))\ny &lt;- x |&gt; select(STANDPLOT_CN, PHYSCLCD)\n\nimp_data &lt;- left_join(imp_data, y, join_by(STANDPLOT_CN))\nimp_data &lt;- imp_data |&gt; relocate(PHYSCLCD, .after = FPAG)\n\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nimp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n  common = rowSums(imp_data_FPA[,sp_prevalence$common]),\n  uncommon = rowSums(imp_data_FPA[,sp_prevalence$uncommon]),\n  rare = rowSums(imp_data_FPA[,sp_prevalence$rare]),\n  total_TD = rowSums((imp_data_FPA[grep(\"_TD\", names(imp_data_FPA))]))\n) |&gt;\n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common)\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; \n  relocate(fpa, .after = FPAG)\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; relocate(PHYSCLCD, .before = FPAG)\n\n# I am removing the extra rows to speed up the imputation test. \nfpas &lt;- imp_data_FPA |&gt; \n  filter(\n    total_TD &gt; 0\n  )\n\n\n\nt &lt;- fpas |&gt; group_by(FPAG) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n)) |&gt; \n  filter(n &gt; 120)\nkeep &lt;- t$FPAG\n\nt2 &lt;- fpas |&gt; \n  filter(FPAG %in% keep)\n\nt2$FPAG &lt;- as.factor(t2$FPAG)\nt2$PHYSCLCD &lt;- as.factor(t2$PHYSCLCD)\n\n\nn_distinct(t2$FPAG)\n\n[1] 26\n\nn_distinct(t2$PHYSCLCD)\n\n[1] 13\n\n\n198 FPAGs in the full set of imp_data. 44 in t2, after filtering for only those with at least 120 subplots.\n15 distinct physcds in imp_data, and t2.\n\nrefs &lt;- rownames(t2[1:(3*nrow(t2)/4),])\n\nx &lt;- t2 |&gt; select(1:6)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- t2 |&gt; select(1, 8:ncol(t2))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n# rf_phys &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n\n\n# save(rf_phys, file = \"rf_phys.Rdata\")\nload(\"rf_phys.Rdata\")\n\n\nplot(rf_phys, vars = yvars(rf_phys))\n# plot(rf, vars = yvars(rf))\n\ntrf_i &lt;- impute(trf, ancillaryData = y)\nrf_phys_i &lt;- impute(rf_phys, ancillaryData = y)\n\n\n\n\n\n\n\n\n\nPlots\nAdding Physcd didn’t help as much as I thought it would, but it did do something. I need to compare the numbers.\n\npar(mar = c(1,2,3.2,1))\nplot(rf_phys_i)\nplot(trf_i)\n# plot(frf2_set)\n# xlim = c(1,10)\n\n\n\n\n\n\n\n\n\n\n\n\ntrf_rmsd &lt;- rmsd.yai(trf_i)\nph_rmsd &lt;- rmsd.yai(rf_phys_i)\nph_rmsd &lt;- rownames_to_column(ph_rmsd, \"spec\")\ntrf_rmsd &lt;- trf_rmsd |&gt; rownames_to_column(\"spec\")\nz &lt;- left_join(ph_rmsd, trf_rmsd, by = \"spec\", \n               suffix = c(\".ph\", \".trf\"))\nz &lt;- z |&gt; mutate(diff = rmsd.ph - rmsd.trf)\nz\n\n\n\n\n\nspec\nrmsd.ph\nrmsd.trf\ndiff\n\n\n\n\nPSME_TD\n297.5946\n266.1156\n31.47904\n\n\nABLA_TD\n384.9643\n354.0954\n30.86889\n\n\nABAM_TD\n410.7614\n380.8726\n29.88885\n\n\nTSHE_TD\n720.9237\n673.2647\n47.65899\n\n\ncommon\n713.6788\n663.5073\n50.17154\n\n\nuncommon\n459.7389\n427.1661\n32.57280\n\n\nrare\n228.7634\n217.4765\n11.28688\n\n\ntotal_TD\n1143.1015\n996.9510\n146.15054\n\n\n\n\n\n\nThe imputation with physcode is higher in rmsd across the board.\nI am not sure what the distance is for RF, but I know it needs to be minimized. Distance is the difference in counts imputed vs observed."
  },
  {
    "objectID": "3_imputation_2.html#variable-selection.",
    "href": "3_imputation_2.html#variable-selection.",
    "title": "Imputation 2",
    "section": "Variable selection.",
    "text": "Variable selection."
  },
  {
    "objectID": "1_Copied_Code.html",
    "href": "1_Copied_Code.html",
    "title": "Plot Selection",
    "section": "",
    "text": "The following code is pulled from my last set of notes in the stated chapters. It has all been updated as of Mar 23 2024.\nTo do\nThe code on this page goes from a shapefile and FIA data to FVS’s computed variables. ___"
  },
  {
    "objectID": "1_Copied_Code.html#plot-selection",
    "href": "1_Copied_Code.html#plot-selection",
    "title": "Plot Selection",
    "section": "Plot selection",
    "text": "Plot selection\n\nlibrary(tidyverse)\nlibrary(RSQLite)\nlibrary(readxl)\nlibrary(writexl)\n\noptions(scipen = 999)\n\nPrevious steps:\n\nI pulled the lat and long from the FIA’s WA database.\nCreated a point cloud from the coordinates table in Arc Pro.\nClipped the point cloud with POC3/OKWEN/OKWEN_shapefiles/OKWEN_AllFOAs_60km_buffer.shp\nSaved the clipped points to 60k_buffer_fiaplots.csv.\n\nIn the following code:\n\nConnect to the WA FIA .db\nSummarize the eco regions present in the foa boundary.\nlist the eco regions in the study area.\nextract all eco regions in WA that are in our study area and the FVS_Ready data.\n\n\n\nCode\ncon &lt;- dbConnect(RSQLite::SQLite(), \"C:/RxFire/Data/_FIADB_WA.db\")\n\n# This is the selection of plots by lat long from the okwen all foas 60k buffer. \nfoa_60_plots &lt;- read.csv(\"C:/RxFire/Regen/60k_buffer_fiaPlots.csv\")\n\n# Matching the foa cns to the table with ecoregions. \ncns &lt;- foa_60_plots |&gt; select(CN)\n\n# dbListTables(con)\n# dbListFields(con, \"FVS_PLOTINIT_PLOT\")\n\nplots &lt;- dbGetQuery(con, \"SELECT STAND_CN, STANDPLOT_CN, ECOREGION FROM FVS_PLOTINIT_PLOT\")\n\ncns$CN &lt;- as.character(cns$CN)\n\n# 45304 plots\nplots_60 &lt;- left_join(cns, plots, join_by(CN == STAND_CN))\n\n# Checking the number of NAs\nprint(\"There are this many NAs\")\n\n\n[1] \"There are this many NAs\"\n\n\nCode\nnrow(plots_60) - nrow(drop_na(plots_60))\n\n\n[1] 1436\n\n\nCode\nplots_60 &lt;- drop_na(plots_60)\n\ndbDisconnect(con)\n\n\nn_ecos &lt;- plots_60 |&gt; group_by(ECOREGION) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n))\n\n# Create a list of ecoregions in the study area. \n# The first time, I used gen_eco, that was too broad. \neco_list &lt;- n_ecos |&gt; \n  mutate(\n    gen_eco = str_sub(ECOREGION, 1, -2)\n  )\n# Pull all plots in those ecoregions. \n# nsa_plots &lt;- plots |&gt; mutate(\n#   gen_eco = str_sub(ECOREGION, 1, -2)) |&gt; \n#   filter(gen_eco %in% eco_list$gen_eco)\n\nnsa_plots &lt;- plots |&gt; mutate(\n  gen_eco = str_sub(ECOREGION, 1, -2)) |&gt; \n  filter(ECOREGION %in% eco_list$ECOREGION)\n\n# 59,800 plots w/gen_eco, 58878 w/ecoregion\n# save(nsa_plots, file = \"nsa_plots.Rdata\")\n\nrm(list = ls()[!ls() %in% c(\"nsa_plots\")])"
  },
  {
    "objectID": "1_Copied_Code.html#ch4",
    "href": "1_Copied_Code.html#ch4",
    "title": "Plot Selection",
    "section": "Ch4",
    "text": "Ch4\n\nlibrary(tidyverse, warn.conflicts = F)\nlibrary(RSQLite)\nlibrary(readxl)\nlibrary(writexl)\n\noptions(scipen = 999)\n\n# nsa_plots &lt;- read_csv(\"C:/RxFire/Regen/Species_Plot_ecotype/FIA_NSA_Nat_design_NEWWA.csv\",\n#                       col_types = c(\"c\"))\n\nload(\"./nsa_plots.Rdata\")\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"C:/RxFire/Data/_FIADB_WA.db\")\n# Making a list to pull from the big database'\n# This requires less RAM than loading in the database. \nstandlist &lt;- NULL\nstandlist &lt;- str_c(\"'\", nsa_plots$STAND_CN, \"'\")\nstandlist &lt;- str_flatten_comma(standlist)\n\n# Pulling the tables\nztree &lt;- dbGetQuery(con, str_c(\"select * from TREE WHERE PLT_CN IN (\", standlist, \")\"))\nzplot &lt;- dbGetQuery(con, str_c(\"select * from plot WHERE CN IN (\", standlist, \")\"))\nzp2veg &lt;- dbGetQuery(con, str_c(\"select * from P2VEG_SUBPLOT_SPP WHERE PLT_CN IN (\", standlist, \")\"))\nSPGRPkey &lt;- dbGetQuery(con,\"select * from REF_SPECIES_GROUP\")\n\n\n# Removing empty fields\nzplot &lt;- zplot[, colSums(is.na(zplot)) &lt; nrow(zplot)]\n# zstand &lt;- zstand[, colSums(is.na(zstand)) &lt; nrow(zstand)]\nztree &lt;- ztree[, colSums(is.na(ztree)) &lt; nrow(ztree)]\n# ztree_init &lt;- ztree_init[, colSums(is.na(ztree_init)) &lt; nrow(ztree_init)] \nzp2veg &lt;- zp2veg[, colSums(is.na(zp2veg)) &lt; nrow(zp2veg)]\n\nzcond &lt;- dbGetQuery(con, str_c(\"select * from COND WHERE PLT_CN IN (\", standlist, \")\"))\nzcond &lt;- zcond[, colSums(is.na(zcond)) &lt; nrow(zcond)]\n\nprint(\"the number of condition CNs in the standlist:\") \n\n[1] \"the number of condition CNs in the standlist:\"\n\ndim(zcond)\n\n[1] 19599    98\n\n# Remove artificial regeneration, keep NAs and zeros. \nzcond &lt;- zcond |&gt; filter(\n  STDORGCD == 0 | is.na(STDORGCD)\n)\nprint(\"after controlling for artificial regen\")\n\n[1] \"after controlling for artificial regen\"\n\ndim(zcond)\n\n[1] 18049    98\n\n# # Altered: remove all non-forest conditions. \n# Remove Non-Forested Conditions related to man. \n# unique(zcond$PRESNFCD)\nzcond &lt;- zcond |&gt; filter(\n  (is.na(PRESNFCD))\n)\nprint(\"after controlling for non-forest conditions\")\n\n[1] \"after controlling for non-forest conditions\"\n\ndim(zcond)\n\n[1] 11377    98\n\n# Remove unsampled plots and water\nzcond &lt;- zcond |&gt; filter(\n  COND_STATUS_CD == 1 | is.na(COND_STATUS_CD) | COND_STATUS_CD == 2\n)\n\n\n\n# Remove unsampled plots. \nzcond &lt;- zcond |&gt; filter(\n  is.na(COND_NONSAMPLE_REASN_CD)\n)\nprint(\"after controlling for unsampled and water\")\n\n[1] \"after controlling for unsampled and water\"\n\ndim(zcond)\n\n[1] 9880   98\n\n# There should also be a line for removing the periodic visits, \n# KINDCD = 0.\nzplot &lt;- zplot |&gt; filter(\n  KINDCD != 0\n)\nx &lt;- zplot |&gt; select(PLT_CN = CN, KINDCD)\ny &lt;- left_join(zcond, x, by = \"PLT_CN\")\nzcond &lt;- drop_na(y, KINDCD)\n\nprint(\"after controlling for periodic visits\")\n\n[1] \"after controlling for periodic visits\"\n\ndim(zcond)\n\n[1] 9145   99\n\nzcond &lt;- zcond |&gt; select(\n  CN, PLT_CN, CONDID, HABTYPCD = HABTYPCD1)\n\nzcond &lt;- zcond |&gt; mutate(\n  FPAG = str_remove_all(str_sub(HABTYPCD, 1, 4), \" \")\n)\n\n# NAs in FPAG\nna &lt;- zcond |&gt; filter(is.na(FPAG))\n# good needs some cleaning\ngood &lt;- zcond |&gt; filter(!is.na(FPAG))\n\ngood$PLT_CN &lt;- as.character(good$PLT_CN)\n\n# # Confirming there are no periodic plots. \n# good |&gt; group_by(PLT_CN) |&gt; \n#   summarise(len = str_width(PLT_CN)) |&gt; \n#   arrange(len)\n\n\n\nplants &lt;- read_csv(\"C:/RxFire/Regen/Species_Plot_ecotype/PLANTS.csv\",\n                   col_types = c(\"c\",\"c\",\"c\",\"c\",\"c\"))\n\nplants &lt;- plants |&gt; select(Symbol , Common_Name) |&gt; drop_na()\n# Join the Common Names to the veg list for readability\nzp2veg &lt;- left_join(zp2veg, plants, join_by(\"VEG_SPCD\" == \"Symbol\"))\n\n# Remove extra fields\nzp2veg &lt;- zp2veg |&gt; select(CN,\n  PLT_CN, VEG_SPCD, Common_Name, COVER_PCT, PLOT, SUBP, VEG_FLDSPCD, \n  UNIQUE_SP_NBR, GROWTH_HABIT_CD)\n\n\ntest &lt;- na |&gt; select(CN)\n\n\n# Looking at those NAs\nCN &lt;- NULL\nCN &lt;- str_c(\"'\", test$CN, \"'\")\nCN &lt;- str_flatten_comma(CN)\n\ntest2 &lt;- dbGetQuery(con, str_c(\"select * from COND WHERE CN IN (\", CN, \")\"))\ntest2 &lt;- test2[, colSums(is.na(test2)) &lt; nrow(test2)]\n\ntest &lt;- test2 |&gt; select(CN, PLT_CN)\nPLT_CN &lt;- NULL\nPLT_CN &lt;- str_c(\"'\", test$PLT_CN, \"'\")\nPLT_CN &lt;- str_flatten_comma(PLT_CN)\n\n# all cns that didn't have FPAGs\ntcond &lt;- dbGetQuery(con, str_c(\"select * from COND WHERE CN IN (\", CN, \")\"))\n\n# These plots exist and have trees, but these cond.CN's do not. \n\n# ttree has zero tree records, but tttree does. The stands have trees but not on \n#  those conditions. \nttree &lt;- dbGetQuery(con, str_c(\"select * from TREE WHERE CN IN (\", CN, \")\"))\ntttree &lt;- dbGetQuery(con, str_c(\"select * from TREE WHERE PLT_CN IN (\", PLT_CN, \")\"))\n\n# There are 1,319 cond's on 1,268 plots. \n# second time through, there are 276 tconds and 245 tplots. \ntplot &lt;- dbGetQuery(con, str_c(\"select * from plot WHERE CN IN (\", PLT_CN, \")\"))\n\n\nrm(CN, PLT_CN, test, test2, tcond, ttree, tttree, tplot)\nrm(ztree, zplot, zp2veg, zcond, plants, nsa_plots, na)\nrm(standlist)\n\ndbDisconnect(con)\n\ng &lt;- good |&gt; select(PLT_CN, CONDID, HABTYPCD) |&gt; unique()\n\n# write_csv(good, \"./good_plots_03242024.csv\")\n\n6092 stands to use vs 6,337 before."
  },
  {
    "objectID": "1_Copied_Code.html#ch-5",
    "href": "1_Copied_Code.html#ch-5",
    "title": "Plot Selection",
    "section": "CH 5",
    "text": "CH 5\ngood shouldn’t have the short cns. Those are periodic visits.\n\nrm(list = ls())\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"C:/RxFire/Data/_FIADB_WA.db\")\n\n# This is just the csv I saved above. \ngood &lt;- read_csv(\"./good_plots_03242024.csv\",\n                 col_types = c(\"ccnc\"))\n\ngood &lt;- good |&gt; select(PLT_CN, CONDID, FPAG) |&gt; unique()\ng &lt;- good |&gt; select(PLT_CN) |&gt; unique()\n\nPLT_CN &lt;- NULL\nPLT_CN &lt;- str_c(\"'\", g$PLT_CN, \"'\")\nPLT_CN &lt;- str_flatten_comma(PLT_CN)\n\nzsubplot &lt;- dbGetQuery(con, str_c(\"select * from subplot WHERE PLT_CN IN (\", PLT_CN, \")\"))\nzsubcond &lt;- dbGetQuery(con, str_c(\"select * from subp_cond WHERE PLT_CN IN (\", PLT_CN, \")\"))\n\n\n# This is every plot and condition that we could sample. \nzsubcond &lt;- left_join(good, zsubcond, join_by(PLT_CN, CONDID))\n\nzsubplot &lt;- zsubplot[, colSums(is.na(zsubplot)) &lt; nrow(zsubplot)]\nzsubcond &lt;- zsubcond[, colSums(is.na(zsubcond)) &lt; nrow(zsubcond)]\n\n# filter for where micro and sup were the same\nzsubplot &lt;- zsubplot |&gt; filter(\n  (MICRCOND == SUBPCOND)\n)\n\n# select all plots with equal conditions and some data for fpag\nzsubkey &lt;- zsubplot |&gt; select(PLT_CN, SUBP) |&gt; unique()\nzcondkey &lt;- zsubcond |&gt; select(PLT_CN, SUBP, FPAG) |&gt; unique()\n#  drop_na()\n\n# Joing them to make a key\nzcon &lt;- left_join(zsubkey, zcondkey, join_by(PLT_CN, SUBP)) |&gt; drop_na()\n\nzsubcond &lt;- zsubcond |&gt; select(\n  PLT_CN, CONDID, FPAG, CN, INVYR, PLOT, SUBP, MICRCOND_PROP, SUBPCOND_PROP, \n  MACRCOND_PROP, NONFR_INCL_PCT_SUBP, NONFR_INCL_PCT_MACRO, CYCLE)\n\n\nunique_conds &lt;- zsubcond |&gt; \n  filter(\n    near(SUBPCOND_PROP, 1, tol = .025) & near(MICRCOND_PROP, 1, tol = .025)\n    )\n\nt &lt;- unique_conds |&gt; select(PLT_CN, SUBP, CN, FPAG)\n\nt &lt;- t |&gt; filter(\n  !startsWith(FPAG, \"A\") & !startsWith(FPAG, \"N\") & !startsWith(FPAG, \"W\")\n)\n\n# I chose CAS4 bc it was the largest group of the three options. \nt &lt;- t |&gt; mutate(\n  FPAG = ifelse(FPAG == \"PIAL\", \"CAGO\", FPAG)\n)\n\nsubs &lt;- t |&gt; rename(SUBPLOT_CN = CN)\n\nunique(t$FPAG) |&gt; sort()\n\n  [1] \"CA\"   \"CAC1\" \"CAC5\" \"CACE\" \"CAF2\" \"CAF3\" \"CAG1\" \"CAG2\" \"CAG3\" \"CAGO\"\n [11] \"CAS-\" \"CAS2\" \"CAS3\" \"CAS4\" \"CC\"   \"CCF2\" \"CCHS\" \"CCS2\" \"CCS3\" \"CD\"  \n [21] \"CD27\" \"CD61\" \"CD63\" \"CD81\" \"CDF0\" \"CDF4\" \"CDG1\" \"CDG2\" \"CDG3\" \"CDG6\"\n [31] \"CDGE\" \"CDH4\" \"CDRX\" \"CDS\"  \"CDS1\" \"CDS2\" \"CDS3\" \"CDS4\" \"CDS5\" \"CDS6\"\n [41] \"cds7\" \"CDS7\" \"CDS8\" \"CE\"   \"CE41\" \"CE54\" \"CEF1\" \"CEF2\" \"CEF3\" \"CEF4\"\n [51] \"CEFA\" \"CEFH\" \"CEFM\" \"CEG1\" \"CEG2\" \"CEG3\" \"CEM1\" \"CEM2\" \"CEM3\" \"CEN2\"\n [61] \"CERR\" \"CES\"  \"CES1\" \"CES2\" \"CES3\" \"CES4\" \"CES5\" \"CES6\" \"CF\"   \"CFF1\"\n [71] \"CFF2\" \"CFF3\" \"CFF4\" \"CFM1\" \"CFRR\" \"CFS\"  \"CFS-\" \"CFS1\" \"CFS2\" \"CFS3\"\n [81] \"CFS4\" \"CFS5\" \"CFS6\" \"CFSC\" \"CH\"   \"CH12\" \"CH21\" \"CH6-\" \"CH62\" \"CHC2\"\n [91] \"CHD1\" \"CHF\"  \"CHF0\" \"CHF1\" \"CHF2\" \"CHF3\" \"CHF4\" \"CHF5\" \"CHF6\" \"CHF9\"\n[101] \"CHFI\" \"CHFS\" \"CHM1\" \"CHMI\" \"CHS\"  \"CHS1\" \"CHS2\" \"CHS3\" \"CHS4\" \"chs5\"\n[111] \"CHS5\" \"CHS6\" \"CHS7\" \"CHS8\" \"CHS9\" \"CHSI\" \"CL\"   \"CLM4\" \"CLS2\" \"CLS3\"\n[121] \"CLS4\" \"CLS5\" \"CM\"   \"CM53\" \"CM55\" \"CMF1\" \"CMF2\" \"CMG2\" \"CMS1\" \"CMS2\"\n[131] \"CMS3\" \"CMS4\" \"CMS5\" \"CP\"   \"CPF0\" \"CPG0\" \"CPG1\" \"CPG2\" \"CPS0\" \"CPS2\"\n[141] \"CPS3\" \"CPS5\" \"CS\"   \"CS53\" \"CSF1\" \"CSF2\" \"CSF3\" \"CW\"   \"CW33\" \"CW55\"\n[151] \"CW61\" \"CWC4\" \"CWF0\" \"CWF2\" \"CWF3\" \"CWF4\" \"CWF5\" \"CWG1\" \"CWGI\" \"CWS2\"\n[161] \"CWS3\" \"CWS4\" \"CWS5\" \"CWS8\" \"HA\"   \"HAF\"  \"HAM0\" \"HAM1\" \"HAS1\" \"HAS3\"\n[171] \"HB\"   \"HBM1\" \"HBS1\" \"HC\"   \"HCD1\" \"HCS1\" \"HCS3\" \"HD\"   \"HM\"   \"HO\"  \n[181] \"HOC2\" \"HOG1\" \"HOG2\" \"HOG3\" \"HOS1\" \"HOS3\" \"HOS6\" \"HQ\"   \"HQG1\" \"HQM2\"\n[191] \"HQS0\" \"HQS2\" \"HX\"   \"SM20\" \"SM40\" \"SM81\" \"SW21\" \"SW22\" \"SW72\"\n\ndbDisconnect(con)\n\nOnly conifer hardwood and shrub classes present.\n\nFVS prep\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"C:/RxFire/Data/_FIADB_WA.db\")\n# write_csv(subs, \"./good_SUB_plots.csv\")\n\nsubs &lt;- read_csv(\"./good_SUB_plots.csv\",\n                 col_types = c(\"cncc\"))\n\nsubs &lt;- subs |&gt; mutate(\n  STANDPLOT_CN = str_c(PLT_CN, \"_\", SUBP)\n)\n\nSTAND_CN &lt;- NULL\nSTAND_CN &lt;- str_c(\"'\", subs$PLT_CN, \"'\")\nSTAND_CN &lt;- str_flatten_comma(STAND_CN)\n\nSTANDPLOT_CN &lt;- NULL\nSTANDPLOT_CN &lt;- str_c(\"'\", subs$STANDPLOT_CN, \"'\")\nSTANDPLOT_CN &lt;- str_flatten_comma(STANDPLOT_CN)\n\n\nstand &lt;- dbGetQuery(con, \n                    str_c(\"Select * from FVS_STANDINIT_PLOT where STAND_CN IN (\", STAND_CN, \")\"))\n\nplot &lt;- dbGetQuery(con, \n                   str_c(\"Select * from FVS_PLOTINIT_PLOT where STANDPLOT_CN IN (\", STANDPLOT_CN, \")\"))\n\nplot &lt;- plot[, colSums(is.na(plot)) &lt; nrow(plot)]\nstand &lt;- stand[, colSums(is.na(stand)) &lt; nrow(stand)]\n\nplot &lt;- subset(plot, select = -c(GROUPS, INV_MONTH, INV_DAY, DATUM))\n\n\nstand &lt;- subset(stand, select = -c(INV_MONTH, INV_DAY, STATE, COUNTY))\n\n\nt &lt;- plot |&gt; select(STANDPLOT_CN)\n\nt &lt;- left_join(t, subs, by = \"STANDPLOT_CN\")\n\nt &lt;- t |&gt; mutate(\n  FPAG = str_remove_all(str_to_upper(FPAG), \" \")\n)\n\nSTANDPLOT_CN &lt;- NULL\nSTANDPLOT_CN &lt;- str_c(\"'\", t$STANDPLOT_CN, \"'\")\nSTANDPLOT_CN &lt;- str_flatten_comma(STANDPLOT_CN)\n\ntree &lt;- dbGetQuery(con, \n                   str_c(\"Select * from FVS_TREEINIT_PLOT where STANDPLOT_CN IN (\", STANDPLOT_CN, \")\"))\n\ntree &lt;- tree[, colSums(is.na(tree)) &lt; nrow(tree)]\n\n\n# 8701 records\nregen &lt;- tree |&gt; filter(\n  startsWith(TREE_CN, \"S\")\n) |&gt; select(STANDPLOT_CN) |&gt; unique()\n\n\nsubs &lt;- subs[, c(1, 2, 4, 5)]\n\nregen &lt;- left_join(regen, subs, by = \"STANDPLOT_CN\")\n\nrtrees &lt;- left_join(regen, tree, by = \"STANDPLOT_CN\")\n\nt4 &lt;- regen |&gt; group_by(FPAG) |&gt; summarise(n = n()) \n\nprint(\"Median number of subplots where regen occurred is \")\n\n[1] \"Median number of subplots where regen occurred is \"\n\nmedian(t4$n)\n\n[1] 8\n\ns &lt;- subs |&gt; select(STANDPLOT_CN, FPAG)\np &lt;- left_join(plot, s, by = \"STANDPLOT_CN\")\n\np$INV_YEAR &lt;-  2020\n\n\nrm(t, t4)\ndbDisconnect(con)\n\nname &lt;- str_c(\"FVS_inputDB_\", \n              strftime(Sys.Date(),\"%m%d%y\"), \n              \"_\", \n              strftime(Sys.time(),\"%H%M\"),\n              \".db\")\n\n# con = dbConnect(RSQLite::SQLite(), dbname = str_c(\"../\", name)\n# \n# dbWriteTable(conn = con, name = \"FVS_STANDINIT_PLOT\", value = stand, overwrite = T)\n# dbWriteTable(conn = con, name = \"FVS_PLOTINIT_PLOT\", value = p, overwrite = T)\n# dbWriteTable(conn = con, name = \"FVS_TREEINIT_PLOT\", value = tree, overwrite = T)\n# dbListTables(conn = con)\n# dbDisconnect(con)\n\nstandlist &lt;- p |&gt; select(STAND_CN, STANDPLOT_CN, VARIANT, FPAG)\n\nunique(standlist$VARIANT)\n\n[1] \"EC\" \"WC\" \"PN\" \"IE\"\n\nstandlist &lt;- standlist |&gt; mutate(\n  VARIANT = ifelse(VARIANT == \"PN\", \"WC\", VARIANT),\n  VARIANT = ifelse(VARIANT == \"IE\", \"EC\", VARIANT)\n)\nunique(standlist$VARIANT)\n\n[1] \"EC\" \"WC\"\n\nname &lt;- str_c(\"standlist_\", \n              strftime(Sys.Date(),\"%m%d%y\"), \n              \"_\", \n              strftime(Sys.time(),\"%H%M\"),\n              \".csv\")\n\n# write_csv(standlist, str_c(\"./\", name))"
  },
  {
    "objectID": "1_Copied_Code.html#ch-6-fvs",
    "href": "1_Copied_Code.html#ch-6-fvs",
    "title": "Plot Selection",
    "section": "CH 6 FVS",
    "text": "CH 6 FVS\nThis code chunk runs FVS to get CC, BA, and SDI.\nSet FVS bin to the FVS executable.\nThis time consuming step might be avoided using the p2veg_spp table. There is a canopy cover by species variable there. It could be summed. Also, perhaps using percent CC by species could be a better predictor than just CC.\nFVS has been running for 20 minutes with these 25,516 subplots.\n\nrm(list = ls())\n\nlibrary(RSQLite)\nlibrary(tidyverse, quietly = T, warn.conflicts = F)\nlibrary(readxl)\n\noptions(scipen = 999)\n\n\n# 1. Set paths ---------------------------------------------------------------\n## Set all the file paths and names in this section. Then, run the rest of the script in sections 2. \n\n## Set the working directory here.\n# setwd(\"C:\\\\RxFire\\\\Regen\\\\FVS\")\nfvs_wd &lt;- \"C:\\\\RxFire\\\\Regen\\\\FVS\"\n\n## Where are the FVS executables? FVSbin? \n#  Include the \\\\FVS prefix to variant.exe. \nFVSbin &lt;-  \"C:\\\\FVSbin_v3.1\\\\FVS\"\n\n# Test\n\nname &lt;- str_c(\"regen_\", \n              strftime(Sys.Date(),\"%m%d%y\"), \n              \"_\", \n              strftime(Sys.time(),\"%H%M\"))\n\n\n## Set the path to the stand input database here, aka the output db from 3_CNs_to_FVS:\ninputDatabase &lt;- 'C:/RxFire/Regen/Mar24_Regen_FVS.db'\n# C:\\\\RxFire\\\\Data\\\\FIADB_WA.db\n# C:\\\\RxFire\\\\Regen\\\\FVS\\\\Feb6_Regen_FVS_1.db\n# C:\\\\RxFire\\\\Regen\\\\Feb7_Regen_FVS_1.db\n\n# 1.2 Standlist from xlsx -------------------------------------------------\n\nstandlist &lt;- read_csv(\"C:/RxFire/Regen/Regen_Notes/standlist03242024.csv\", \n                      col_types = c(\"cccc\")) |&gt; select(\n                        CN = STANDPLOT_CN, FVSVariant = VARIANT\n                      ) \n\n# This is to speed up the testing\n# standlist &lt;- standlist[1:1000, ]\n\n\n\n# 2. Batch file Creation -----------------------------------------------------\n## Run everything in section 2. There shouldn't be anything to change.\n#  Except, maybe createInputFile(group_stands$CN[s], if CN was read in as Stand_CN. \n\n\nint &lt;- Sys.time()\n\n# Create directory where FVS runs will be sent:\nRunDirectory &lt;- str_c(fvs_wd, '/', name)\n\nif (!dir.exists(RunDirectory)) {\n  print(paste(\"Making Run directory: \", RunDirectory))\n  dir.create(RunDirectory)\n} else(\n  print(str_c(RunDirectory, \", already exists\"))\n)\n\n# Create input Directory\ninputDirectory &lt;- str_c(RunDirectory, \"/In\")\n\nif (!dir.exists(inputDirectory)) {\n  print(paste(\"Making input directory: \", inputDirectory))\n  dir.create(inputDirectory)\n} else(\n  print(str_c(inputDirectory, \", already exists\"))\n)\n\n# Create Cmd Directory\nCmdDirectory &lt;- str_c(RunDirectory, \"/Cmd\")\n\nif (!dir.exists(CmdDirectory)) {\n  print(paste(\"Making input directory: \", CmdDirectory))\n  dir.create(CmdDirectory)\n} else(\n  print(str_c(CmdDirectory, \", already exists\"))\n)\n\n## The path to the FVS output database is set here:\noutputDatabase &lt;- str_c(RunDirectory, \"/\", name, \".db\")\n\n\n\n## This function creates the string for a single stand in FVS.\ncreateInputFile &lt;- function(stand, managementID, inputDatabase, outputDatabase){\n  # Create .key file\n  input &lt;- paste0('STDIDENT\\n',                     \n                  stand, '\\n',                     \n                  'STANDCN\\n',                     \n                  stand, '\\n',                     \n                  'MGMTID\\n',                     \n                  managementID,                     \n                  '\\n',                             \n                  'NUMCYCLE          1\\n', # Set time intervals. \n                  # 0 = Change all cycles | Cycle length to one year\n                  'TIMEINT           0         1\\n',\n                  'SCREEN\\n',               \n                  'DATABASE\\n',                                                                                     # Databases in    \n                  'DSNIN\\n',                                                \n                  inputDatabase, '\\n',                                        \n                  'StandSQL\\n',                                             \n                  'SELECT * FROM FVS_PLOTINIT_PLOT\\n',\n                  # 'SELECT * FROM FVS_PlotInit\\n',  # For a different table name                   \n                  \"WHERE  Standplot_CN  = '%stand_cn%'\\n\",                     \n                  'EndSQL\\n',                                                    \n                  'DSNIN\\n',                                          \n                  inputDatabase, '\\n',                                             \n                  'TreeSQL\\n',\n                  'SELECT * FROM FVS_TREEINIT_PLOT\\n',\n                  # 'SELECT * FROM FVS_TreeInit\\n',                              \n                  \"WHERE  Standplot_CN  = '%stand_cn%'\\n\",                            \n                  'EndSQL\\n',                                                          \n                  'END\\n',   # Database ends here\n                  'STRCLASS\\n',\n                  # year of compute 0 = Every cycle\n                  'COMPUTE           0\\n',                                                                        # Compute below here\n                  # # acancov defined when str_class is used, after thin Canopy\n                  'CC = bcancov\\n',\n                  'END\\n',                                                                                            # Compute ends\n                  'DATABASE\\n',                                                                                     # DB Out Starts\n                  'DSNOUT\\n',                                      \n                  outputDatabase, '\\n',\n                  'SUMMARY           2\\n',\n                  'StrClsDB\\n',\n                  'COMPUTDB\\n',\n                  'END\\n',\n                  'Process\\n\\n')                                    \n                   \n  \n}\n\nwrite(str_c(\"set RScript=\", \" \\\"\", \"C:/Program Files/R/R-4.3.1/bin/Rscript.exe\", \"\\\"\",\n            \"\\n \\n\",\n            \"cd \", inputDirectory, \"\\n\\n\"), paste0(RunDirectory, '\\\\test.bat'), append = \"TRUE\")\n\n\n\nfor (g in unique(standlist$FVSVariant)) {\n  masterkeys &lt;- NULL\n  group_stands &lt;- subset(standlist, FVSVariant == g)\n  for (s in 1:nrow(group_stands)) {\n    \n    keywords &lt;- createInputFile(stand = group_stands$CN[s], managementID = group_stands$CN[s], \n                                inputDatabase = inputDatabase,\n                                outputDatabase = outputDatabase\n                                )\n    \n    masterkeys &lt;- paste0(masterkeys, keywords)\n  }\n  # Print to the key file\n  masterkeys &lt;- paste0(masterkeys, \"\\nSTOP\\n\")\n  # \"\\n STOP?\\n\" or \"\\nSTOP\\n\", outfile has errors 1 & 2, invalid keyword & no Stop\n  file_name &lt;- str_sub(g, end = -5)\n  write(masterkeys, file = str_c(inputDirectory, '\\\\', g, '.key'))\n  \n  ## Create the .in file ##\n  fvs_in &lt;- paste0(g, \".key\\n\",\n                   g, \".fvs\\n\",\n                   g, \".out\\n\",\n                   g, \".trl\\n\",\n                   g, \".sum\\n\")\n  \n  fvs_in_file &lt;- paste0(inputDirectory, '\\\\', g, '.in')\n  write(fvs_in, file = fvs_in_file)\n  fvs_bat &lt;- paste0(FVSbin, unique(group_stands$FVSVariant), \".exe &lt; \", g, \".in &gt;\",\n                    RunDirectory, \"/Cmd/\", g, \".txt\", \" 2&gt;&1\", \"\\n\",\n                    # Send each CMD file to this script\n                    \"%RScript%\",\" C:/RxFire/Scripts/ErrorProcessing/RcmdProcess.R \",\n                    \"\\\"\", RunDirectory, \"/Cmd/\", g, \".txt\", \"\\\"\", \"\\n\")\n  \n  write(fvs_bat, paste0(RunDirectory, '\\\\test.bat'), append = \"TRUE\")\n}\n\n# Summarize the OUT files\nfvs_errors &lt;- str_c(\"\\nREM This one cleans in extra files out and summarizes the output the Run Directory \\n\",\n                    \"%RScript%\",\" C:/RxFire/Scripts/ErrorProcessing/RfvsProcess.R \",\n                    \"\\\"\", RunDirectory, \"/In\", \"\\\"\")\n\nwrite(fvs_errors, paste0(RunDirectory, '\\\\test.bat'), append = \"TRUE\")\n\n# write(\"PAUSE\", paste0(inputDirectory, '\\\\test.bat'), append = \"TRUE\")\n\nout &lt;- Sys.time()\n\nprint(out - int)\n\n# Run this Batch file\nshell.exec(str_c(RunDirectory, '\\\\test.bat'))"
  },
  {
    "objectID": "1_Copied_Code.html#imputation-prep",
    "href": "1_Copied_Code.html#imputation-prep",
    "title": "Plot Selection",
    "section": "Imputation Prep",
    "text": "Imputation Prep\nPull the FVS output and organize the data.\n\nlibrary(tidyverse, quietly = T)\nlibrary(esquisse)\nlibrary(yaImpute)\nlibrary(RSQLite)\nlibrary(vegan)\nlibrary(randomForest)\nlibrary(RSQLite)\n\noptions(scipen = 999)\n\nSet k for knn. Get the compute and summary tables from the fvs run. Get the tree and plots tables from fvs_ready. Also adding the cond table for troubleshooting.\n\nk = 10\n\n\n# Pulling my list of subplots with FPAGs that I used in FVS\n# \"C:\\RxFire\\Regen\\Regen_Notes\\standlist03242024.csv\"\n# getwd()\nstandlist &lt;- read_csv(\"standlist03242024.csv\", \n                      col_types = c(\"cccc\")) \n\n\n## The FVS variables DB I created earlier by running these plots in FVS\n## and extracting the first years estimates of CC, BA, & SDI\n# \"C:/RxFire/Regen/FVS/regen_020724_4n/regen_020724_4n.db\"\n# \"C:\\RxFire\\Regen\\FVS\\regen_032524_0919\\regen_032524_0919.db\"\ncon &lt;- dbConnect(\n  RSQLite::SQLite(), \"C:/RxFire/Regen/FVS/regen_032524_0919/regen_032524_0919.db\"\n  )\n\n# Compute has CC\n# Summary2 has BA and SDI\ncomp &lt;- dbGetQuery(con, \"select CaseID, StandID, CC from FVS_Compute\")\nsummary &lt;- dbGetQuery(\n  con, \n  str_c(\"select CaseID, StandID, Tpa, BA, SDI from FVS_Summary2\",\n        \" where Year = 2020\")\n  )\n\npred &lt;- left_join(comp, summary, join_by(CaseID, StandID))\n\ndbDisconnect(con)\n\n# rm(comp, summary, con)\n\n# making a list for sql\ndb_list &lt;- function(df, CN_col){\n  name &lt;- NULL\n  name &lt;- df |&gt; select({{CN_col}})\n  name &lt;- name |&gt; mutate(CN_col = str_c(\"'\", {{CN_col}}, \"'\")) \n  name &lt;- str_flatten_comma(name$CN_col)\n  # name &lt;- str_flatten_comma(name[, CN_col])\n  name\n}\nstplt_cn &lt;- db_list(df = pred, CN_col = StandID)\n\n\n# connecting to the WA state FIA db\ncon &lt;- dbConnect(RSQLite::SQLite(), \"C:/RxFire/Data/_FIADB_WA.db\")\n\n# collecting the trees\ntree &lt;- dbGetQuery(\n  con, \n  str_c(\"select * from FVS_TREEINIT_PLOT where STANDPLOT_CN in (\", \n        stplt_cn, \")\"))\n\n# collecting tne plots and subplots\nplot &lt;- dbGetQuery(\n  con, \n  str_c(\"select * from FVS_PLOTINIT_PLOT where STANDPLOT_CN in (\", \n        stplt_cn, \")\"))\n\n\n# cond &lt;- dbGetQuery(\n#   con, \n#   str_c(\"select * from cond where STANDPLOT_CN in (\", \n#         stplt_cn, \")\"))\n\ndbDisconnect(con)\n\nClean the tables.\n\n# Cleaning out the NA columns\nclean_na_cols &lt;- function(df){\n  df &lt;- df[, colSums(is.na(df)) &lt; nrow(df)]\n}\n\ntree &lt;- clean_na_cols(tree)\nplot &lt;- clean_na_cols(plot)\n\n# Cleaning out the useless columns\nplot &lt;- plot |&gt; select(-c(GROUPS, STAND_ID, STANDPLOT_ID, INV_DAY, INV_MONTH, \n                          REGION, FOREST, SAM_WT, PHYSIO_REGION, STATE, COUNTY))\n\ntree &lt;- tree |&gt; select(-c(STAND_ID, STANDPLOT_ID))\n\npred &lt;- pred |&gt; select(-c(CaseID, Tpa))\n\nSeedling densities are the trees per acre for each species’ seedlings. Adding the plant symbols for seedlings.\n\n# Separating the seedlings from the rest\nseedling_densities &lt;- tree |&gt;  filter(startsWith(TREE_CN, \"S\")) |&gt; \n  group_by(STANDPLOT_CN, SPECIES) |&gt; \n  summarise(TPA = sum(TREE_COUNT))\n\n`summarise()` has grouped output by 'STANDPLOT_CN'. You can override using the\n`.groups` argument.\n\ncon &lt;- dbConnect(\n  RSQLite::SQLite(), \"C:\\\\RxFire\\\\Data\\\\_FIADB_WA.db\"\n  )\n# Pulling in the species reference table\nplants_ref &lt;- dbGetQuery(\n  con, \"select SPECIES_SYMBOL, SPCD, COMMON_NAME, W_SPGRPCD from REF_SPECIES\"\n  )\nplant_gr_ref &lt;- dbGetQuery(\n  con, \"select SPGRPCD, NAME from REF_SPECIES_GROUP\"\n  )\ndbDisconnect(con)\n\n# Cleaning it up\nplants_ref &lt;- plants_ref |&gt; rename(SPGRPCD = W_SPGRPCD, SYMBL = SPECIES_SYMBOL)\nplants_ref &lt;- left_join(plants_ref, plant_gr_ref, by = join_by(SPGRPCD))\nplants &lt;- plants_ref |&gt; select(SYMBL, SPCD)\nseedling_densities &lt;- seedling_densities |&gt; mutate(SPECIES = as.numeric(SPECIES))\n\n# Getting plant codes for seedlings\nseedling_densities &lt;- left_join(seedling_densities, plants, join_by(\"SPECIES\" == \"SPCD\"))\n# Removing an extra col. \nseedling_densities &lt;- seedling_densities |&gt; select(-c(SPECIES))\n\nWidening the table to match the st Joe example. The value of each species TPA goes into a column for that species. Each row is a standplot_cn. If there were no species of a type in that stand, a zero is entered.\n\n# Matching the St. Joe data\nseedling_response &lt;- seedling_densities |&gt; pivot_wider(names_from = SYMBL, \n                 values_from = TPA,\n                 values_fill = 0,\n                 names_glue = \"{SYMBL}_{'TD'}\")\n\n\n# Un-grouping to avoid future messages\nseedling_response &lt;- seedling_response |&gt; ungroup()\nseedling_densities &lt;- seedling_densities |&gt; ungroup()\n\n\n\n\n# replacing all NAs with zero, just in case\nnas_to_zeroes &lt;- function(df){\n  df &lt;- df |&gt; mutate_all(~replace(., is.na(.), 0))\n  df\n}\nseedling_response &lt;- nas_to_zeroes(seedling_response) \n\n# clearing out the objects\nX_predictors &lt;- NULL\nY_response &lt;- NULL\n# creating lists of subplots\nX_predictors &lt;- pred |&gt; select(STANDPLOT_CN = StandID) |&gt; unique()\nY_response &lt;- seedling_response |&gt; select(STANDPLOT_CN = STANDPLOT_CN)\n\nThere is a mismatch in dims between the predictors and response variables.\nX has about 25k rows and Y has about 13k. This is looking at all possible plots with the value computed from FVS, vs those plots with seedlings.\nIf I remove the extra 12k rows where no regeneration is occurring, that’s bad. If I don’t remove it, then I half of my data is zero.\nThe current plan is to use a couple models, one for probability of regeneration. one for regen with and one one without disturbance. From what I understand, the probability of regen model is for post disturbance. So, this is more of an ingrowth model. We need the zeroes and I don’t like that.\nThat is what I did last time, so at least the plots will be comparable.\nI think I can at least remove the subplots that are non-forested.\n\n# finding the mismatch \ntt &lt;- anti_join(X_predictors, Y_response, by = \"STANDPLOT_CN\")\n\nt &lt;- left_join(tt, tree, by = \"STANDPLOT_CN\")\n\nt2 &lt;- t |&gt; group_by(STANDPLOT_CN) |&gt; \n  summarize(seedling_records = sum(startsWith(TREE_CN, \"s\")),\n            lt_records = sum(!startsWith(TREE_CN, \"s\")))\n\nt3 &lt;- t2 |&gt; filter(is.na(seedling_records) & is.na(lt_records)) |&gt; \n  select(STANDPLOT_CN)\n\n\nt2 &lt;- t2 |&gt; filter(!is.na(lt_records) & !is.na(seedling_records))\n\nOf those records where there is no regen, 12k at least had large trees. 1k had neither seedlings of large trees.\nI tried to find out why there were no trees on those subplots, but I couldn’t:\n# t3 &lt;- left_join(t3, plot, by = \"STANDPLOT_CN\")\n# \n# standlist &lt;- t3 |&gt; select(STAND_CN)\n# standcn &lt;- db_list(standlist, STAND_CN)\n# \n# con &lt;- dbConnect(RSQLite::SQLite(), \"C:/RxFire/Data/_FIADB_WA.db\")\n# \n# cond &lt;- dbGetQuery(\n#   con, \n#   str_c(\"select * from cond where PLT_CN in (\", \n#         standcn, \")\"))\n# \n# dbDisconnect(con)\n# \n# cond &lt;- clean_na_cols(cond)\n# \n# \n# cond_status_cd &lt;- cond |&gt; \n#   filter(COND_STATUS_CD == 1 | COND_STATUS_CD == 2 )\n# \n# # hist(cond_status_cd$OWNGRPCD)\n# \n# # Fire damage. \n# hist(cond_status_cd[cond_status_cd$DSTRBCD1 &gt; 29 & \n#                       cond_status_cd$DSTRBCD1 &lt; 40, \n#                     \"DSTRBCD1\"])\n# \n# cond_presnfcd &lt;- cond_status_cd |&gt; \n#   filter(is.na(PRESNFCD)) |&gt; clean_na_cols()\n# \n# cond_presnfcd &lt;- cond_presnfcd |&gt; \n#   select(-c(STATECD, INVYR, CN, COUNTYCD, PLOT,\n#             MAPDEN, PROP_BASIS, SLOPE, ASPECT, DSTRBYR1, DSTRBYR2, DSTRBYR3))\n# \n# # names(cond_presnfcd)\n# \n# cond_presnfcd &lt;- cond_presnfcd |&gt; \n#   select(-c(CREATED_BY, CREATED_DATE, CREATED_IN_INSTANCE, MODIFIED_BY, MODIFIED_DATE, MODIFIED_IN_INSTANCE))\n# \n# cond_presnfcd2 &lt;- cond_presnfcd[, c(1, 49:ncol(cond_presnfcd))]\n# \n# # summary(as.factor(cond_presnfcd$STUMP_CD_PNWRS))\n# \n# # hist(cond_presnfcd$BALIVE)\nThere are standplot_cns that do not have trees. I am not sure if I should count them. They might be NAs.\nLooking at an example:\n\nThe subplot table says they are all the same.\nThe Cond table doesn’t make distinctions for Subplots.\nThere are tree records in the the other three plots.\n\nI am not sure what to do. There are some codes that should be controlled for, but I cannot get rid of all of them. Some of the codes that should be controlled for were probably brought in with the cond table, I couldn’t use standplot_cn. So it pulled in every condition.\nI found this field and it could be of use:\nPHYSCLCD Physiographic class code. A code indicating the general effect of land form, topographical position, and soil on moisture available to trees.\n\nRemoving the no tree plots.\n\nx &lt;- anti_join(X_predictors, t3, by = \"STANDPLOT_CN\")\nnrow(X_predictors) - nrow(x)\n\n[1] 895\n\nX_predictors &lt;- left_join(x, X_predictors, by = \"STANDPLOT_CN\")\n\n\n# Adding the plots without regen. \nimp_response &lt;- left_join(X_predictors, seedling_response, join_by(STANDPLOT_CN))\n\n# removing the NAs\nimp_response &lt;- nas_to_zeroes(imp_response) \n# imp_data &lt;- imp_data[,1:35]\n\n# removing fields from standlist to join\nFPAG &lt;- standlist |&gt; select(STANDPLOT_CN, FPAG)\n# renaming the field\npred &lt;- pred |&gt; rename(STANDPLOT_CN = StandID)\n\npred &lt;- left_join(x, pred, by = \"STANDPLOT_CN\")\n# joining fpags to prediction list. \nimp_pred &lt;- left_join(pred, FPAG, by = \"STANDPLOT_CN\")\n\nimp_data &lt;- left_join(imp_pred, imp_response, by = \"STANDPLOT_CN\")\n\nMaking a set for the zeroes just in case.\n\nzx &lt;- Y_response |&gt; select(STANDPLOT_CN)\n# Adding the plots without regen. \nzimp_response &lt;- left_join(zx, seedling_response, join_by(STANDPLOT_CN))\n\n# removing the NAs\nzimp_response &lt;- nas_to_zeroes(zimp_response) \n\nzpred &lt;- left_join(zx, pred, by = \"STANDPLOT_CN\")\n# joining fpags to prediction list. \nzimp_pred &lt;- left_join(zpred, FPAG, by = \"STANDPLOT_CN\")\n\nzimp_data &lt;- left_join(zimp_pred, zimp_response, by = \"STANDPLOT_CN\")\n\nCleaning up the other tables\n\ntree &lt;- left_join(x, tree, by = \"STANDPLOT_CN\")\nplot &lt;- left_join(x, plot, by = \"STANDPLOT_CN\")\n\n\n# removing extra objects\nrm(con, X_predictors, Y_response, stplt_cn, t, plant_gr_ref, \n   plants, standlist, FPAG, pred)\n\n\nname &lt;- str_c(\"attempt_\", \n              strftime(Sys.Date(),\"%m%d%y\"))\n              # , \n              # \"_\"\n              # , \n              # strftime(Sys.Date(),\"%H%M\"))\n\n# con &lt;- dbConnect(RSQLite::SQLite(), str_c(\"./\", name, \".db\"))\n# dbWriteTable(con, \"imp_data\", imp_data)\n# dbWriteTable(con, \"plants_ref\", plants_ref)\n# dbWriteTable(con, \"FVS_PLOTINIT_PLOT\", plot)\n# dbWriteTable(con, \"FVS_TREEINIT_PLOT\", tree)\n# dbWriteTable(con, \"regen_only_imp_data\", zimp_data)\n# \n# dbDisconnect(con)\n\nkeep &lt;- c(\"clean_na_cols\", \"db_list\", \"nas_to_zeroes\", \"z_scores\", \"k\")\n# rm(list = ls()[!(ls() %in% keep)])"
  },
  {
    "objectID": "0_Scratch.html",
    "href": "0_Scratch.html",
    "title": "Scratch",
    "section": "",
    "text": "# refs &lt;- rownames(t2[1:(3*nrow(t2)/4),])\n# \n# x &lt;- t2 |&gt; select(1:6)\n# x &lt;- remove_rownames(x)\n# x &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n# \n# yfull &lt;- t2 |&gt; select(1, 8:ncol(t2))\n# y &lt;- yfull[refs,]\n# y &lt;- remove_rownames(y)\n# y &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\n# yfull &lt;- remove_rownames(yfull)\n# yfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n# \n# k = 10\n# \n# yrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n# \n# names(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n# # rf_phys &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n# \n# \n# # save(rf_phys, file = \"rf_phys.Rdata\")\n# \n# load(\"rf_phys.Rdata\")\n# load(\"trf.Rdata\")\n# \n# trf_i &lt;- impute(trf, ancillaryData = y)\n# rf_phys_i &lt;- impute(rf_phys, ancillaryData = y)"
  },
  {
    "objectID": "0_Scratch.html#non-fvs-variables",
    "href": "0_Scratch.html#non-fvs-variables",
    "title": "Scratch",
    "section": "Non-FVS variables",
    "text": "Non-FVS variables\nI was trying to get the Kralicek variables from FIA while FVS was running on the expanded dataset. It took FVS a while to run the 26k subplots, at least 25min.\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"C:/RxFire/Data/_FIADB_WA.db\")\n\nstandlist &lt;- read_csv(\"C:/RxFire/Regen/Regen_Notes/standlist03242024.csv\", \n                      col_types = c(\"cccc\")) \n\nn_distinct(standlist$STAND_CN)\n\nSTAND_CN &lt;- NULL\nSTAND_CN &lt;- str_c(\"'\", unique(standlist$STAND_CN), \"'\")\nSTAND_CN &lt;- str_flatten_comma(STAND_CN)\n\n# COND::BALIVE Basal area per acre of livetrees\nsubcond &lt;- dbGetQuery(con, str_c(\n  \"select * from subp_cond where PLT_CN IN (\", STAND_CN, \")\"))\ncond &lt;- dbGetQuery(con, str_c(\n  \"select * from cond where PLT_CN IN (\", STAND_CN, \")\"))\n\n# P2VEG_STR::COVER_PCT, NT AND TT ARE TREES. \nveg &lt;- dbGetQuery(con, str_c(\n  \"select * from P2VEG_SUBP_STRUCTURE where PLT_CN IN (\", STAND_CN, \")\"))\n\ntree &lt;- dbGetQuery(con, str_c(\n  \"select * from FVS_TREEINIT_PLOT where STAND_CN IN (\", STAND_CN, \")\"))\n\nsubcond &lt;- subcond |&gt; \n  mutate(\n    STANDPLOT_CN = str_c(as.character(PLT_CN), \"_\", as.character(SUBP))\n  )\ns &lt;- subcond |&gt; select(PLT_CN, STANDPLOT_CN, SUBP, CONDID, )\n\nc &lt;- left_join(s, cond, join_by(PLT_CN, CONDID))\nc2 &lt;- c |&gt; select(STANDPLOT_CN, BALIVE) |&gt; drop_na()\n\nveg &lt;- veg |&gt; \n  mutate(\n    STANDPLOT_CN = str_c(as.character(PLT_CN), \"_\", as.character(SUBP))\n  )\n\n\nv &lt;- veg |&gt; filter(LAYER == 5)\nv &lt;- v |&gt; filter(GROWTH_HABIT_CD == \"TT\")\n\nv2 &lt;- v |&gt; group_by(STANDPLOT_CN) |&gt; \n  summarise(CC = sum(COVER_PCT))\n\np. 183 FVS essentials.\n\\[\nSDI = \\sum (TPA_i (\\frac{DBH}{10})^{1.605})\n\\] TPA_i is tpa for a tree record.\nSDI is the sum of Trees per acre times the DBH for those trees, divided by ten to the power of 1.605.\nDBH and tpa are in the tree table.\n\nx &lt;- standlist |&gt; select(STANDPLOT_CN)\n\nt &lt;- left_join(x, tree, by = \"STANDPLOT_CN\")\nc &lt;- left_join(x, cond, by = \"STANDPLOT_CN\")\nv &lt;- left_join(x, veg, by = \"STANDPLOT_CN\")\n\ntpa &lt;- t |&gt; \n  mutate(sdi = (TREE_COUNT * ((DIAMETER/10)^1.605)))\n\nsdi &lt;- tpa[tpa$HISTORY == 1, ] |&gt; group_by(STANDPLOT_CN) |&gt; \n  summarize(SDI = sum(sdi)) |&gt; drop_na()\n\n\ny &lt;- left_join(x, sdi, by = \"STANDPLOT_CN\")\n\ny &lt;- left_join(y, c2, by = \"STANDPLOT_CN\")\n\ny &lt;- left_join(y, v2, by = \"STANDPLOT_CN\")\n\nCanopy cover is not well predicted by the p2veg tables.\n\nend\nThese are plots looking at the distrubution of PSME. I made them while taking notes to understand the distrubutions and try to figure out a reasonable diffrence between NNs.\n\nimp_zx$PSME_TD |&gt; mean()\nimp_zx$PSME_TD |&gt; sd()\n\nhist(imp_zx[imp_zx$PSME_TD &gt; 0, \"PSME_TD\"], breaks = 500)\n\nhist(imp_zx[imp_zx$PSME_TD &gt; 0, \"PSME_TD\"], breaks = 500,\n     xlim = c(0, 5000), \n     ylim = c(0, 500))\n\nhist(imp_zx[imp_zx$PSME_TD &gt; 0, \"PSME_TD\"], breaks = 500,\n     xlim = c(0, 5000), \n     ylim = c(0, 50))\n\nhist(log(imp_zx[imp_zx$PSME_TD &gt; 0, \"PSME_TD\"]), breaks = 50)\n\n\nhist(imp_zx[imp_zx$PSME_TD &lt; 74, \"PSME_TD\"], breaks = 5, xlim = c(0,1))\nhist(imp_zx[imp_zx$PSME_TD &gt; 0 & imp_zx$PSME_TD &lt; 1000, \"PSME_TD\"], breaks = 100, xlim = c(0,1000))\nhist(imp_zx[imp_zx$PSME_TD &gt; 1000 & imp_zx$PSME_TD &lt; 5000, \"PSME_TD\"], breaks = 100, xlim = c(1000,5000))\n\nTrying something to make more sense of the FVS_ready counts.\n\nb &lt;- imp_zx |&gt; select(STANDPLOT_CN, PSME_TD, total_TD)\nb &lt;- b |&gt; filter(PSME_TD &gt; 0 )\nb &lt;- b |&gt; mutate(PSME = PSME_TD / 74.96528, \n                 total = total_TD / 74.96528,\n                 log_psme = log(PSME_TD))\n\nsummary(b$PSME)\nhist(b$PSME, breaks = 202)\nsummary(b$log_psme)\nhist(b$log_psme)\nhist(log(b$PSME))\n\nplot(density(log(b$PSME)))\nplot(density(b$log_psme))\nplot(b$log_psme)\n\n\na &lt;- imp_zx |&gt; filter(\n  total_TD &gt; 0\n)\nmean(a$PSME_TD)\n\n\nplot(a$SDI, a$total_TD)\nplot(a$SDI, log(a$total_TD))\nplot(a$CC, a$total_TD)\nplot(a$BA, a$total_TD)\n\nplot(sort(a$total_TD))\nplot(log(sort(a$total_TD)))\n\nplot(log(sort(imp_zx[imp_zx$PSME_TD&gt;0, \"PSME_TD\"])))\n\n\n# a &lt;- a |&gt; mutate(total = total_TD/ 74.96528,\n#                  log_tot = log(total))\n# # library(fsbrain)\n# a3 &lt;- clip.data(a$total_TD, lower =  0.05, upper = 0.95)\n\na3 &lt;- a |&gt; filter(total_TD &lt;= quantile(total_TD, 0.95))\na3 &lt;- a3 |&gt; filter(total_TD &gt;= quantile(total_TD, .05))\na3 &lt;- a3 |&gt; arrange(desc(total_TD)) |&gt; mutate(row = row_number())\n\nplot(a3$row, a3$total_TD )\n\nplot(density(a3$total_TD |&gt; log()))\nabline(v = log(mean(a3$total_TD)), col = \"red\")\n\n\nhist(a$total, breaks = 100, \n     xlim = c(0,100),\n     ylim = c(0, 50))\n\nmean(a3$total_TD)\nsd(a3$total_TD)\n\n\nidk &lt;- rexp(12709, .0021)\nplot(idk)\n\nplot(density(log(idk)))\nplot(density(log(fpas$total_TD)))\n\n\n\nplot(density(rexp(12709, .0021)),\n     xlim = c(0,40000),\n     ylim = c(0,.002))\n\nplot(density(fpas$total_TD),\n     xlim = c(0,40000),\n     ylim = c(0,.002))"
  },
  {
    "objectID": "2_Imputation.html",
    "href": "2_Imputation.html",
    "title": "Imputation",
    "section": "",
    "text": "First set\n\nFirst set is a repeat of the first imputation I did. This one is using the full set of CNs. That is, it contains all the stands that are in ecoregions associated with the study area.\nIt is comparing the Kralicek three predictors vs the set that contains elevation, aspect, and slope as well. The z variables indicate that the data set only contains plots that have seedlings. There are less zeroes in that set. The full set is about half zeroes.\nThis set has the msn and mal distance plots, but not RF.\n\nSet 2\n\nAdding in Random Forests, broadening FPAG to fpa by removing one digit from the Ecoregion code. Organizing the response by species prevalence. Prevalent species are those that have records starting between the 75 percentile and the 90th. It is all zeroes before that. Common species start between the 90th and 97.5. Uncommon species start to have records between 97.5 and 99. Rare after 99.\n\nThe same RF and other distance measures, but on a dataset containing only plots with regeneration.\n\nResults were mixed. It looks like is does a better job of imputing, but the rmsd is higher. It seems like rmsd would be lower in the full set since imputing zero would be right half the time.\nPrevalent species are\n\n\n\nSYMBL\nName\n\n\n\n\nPSME\nDoug-fir\n\n\nABAM\nsilver fir\n\n\nABLA\nsubalpine fir\n\n\nTSHE\nwestern hemlock\n\n\n\nCommon species are:\n\n\n\nSYMBL\nName\n\n\n\n\nPIPO\nPonderosa pine\n\n\nTSME\nMountain Hemlock\n\n\nABGR\nGrand Fir\n\n\nTHPL\nRed Cedar\n\n\nPIEN\nEngelmann spruce\n\n\nPICO\nLodgepole pine\n\n\nPIMO3\nW. White Pine\n\n\n\nUncommon species are:\n\n\n\nSYMBL\nName\n\n\n\n\nPIAL\nwhitebark pine\n\n\nACGL\nRocky Mountain maple\n\n\nLAOC\nwestern larch\n\n\nTABR2\nPacific yew\n\n\nCHNO\nAlaska yellow-cedar\n\n\nPOTR5\nquaking aspen\n\n\n\n\nlibrary(tidyverse, quietly = T)\nlibrary(esquisse)\nlibrary(yaImpute)\nlibrary(RSQLite)\nlibrary(vegan)\nlibrary(randomForest)\nlibrary(RSQLite)\n\noptions(scipen = 999)"
  },
  {
    "objectID": "2_Imputation.html#summary",
    "href": "2_Imputation.html#summary",
    "title": "Imputation",
    "section": "",
    "text": "First set\n\nFirst set is a repeat of the first imputation I did. This one is using the full set of CNs. That is, it contains all the stands that are in ecoregions associated with the study area.\nIt is comparing the Kralicek three predictors vs the set that contains elevation, aspect, and slope as well. The z variables indicate that the data set only contains plots that have seedlings. There are less zeroes in that set. The full set is about half zeroes.\nThis set has the msn and mal distance plots, but not RF.\n\nSet 2\n\nAdding in Random Forests, broadening FPAG to fpa by removing one digit from the Ecoregion code. Organizing the response by species prevalence. Prevalent species are those that have records starting between the 75 percentile and the 90th. It is all zeroes before that. Common species start between the 90th and 97.5. Uncommon species start to have records between 97.5 and 99. Rare after 99.\n\nThe same RF and other distance measures, but on a dataset containing only plots with regeneration.\n\nResults were mixed. It looks like is does a better job of imputing, but the rmsd is higher. It seems like rmsd would be lower in the full set since imputing zero would be right half the time.\nPrevalent species are\n\n\n\nSYMBL\nName\n\n\n\n\nPSME\nDoug-fir\n\n\nABAM\nsilver fir\n\n\nABLA\nsubalpine fir\n\n\nTSHE\nwestern hemlock\n\n\n\nCommon species are:\n\n\n\nSYMBL\nName\n\n\n\n\nPIPO\nPonderosa pine\n\n\nTSME\nMountain Hemlock\n\n\nABGR\nGrand Fir\n\n\nTHPL\nRed Cedar\n\n\nPIEN\nEngelmann spruce\n\n\nPICO\nLodgepole pine\n\n\nPIMO3\nW. White Pine\n\n\n\nUncommon species are:\n\n\n\nSYMBL\nName\n\n\n\n\nPIAL\nwhitebark pine\n\n\nACGL\nRocky Mountain maple\n\n\nLAOC\nwestern larch\n\n\nTABR2\nPacific yew\n\n\nCHNO\nAlaska yellow-cedar\n\n\nPOTR5\nquaking aspen\n\n\n\n\nlibrary(tidyverse, quietly = T)\nlibrary(esquisse)\nlibrary(yaImpute)\nlibrary(RSQLite)\nlibrary(vegan)\nlibrary(randomForest)\nlibrary(RSQLite)\n\noptions(scipen = 999)"
  },
  {
    "objectID": "2_Imputation.html#set-1-3-vs-6-full-set-vs-regen-only",
    "href": "2_Imputation.html#set-1-3-vs-6-full-set-vs-regen-only",
    "title": "Imputation",
    "section": "Set 1, 3 vs 6, full set vs regen only",
    "text": "Set 1, 3 vs 6, full set vs regen only\nThis is a repeat of the first comparison I did. I am using the expanded dataset for this run, but for CDS6, it is only about 400 extra plots.\nThis time around, I saved a dataset where I only kept plots/stands that had regeneration/seedlings. So I changed it a little to compare three and six predictor variable models while also seeing what happens without so many zeroes.\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n\npred_topo &lt;- plots |&gt; select(\n  STANDPLOT_CN, ELEVFT, SLOPE, ASPECT\n)\npred_Kral &lt;- imp_data |&gt; select(\n  STANDPLOT_CN, CC, BA, SDI, FPAG\n)\n\nresponse &lt;- imp_data |&gt; select(\n  -c(CC, BA, SDI, FPAG)\n)\n\npredictors &lt;- left_join(pred_Kral, pred_topo)|&gt; \n  relocate(FPAG, .after = STANDPLOT_CN)\n\n\n# Filtering for only CDS6\ncds6 &lt;- predictors |&gt; filter(\n  FPAG == \"CDS6\") |&gt; \n  select(-c(FPAG))\n\n\ncds_cns &lt;- cds6 |&gt; select(STANDPLOT_CN)\nzcds_cns &lt;- zimp_data |&gt; filter(FPAG == \"CDS6\") |&gt; select(STANDPLOT_CN)\nzcds6 &lt;- left_join(zcds_cns, cds6, by =\"STANDPLOT_CN\")\n\n# Joining the x and y\nimp_2 &lt;- left_join(cds_cns, response, by = \"STANDPLOT_CN\")\n# Making CN into rownames\nimp_2 &lt;- column_to_rownames(imp_2, \"STANDPLOT_CN\")\n# making sure it's not all zero\nimp_2 &lt;- imp_2[, !colSums(imp_2) == 0]\n\nimp_2 &lt;- left_join(cds6, response)\nzimp_2 &lt;- left_join(zcds6, response)\n\n\n# form some test data, y's are defined only for reference observations.\n# refs  =  sample(x  =  rownames(imp_2), size  =  (nrow(imp_2)/4)*3)\nrefs &lt;- rownames(imp_2[1:(round(.75*nrow(imp_2))), ])\n# zrefs  =  sample(x  =  rownames(zimp_2), size  =  (nrow(zimp_2)/4)*3)\nzrefs &lt;- rownames(zimp_2[1:(round(.75*nrow(zimp_2))), ])\n\n# x is every row and column of predictor variables.\n# CC, BA, SDI, ELEVFT, SLOPE, ASPECT\nX_predictors1 &lt;- imp_2 |&gt; select(CC, BA, SDI)\nX_predictors2 &lt;- imp_2 |&gt; select(CC, BA, SDI, ELEVFT, SLOPE, ASPECT)\nzX_predictors1 &lt;- zimp_2 |&gt; select(CC, BA, SDI)\nzX_predictors2 &lt;- zimp_2 |&gt; select(CC, BA, SDI, ELEVFT, SLOPE, ASPECT)\n\n# y is all other columns, seedling tree densities. \n# row names are row numbers\n# y &lt;- imp_df[refs,3:36], this was the example code. \nY_response &lt;- imp_2[refs,] |&gt; select(ends_with(\"TD\")) \nY_response &lt;- Y_response[, order(colSums(-Y_response))]\n\nzY_response &lt;- zimp_2[zrefs,] |&gt; select(ends_with(\"TD\")) \nzY_response &lt;- zY_response[, order(colSums(-zY_response))]\n\n# remove zero columns\nY_response &lt;- Y_response[, !colSums(Y_response) == 0]\nzY_response &lt;- zY_response[, !colSums(zY_response) == 0]\n\n\nk = 10\n\n# build yai objects using\n# most similar neighbor\nmsn_dist_3 &lt;- yai(x = X_predictors1, y = Y_response, method = \"msn\", k = k)\n# and mahalanobis\nmal_dist_3 &lt;- yai(x = X_predictors1, y = Y_response, method = \"mahalanobis\", k = k)\n\n# For the expanded list of predictors\nmsn_dist_6 &lt;- yai(x = X_predictors2, y = Y_response, method = \"msn\", k = k)\n# and mahalanobis\nmal_dist_6 &lt;- yai(x = X_predictors2, y = Y_response, method = \"mahalanobis\", k = k)\n\n# Small predictors but standarcized\nzmsn_dist_3 &lt;- yai(x = zX_predictors1, y = zY_response, method = \"msn\", k = k)\n# and mahalanobis\nzmal_dist_3 &lt;- yai(x = zX_predictors1, y = zY_response, method = \"mahalanobis\", k = k)\n\n# Standardized expanded\nzmsn_dist_6 &lt;- yai(x = zX_predictors2, y = zY_response, method = \"msn\", k = k)\n# and mahalanobis\nzmal_dist_6 &lt;- yai(x = zX_predictors2, y = zY_response, method = \"mahalanobis\", k = k)\n\n\nimputed_msn_dist_3 &lt;- impute(msn_dist_3)\n# imputed_mal_dist_1 &lt;- impute(mal_dist_1)\nimputed_msn_dist_6 &lt;- impute(msn_dist_6)\n# imputed_mal_dist_2 &lt;- impute(mal_dist_2)\nimputed_zmsn_dist_3 &lt;- impute(zmsn_dist_3)\n# imputed_zmal_dist_1 &lt;- impute(zmal_dist_1)\nimputed_zmsn_dist_6 &lt;- impute(zmsn_dist_6)\n# imputed_zmal_dist_2 &lt;- impute(zmal_dist_2)\n\nnames &lt;- c('PSME_TD', 'PICO_TD', 'PIPO_TD', 'PRVI_TD', 'ABGR_TD', 'PREM_TD', \n           'PSME_TD.o', 'PICO_TD.o', 'PIPO_TD.o', 'PRVI_TD.o', 'ABGR_TD.o', 'PREM_TD.o')\n\nimp_msn_dist_3 &lt;- imputed_msn_dist_3[, names(imputed_msn_dist_3) %in% names] |&gt; \n  filter(PSME_TD &lt; 15000 & PSME_TD.o &lt; 15000)\nimp_msn_dist_6 &lt;- imputed_msn_dist_6[, names(imputed_msn_dist_6) %in% names] |&gt; \n  filter(PSME_TD &lt; 15000 & PSME_TD.o &lt; 15000)\nzimp_msn_dist_3 &lt;- imputed_zmsn_dist_3[, names(imputed_zmsn_dist_3) %in% names] |&gt; \n  filter(PSME_TD &lt; 15000 & PSME_TD.o &lt; 15000)\nzimp_msn_dist_6 &lt;- imputed_zmsn_dist_6[, names(imputed_zmsn_dist_6) %in% names] |&gt; \n  filter(PSME_TD &lt; 15000 & PSME_TD.o &lt; 15000)\n\n\nPlots, 3 vs 6 & Full vs Regen\nHere are imputed vs observed when using other the Kralicek 3 variables or adding elev, slope, and aspect for the 6 variable ones.\n\nplot(imp_msn_dist_3)\nplot(imp_msn_dist_6)\n\n\n\n\n\n\n\n\n\n\n\n\nHere are the three vs six variable plots, but this time, z is for zero. As in there are no zeroes in response variables. z means these are only for plots that have seedlings.\n\nplot(zimp_msn_dist_3)\nplot(zimp_msn_dist_6)\n\n\n\n\n\n\n\n\n\n\n\n\nThree variables, all plots vs seedling only plots/stands.\nThese have different labels. Prvi and Abgr are swapped.\n\nplot(imp_msn_dist_3)\nplot(zimp_msn_dist_3)\n\n\n\n\n\n\n\n\n\n\n\n\nSix variable plots, all stands vs seeldings only.\n\nplot(imp_msn_dist_6)\nplot(zimp_msn_dist_6)"
  },
  {
    "objectID": "2_Imputation.html#fpag-to-fpa",
    "href": "2_Imputation.html#fpag-to-fpa",
    "title": "Imputation",
    "section": "FPAG to fpa",
    "text": "FPAG to fpa\nI am skipping a set of imputations I did before, in attempt 4 fpag. That one was a failure because FPAG couldn’t be added to the distance matrix. I couldn’t use it with MSN, I don’t think I have tried to use it with RF yet.\nThis set of code is from CH 14 in the regen book.\n\nrm(list = ls())\n\nk = 10\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n\nimp_data_orig &lt;- imp_data\n\n# Grabbing the topography variables\npred_topo &lt;- plots |&gt; select(\n  STANDPLOT_CN, ELEVFT, SLOPE, ASPECT\n)\n# Get the Kralicek variables\npred_Kral &lt;- imp_data |&gt; select(\n  STANDPLOT_CN, CC, BA, SDI, FPAG\n)\n\n# remove the predictors from the response.\nresponse &lt;- imp_data |&gt; select(\n  -c(CC, BA, SDI, FPAG)\n)\n# join the Kralicek and topo variables. \npredictors &lt;- left_join(pred_Kral, pred_topo, join_by(STANDPLOT_CN))|&gt; \n  relocate(FPAG, .after = STANDPLOT_CN)\n\n\n\nunique(imp_data$FPAG)\n\n  [1] \"CWF4\" \"CDS6\" \"CDS2\" \"CAS3\" \"CDG1\" \"CMS3\" \"CWS5\" \"CHS1\" \"CES4\" \"CES2\"\n [11] \"CES1\" \"CAC1\" \"CPS2\" \"CDS7\" \"CPG1\" \"CEF2\" \"CPS5\" \"CES3\" \"CDS8\" \"CD\"  \n [21] \"CWG1\" \"CWS2\" \"CWF2\" \"CP\"   \"CF\"   \"CFF2\" \"CEG3\" \"CMS2\" \"CHF2\" \"CW\"  \n [31] \"HC\"   \"CC\"   \"CEF4\" \"CAG1\" \"CDG3\" \"CDS4\" \"CES\"  \"CFS5\" \"CEM2\" \"CHS4\"\n [41] \"CCS2\" \"CCF2\" \"CHF3\" \"CH\"   \"CWS4\" \"CFS6\" \"CFS2\" \"CFS4\" \"HO\"   \"CE\"  \n [51] \"CLS5\" \"CWS3\" \"CWS8\" \"CCS3\" \"HQS2\" \"CHS2\" \"CFS3\" \"CEF1\" \"CHF1\" \"CPG2\"\n [61] \"CMS1\" \"CFF1\" \"HOG2\" \"CWF3\" \"HOG1\" \"CMF1\" \"CMG2\" \"CEG1\" \"CDS\"  \"CE41\"\n [71] \"CW61\" \"CCHS\" \"CDS1\" \"CEFH\" \"CD81\" \"CEFA\" \"CW55\" \"CAG2\" \"CAS4\" \"CHF4\"\n [81] \"CDG2\" \"HQG1\" \"CHS7\" \"CAS2\" \"HQM2\" \"CDF4\" \"HX\"   \"CHS6\" \"CMS5\" \"CHC2\"\n [91] \"HQ\"   \"HOG3\" \"CD27\" \"HOS6\" \"HOS3\" \"CWC4\" \"CPS3\" \"HAM1\" \"CEM3\" \"CA\"  \n[101] \"CWGI\" \"SW72\" \"CL\"   \"CD63\" \"CDH4\" \"CPS0\" \"CPG0\" \"CD61\" \"CWF5\" \"CEG2\"\n[111] \"CDF0\" \"CPF0\" \"CERR\" \"CWF0\" \"CEFM\" \"HOC2\" \"CHF5\" \"CACE\" \"CS\"   \"CM\"  \n[121] \"CEN2\" \"CDGE\" \"cds7\" \"HCS3\" \"HQS0\" \"HCS1\" \"CM53\" \"CDG6\" \"CS53\" \"CEM1\"\n[131] \"CE54\" \"CDS5\" \"CES5\" \"HAS3\" \"CEF3\" \"CAGO\" \"CAC5\" \"SW21\" \"CAF3\" \"HOS1\"\n[141] \"HA\"   \"CDS3\" \"CW33\" \"CLM4\" \"CFF4\" \"CFS1\" \"CHS5\" \"HB\"   \"CH21\" \"CHS3\"\n[151] \"CMS4\" \"chs5\" \"CSF1\" \"CAG3\" \"CHM1\" \"CLS3\" \"HBS1\" \"CFF3\" \"CAF2\" \"CMF2\"\n[161] \"SM20\" \"CFS\"  \"CHFS\" \"CH62\" \"CFM1\" \"CHMI\" \"HBM1\" \"CFRR\" \"CHD1\" \"CHS8\"\n[171] \"CHF9\" \"CHFI\" \"CHSI\" \"HAM0\" \"CLS4\" \"SM81\" \"CLS2\" \"CES6\" \"CSF2\" \"CFSC\"\n[181] \"CHF\"  \"CHS9\" \"CH6-\" \"CSF3\" \"HM\"   \"HD\"   \"CFS-\" \"SM40\" \"CHF6\" \"CHS\" \n[191] \"CAS-\" \"CDRX\" \"HAS1\" \"CH12\" \"CHF0\" \"HCD1\" \"CM55\" \"HAF\" \n\n\n\nimp_data |&gt; group_by(FPAG) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n)) |&gt; head()\n\n# A tibble: 6 × 2\n  FPAG      n\n  &lt;chr&gt; &lt;int&gt;\n1 CDS6   2396\n2 CFS2   2004\n3 CHS1   1524\n4 CHF1   1462\n5 CDS7   1352\n6 CDG1   1090\n\n\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nx &lt;- unique(imp_data_FPA$fpa)\nx\n\n [1] \"CWF\" \"CDS\" \"CAS\" \"CDG\" \"CMS\" \"CWS\" \"CHS\" \"CES\" \"CAC\" \"CPS\" \"CPG\" \"CEF\"\n[13] \"CD\"  \"CWG\" \"CP\"  \"CF\"  \"CFF\" \"CEG\" \"CHF\" \"CW\"  \"HC\"  \"CC\"  \"CAG\" \"CFS\"\n[25] \"CEM\" \"CCS\" \"CCF\" \"CH\"  \"HO\"  \"CE\"  \"CLS\" \"HQS\" \"HOG\" \"CMF\" \"CMG\" \"CE4\"\n[37] \"CW6\" \"CCH\" \"CD8\" \"CW5\" \"HQG\" \"HQM\" \"CDF\" \"HX\"  \"CHC\" \"HQ\"  \"CD2\" \"HOS\"\n[49] \"CWC\" \"HAM\" \"CA\"  \"SW7\" \"CL\"  \"CD6\" \"CDH\" \"CPF\" \"CER\" \"HOC\" \"CS\"  \"CM\" \n[61] \"CEN\" \"cds\" \"HCS\" \"CM5\" \"CS5\" \"CE5\" \"HAS\" \"SW2\" \"CAF\" \"HA\"  \"CW3\" \"CLM\"\n[73] \"HB\"  \"CH2\" \"chs\" \"CSF\" \"CHM\" \"HBS\" \"SM2\" \"CH6\" \"CFM\" \"HBM\" \"CFR\" \"CHD\"\n[85] \"SM8\" \"HM\"  \"HD\"  \"SM4\" \"CDR\" \"CH1\" \"HCD\" \"HAF\"\n\n\n\n# There are 17 fpas vs 34 FPAGs\nn_distinct(imp_data_FPA$fpa)\n\n[1] 92\n\nn_distinct(imp_data_FPA$FPAG)\n\n[1] 198\n\n# n_distinct(imp_data$FPAG)\n\n# There are 4028 vs 2402 in the largest group\nimp_data_FPA |&gt; group_by(fpa) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n)) |&gt; head()\n\n# A tibble: 6 × 2\n  fpa       n\n  &lt;chr&gt; &lt;int&gt;\n1 CDS    4615\n2 CFS    2945\n3 CHS    2520\n4 CHF    2430\n5 CES    2055\n6 CMS    1532\n\n\nBefore expanding the set, there were 17 fpas and 34 fpags. Now there are 92 fpas and 198 FPAGs\nHere is the table before:\n\n\n\nfpa\nn\n\n\n\n\nCDS\n4028\n\n\nCES\n2004\n\n\nCFS\n1840\n\n\nCDG\n1383\n\n\nCMS\n1221\n\n\nCHS\n1220"
  },
  {
    "objectID": "2_Imputation.html#species-prevalence",
    "href": "2_Imputation.html#species-prevalence",
    "title": "Imputation",
    "section": "Species prevalence",
    "text": "Species prevalence\n\nz &lt;- apply(imp_data, 2, max) \nz &lt;- z[6:length(z)]\nx &lt;- names(z)\ny &lt;- z\nnames(y) &lt;- NULL\ny &lt;- as.numeric(y)\nnames(y) &lt;- x\n# This is a sorted list of the maximum trees per acre per species on one plot\ny |&gt; sort(decreasing = T)\n\n    TSHE_TD     PIEN_TD     ACGL_TD     PICO_TD     PSME_TD     THPL_TD \n47527.98907 24588.61264 24063.85567 18816.28590 15142.98705 14768.16064 \n    ABGR_TD     ABAM_TD     BEPA_TD     LAOC_TD     PIPO_TD     FRLA_TD \n13793.61197 12219.34104 10944.93124 10345.20898  9070.79918  8770.93805 \n    ABLA_TD     MAFU_TD     TSME_TD     PRVI_TD     PREM_TD     CHNO_TD \n 7796.38937  7196.66712  4722.81279  4347.98638  3523.36827  3148.54186 \n   POTR5_TD     ABPR_TD     LALY_TD    TABR2_TD    ALRU2_TD     PRAV_TD \n 2773.71545  2623.78489  2548.81960  2248.95847  2248.95847  2248.95847 \n   QUGA4_TD    PIMO3_TD    POBAT_TD     ABCO_TD    ACMA3_TD     PIAL_TD \n 2099.02791  1874.13206  1274.40980  1274.40980  1049.51395   974.54867 \n    PISI_TD    CONU4_TD      2TB_TD    ALRH2_TD     JUOC_TD     CHLA_TD \n  674.68754   449.79170   449.79170   449.79170   374.82641   374.82640 \n    ARME_TD    PRPE2_TD     JUNI_TD    BEOC2_TD     PSMA_TD     BEUT_TD \n  224.89585   224.89585   149.93060   149.93057    74.96528    74.96528 \n    JUHI_TD \n   74.96528 \n\nimp &lt;- imp_data\n\nimp_p &lt;- imp |&gt; select(1:5)\nimp_r &lt;- imp |&gt; select(1, 6:ncol(imp))\nimp_r &lt;- imp_r |&gt; mutate(\n  total_TD = rowSums(imp_r[,2:ncol(imp_r)])\n)\n\nimp &lt;- left_join(imp_p, imp_r, by = \"STANDPLOT_CN\")\nimp_z &lt;- imp[imp$total_TD &gt; 0,]\n\n# summary(imp_z[,6:ncol(imp_z)])\n\n\n\n# apply(imp_z[,6:ncol(imp_z)], 2, quantile, seq(0.72, 0.90, .04))\n\nprevalent_sp &lt;- c('PSME_TD', 'ABAM_TD', 'ABLA_TD', 'TSHE_TD')\nkeep &lt;- names(imp_z)[!names(imp_z) %in% prevalent_sp]\n\nimp_z2 &lt;- imp_z[,keep]\n\n# apply(imp_z2[,6:ncol(imp_z2)], 2, quantile, seq(0.90, 0.9875, .025))\n\ncommon_sp &lt;- c('PIPO_TD' , 'TSME_TD', 'ABGR_TD', 'THPL_TD', 'PIEN_TD', 'PICO_TD', 'PIMO3_TD')\n\nkeep &lt;- names(imp_z2)[!names(imp_z2) %in% common_sp]\nimp_z3 &lt;- imp_z2[,keep]\n\n# apply(imp_z3[,6:ncol(imp_z3)], 2, quantile, seq(0.975, .99, .005))\n\nuncommon_sp &lt;- c('PIAL_TD', 'ACGL_TD', 'LAOC_TD', 'TABR2_TD', 'CHNO_TD', \n                 'POTR5_TD')\n\nkeep &lt;- names(imp_z3)[!names(imp_z3) %in% uncommon_sp]\nimp_z4 &lt;- imp_z3[,keep]\n\n# apply(imp_z4[,6:ncol(imp_z4)], 2, quantile, seq(0.99, 1, .005))\n\nrare_sp &lt;- names(imp_z4[,6:(ncol(imp_z4)-1)])\n\nsp_prevalence &lt;-  list(prevalent = prevalent_sp, \n     common = common_sp, \n     uncommon = uncommon_sp, \n     rare = rare_sp)\n# save(sp_prevalence, file = \"sp_prevalence.Rdata\")\n# getwd()\n\nprint(sp_prevalence)\n\n$prevalent\n[1] \"PSME_TD\" \"ABAM_TD\" \"ABLA_TD\" \"TSHE_TD\"\n\n$common\n[1] \"PIPO_TD\"  \"TSME_TD\"  \"ABGR_TD\"  \"THPL_TD\"  \"PIEN_TD\"  \"PICO_TD\"  \"PIMO3_TD\"\n\n$uncommon\n[1] \"PIAL_TD\"  \"ACGL_TD\"  \"LAOC_TD\"  \"TABR2_TD\" \"CHNO_TD\"  \"POTR5_TD\"\n\n$rare\n [1] \"LALY_TD\"  \"BEPA_TD\"  \"PREM_TD\"  \"ABPR_TD\"  \"PRVI_TD\"  \"ALRU2_TD\"\n [7] \"QUGA4_TD\" \"CONU4_TD\" \"ACMA3_TD\" \"JUOC_TD\"  \"FRLA_TD\"  \"2TB_TD\"  \n[13] \"POBAT_TD\" \"MAFU_TD\"  \"ARME_TD\"  \"ABCO_TD\"  \"PISI_TD\"  \"PSMA_TD\" \n[19] \"ALRH2_TD\" \"JUNI_TD\"  \"BEUT_TD\"  \"BEOC2_TD\" \"PRPE2_TD\" \"JUHI_TD\" \n[25] \"CHLA_TD\"  \"PRAV_TD\" \n\n# Here are the quantiles for most prevelant species with zeroes\n# apply(imp_data[,sp_prevalence$prevalent], 2, quantile, seq(0.86, 1, .01))\n\n\n# Here are the quantiles for common species with zeroes\napply(imp_data[,sp_prevalence$common], 2, quantile, seq(0.95, 1, .01))\n\n        PIPO_TD    TSME_TD     ABGR_TD     THPL_TD     PIEN_TD     PICO_TD\n95%     0.00000    0.00000    74.96528    74.96528     0.00000     0.00000\n96%     0.00000    0.00000   149.93057    74.96528     0.00000     0.00000\n97%     0.00000   74.96528   224.89585   149.93057     0.00000    74.96528\n98%    74.96528   74.96528   374.82641   224.89585    74.96528   149.93057\n99%   149.93057  224.89585   674.68754   449.79170   149.93057   449.79170\n100% 9070.79918 4722.81279 13793.61197 14768.16064 24588.61264 18816.28590\n       PIMO3_TD\n95%     0.00000\n96%     0.00000\n97%     0.00000\n98%     0.00000\n99%    74.96528\n100% 1874.13206\n\n# Here are the quantiles for uncommon species with zeroes\napply(imp_data[,sp_prevalence$uncommon], 2, quantile, seq(0.9875, 1, .0025))\n\n         PIAL_TD     ACGL_TD     LAOC_TD   TABR2_TD    CHNO_TD   POTR5_TD\n98.75%   0.00000     0.00000    74.96528    0.00000   74.96528    0.00000\n99%      0.00000    74.96528    74.96528    0.00000   74.96528    0.00000\n99.25%  74.96528    74.96528    74.96528   74.96528  149.93057   74.96528\n99.5%   74.96528   149.93057   149.93057   74.96528  292.36460  149.93057\n99.75% 149.93057   449.79170   449.79170  224.89585  449.79170  299.86113\n100%   974.54867 24063.85567 10345.20898 2248.95847 3148.54186 2773.71545\n\n# Here are the quantiles for rare species with zeroes\napply(imp_data[,sp_prevalence$rare], 2, quantile, seq(0.9925, 1, .0025))\n\n          LALY_TD  BEPA_TD    PREM_TD    ABPR_TD   PRVI_TD   ALRU2_TD\n99.25%    0.00000     0.00    0.00000    0.00000    0.0000    0.00000\n99.5%     0.00000     0.00   74.96528   74.96528    0.0000    0.00000\n99.75%   74.96528     0.00  224.89585  149.93057  149.9306   74.96528\n100%   2548.81960 10944.93 3523.36827 2623.78489 4347.9864 2248.95847\n         QUGA4_TD CONU4_TD   ACMA3_TD  JUOC_TD  FRLA_TD   2TB_TD POBAT_TD\n99.25%    0.00000   0.0000    0.00000   0.0000    0.000   0.0000     0.00\n99.5%    67.46875   0.0000    0.00000   0.0000    0.000   0.0000     0.00\n99.75%  149.93057   0.0000   74.96528   0.0000    0.000   0.0000     0.00\n100%   2099.02791 449.7917 1049.51395 374.8264 8770.938 449.7917  1274.41\n        MAFU_TD  ARME_TD ABCO_TD  PISI_TD  PSMA_TD ALRH2_TD  JUNI_TD  BEUT_TD\n99.25%    0.000   0.0000    0.00   0.0000  0.00000   0.0000   0.0000  0.00000\n99.5%     0.000   0.0000    0.00   0.0000  0.00000   0.0000   0.0000  0.00000\n99.75%    0.000   0.0000    0.00   0.0000  0.00000   0.0000   0.0000  0.00000\n100%   7196.667 224.8958 1274.41 674.6875 74.96528 449.7917 149.9306 74.96528\n       BEOC2_TD PRPE2_TD  JUHI_TD  CHLA_TD  PRAV_TD\n99.25%   0.0000   0.0000  0.00000   0.0000    0.000\n99.5%    0.0000   0.0000  0.00000   0.0000    0.000\n99.75%   0.0000   0.0000  0.00000   0.0000    0.000\n100%   149.9306 224.8958 74.96528 374.8264 2248.958"
  },
  {
    "objectID": "2_Imputation.html#rf-on-cds",
    "href": "2_Imputation.html#rf-on-cds",
    "title": "Imputation",
    "section": "2, RF on CDS",
    "text": "2, RF on CDS\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nCDS &lt;- imp_data_FPA[imp_data_FPA$fpa == \"CDS\", ]\n\nCDS &lt;- CDS |&gt;  mutate(\n  common = rowSums(CDS[,sp_prevalence$common]),\n  uncommon = rowSums(CDS[,sp_prevalence$uncommon]),\n  rare_TD = rowSums(CDS[,sp_prevalence$rare]), \n  total_TD = rowSums((CDS[, 6:39]))\n) |&gt; \n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common) \n\nCDS &lt;- CDS |&gt; \n  relocate(fpa, .after = FPAG)\n\n\n# Here are the quantiles for most prevalent species with zeroes\napply(CDS[,sp_prevalence$prevalent], 2, quantile, seq(0.99, 1, .001))\n\n         PSME_TD ABAM_TD   ABLA_TD   TSHE_TD\n99%     974.5487       0   0.00000   0.00000\n99.1%  1085.0475       0  74.96528   0.00000\n99.2%  1199.4445       0  74.96528   0.00000\n99.3%  1274.4098       0  74.96528   0.00000\n99.4%  1349.3751       0  74.96528   0.00000\n99.5%  1494.0581       0  74.96528   0.00000\n99.6%  1574.2709       0 149.93057   0.00000\n99.7%  1672.9252       0 149.93057   0.00000\n99.8%  2024.0626       0 224.89585   0.00000\n99.9%  2681.6581       0 357.73433  74.96528\n100%  15142.9871       0 674.68754 299.86113\n\n\nI viewed the table and picked values based on the next highest after the max. I suppose I could also trim the highest values.\n\n# I am replacing the highest value with the next highest value\nCDS$PSME_TD[CDS$PSME_TD &gt; 3148.5] &lt;- 3148.5\n# Removing an All zero column and a nearly empty one. \nCDS &lt;- CDS |&gt; select(-c(ABAM_TD, TSHE_TD))\n\ncds &lt;- CDS\n\nrefs &lt;- cds[1:(3*nrow(cds)/4),]\n\n# CDS\n# cds\n# data(\"MoscowMtStJoe\")\n\nx &lt;- cds |&gt; select(1:4)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\ny &lt;- cds |&gt; select(1, 7:ncol(cds))\n# y &lt;- y[refs]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\n\n\n\nmal &lt;- yai(x = x, y = y, method = \"mahalanobis\", k = k)\nmsn &lt;- yai(x = x, y = y, method = \"msn\", k = k)\ngnn &lt;- yai(x = x, y = y, method = \"gnn\", k = k)\n\nWarning in yai(x = x, y = y, method = \"gnn\", k = k): 2944 rows have y-variable\nrow sums &lt;= 0 were converted to target observations for method gnn\n\nica &lt;- yai(x = x, y = y, method = \"ica\", k = k)\n\nLoading required namespace: fastICA\n\nerror_full &lt;- errorStats(mal, msn, gnn, ica)\n\nWarning in notablyDistant(x, p = 1 - pzero): when computing threshold, 441 zero\ndistances of 4615 references were set to 0.0000000002325966\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 441 zero\ndistances of 4615 references were set to 0.0000000002325966\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 441 zero\ndistances of 4615 references were set to 0.000000000130061\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 136 zero\ndistances of 1671 references were set to 0.00000000000000001387779\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 441 zero\ndistances of 4615 references were set to 0.0000000002326219\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\n# rf &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n# save(rf, file = \"rf.Rdata\")\nload(\"rf.Rdata\")\n\n# This won't run with rf in it? \n# error_full &lt;- errorStats(mal, msn, gnn, rf)\n\nFull_set &lt;- impute(rf, ancillaryData = y)\nrmsd &lt;- compare.yai(mal, msn, gnn, Full_set, ica)\n\nWarning in compare.yai(mal, msn, gnn, Full_set, ica): not all scale factors are\nthe same.\n\nrmsd.yai(Full_set)\n\n              rmsd\nPSME_TD  188.40859\nABLA_TD   26.69023\ncommon   252.39648\nuncommon 376.31626\nrare_TD  111.67231\ntotal_TD 428.91156\n\n\n\nPlots, RF, Full set\nDots below the one to one line indicate lower rmsd for the named imputation on the horizontal. RF does the best.\n\nplot(rmsd, main = \"Full Set\")\n\n\n\n\n\npar(mar = c(1,2,3.2,1))\nplot(rf, vars = yvars(rf))\n\n\n\n\n\npar(mar = c(1,2,3.2,1))\nplot(msn)\n\n\n\n\n\nrmsd\n\n         mal.rmsdS msn.rmsdS gnn.rmsdS Full_set.rmsdS ica.rmsdS\nPSME_TD  0.9742293 1.0028254 1.0430676      0.8780024 0.9760192\nABLA_TD  1.2163312 1.3051459 1.4111898      1.1805489 1.2163312\ncommon   0.9446253 1.0126262 0.8401424      0.7498232 0.9460919\nuncommon 1.4020282 1.3936819 1.4072269      1.0124991 1.4019150\nrare_TD  1.3471906 1.2835394 1.3637743      1.2004361 1.3613216\ntotal_TD 0.5857362 0.8211703 0.4994699      0.6581468 0.5857362\n\n\n\nfind_best &lt;- function(df) {\n  data.frame(name = names(df)[apply(df, 1, which.min)],\n     value = apply(df, 1, min))\n}\n\nfind_best(rmsd)\n\n                   name     value\nPSME_TD  Full_set.rmsdS 0.8780024\nABLA_TD  Full_set.rmsdS 1.1805489\ncommon   Full_set.rmsdS 0.7498232\nuncommon Full_set.rmsdS 1.0124991\nrare_TD  Full_set.rmsdS 1.2004361\ntotal_TD      gnn.rmsdS 0.4994699"
  },
  {
    "objectID": "2_Imputation.html#rf-on-seedling-plots",
    "href": "2_Imputation.html#rf-on-seedling-plots",
    "title": "Imputation",
    "section": "3. RF on seedling plots",
    "text": "3. RF on seedling plots\n\nk = 10\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\n# imp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n\n# Grabbing the topography variables\npred_topo &lt;- plots |&gt; select(\n  STANDPLOT_CN, ELEVFT, SLOPE, ASPECT\n)\n# Get the Kralicek variables\npred_Kral &lt;- zimp_data |&gt; select(\n  STANDPLOT_CN, CC, BA, SDI, FPAG\n)\n\n# remove the predictors from the response.\nresponse &lt;- zimp_data |&gt; select(\n  -c(CC, BA, SDI, FPAG)\n)\n# join the Kralicek and topo variables. \npredictors &lt;- left_join(pred_Kral, pred_topo, join_by(STANDPLOT_CN))|&gt; \n  relocate(FPAG, .after = STANDPLOT_CN)\n\n\nCDS\n\nimp_data_FPA &lt;- zimp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nx &lt;- unique(imp_data_FPA$fpa)\n\nCDS &lt;- imp_data_FPA[imp_data_FPA$fpa == \"CDS\", ]\n\nCDS &lt;- CDS |&gt;  mutate(\n  common = rowSums(CDS[,sp_prevalence$common]),\n  uncommon = rowSums(CDS[,sp_prevalence$uncommon]),\n  rare_TD = rowSums(CDS[,sp_prevalence$rare]), \n  total_TD = rowSums((CDS[, 6:39]))\n) |&gt; \n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common) \n\nCDS &lt;- CDS |&gt; \n  relocate(fpa, .after = FPAG)\n\n# I am replacing the highest value with the next highest value\nCDS$PSME_TD[CDS$PSME_TD &gt; 3148.5] &lt;- 3148.5\n# Removing an All zero column and a nearly empty one. \nCDS &lt;- CDS |&gt; select(-c(ABAM_TD, TSHE_TD))\n\ncds &lt;- CDS\n\nrefs &lt;- cds[1:(3*nrow(cds)/4),]\n\n# CDS\n# cds\n# data(\"MoscowMtStJoe\")\n\nx &lt;- cds |&gt; select(1:4)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\ny &lt;- cds |&gt; select(1, 7:ncol(cds))\n# y &lt;- y[refs]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\n\n\n\nzmal &lt;- yai(x = x, y = y, method = \"mahalanobis\", k = k)\nzmsn &lt;- yai(x = x, y = y, method = \"msn\", k = k)\nzgnn &lt;- yai(x = x, y = y, method = \"gnn\", k = k)\nzica &lt;- yai(x = x, y = y, method = \"ica\", k = k)\n\nzerror_full &lt;- errorStats(zmal, zmsn, zgnn, zica)\n\nWarning in notablyDistant(x, p = 1 - pzero): when computing threshold, 144 zero\ndistances of 1671 references were set to 0.0000000003454502\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 144 zero\ndistances of 1671 references were set to 0.0000000003454502\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 144 zero\ndistances of 1671 references were set to 0.0000000002290794\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 136 zero\ndistances of 1671 references were set to 0.00000000000000005551115\n\n\nWarning in notablyDistant(x, p = plg): when computing threshold, 144 zero\ndistances of 1671 references were set to 0.0000000003455536\n\nzyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(zyrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\n# zrf &lt;- yai(x = x, y = zyrf, method = \"randomForest\", k = k)\n# save(zrf, file = \"zrf.Rdata\")\nload(\"zrf.Rdata\")\n\n# This won't run with rf in it? \n# error_full &lt;- errorStats(mal, msn, gnn, rf)\n\nzFull_set &lt;- impute(zrf, ancillaryData = y)\nzrmsd &lt;- compare.yai(zmal, zmsn, zgnn, zFull_set, zica)\n\n\nrmsd.yai(zFull_set)\n\n              rmsd\nPSME_TD  312.83162\nABLA_TD   44.27986\ncommon   405.36313\nuncommon 625.12598\nrare_TD  183.63585\ntotal_TD 709.81751\n\n\nFor each species set, which imputation had the lowest rmsd?\n\nfind_best &lt;- function(df) {\n  data.frame(name = names(df)[apply(df, 1, which.min)],\n     value = apply(df, 1, min))\n}\nfind_best(zrmsd)\n\n                    name     value\nPSME_TD  zFull_set.rmsdS 0.9559565\nABLA_TD  zFull_set.rmsdS 1.1841441\ncommon   zFull_set.rmsdS 0.7420633\nuncommon zFull_set.rmsdS 1.0143569\nrare_TD  zFull_set.rmsdS 1.2025893\ntotal_TD      zgnn.rmsdS 0.4994699\n\nfind_best(rmsd)\n\n                   name     value\nPSME_TD  Full_set.rmsdS 0.8780024\nABLA_TD  Full_set.rmsdS 1.1805489\ncommon   Full_set.rmsdS 0.7498232\nuncommon Full_set.rmsdS 1.0124991\nrare_TD  Full_set.rmsdS 1.2004361\ntotal_TD      gnn.rmsdS 0.4994699\n\n\nRF does best for all but total tree density. The set with all the zeroes has lower rmsd. I find that odd.\nIt would be likely that imputing zero for zero would reduce rmsd. Even by chance, if half the data is zero, it would be likely to imput the observed."
  },
  {
    "objectID": "2_Imputation.html#plots-vs-plots",
    "href": "2_Imputation.html#plots-vs-plots",
    "title": "Imputation",
    "section": "Plots vs Plots",
    "text": "Plots vs Plots\nThese tell the same story, RF does better.\n\nplot(zrmsd, main = \"zFull Set\")\nplot(rmsd, main = \"Full Set\")\n\n\n\n\n\n\n\n\n\n\n\n\nThe zSeedling data shows the distribution of species better. It’s not half zeros. The imputed values look identical.\n\nplot(zrf, vars = yvars(zrf))\nplot(rf, vars = yvars(rf))\n\n\n\n\n\n\n\n\n\n\n\n\nzSeedling’s imputed vs observed are closer to the 1:1 line. The large values in total and uncommon make it less clear.\n\npar(mar = c(2,2,3.2,1))\nplot(zmsn)\nplot(msn)\n\n\n\n\n\n\n\n\n\n\n\n\nFor the RF imputation, the Seedlings only data was marginally more distant.\n\nzrmsd\n\n         zmal.rmsdS zmsn.rmsdS zgnn.rmsdS zFull_set.rmsdS zica.rmsdS\nPSME_TD   1.0307255  0.9949283  1.0455937       0.9559565  1.0339957\nABLA_TD   1.4671745  1.2608720  1.4111898       1.1841441  1.4671745\ncommon    0.9436294  0.8770926  0.8384303       0.7420633  0.9393318\nuncommon  1.4064999  1.4029035  1.4069185       1.0143569  1.4064118\nrare_TD   1.4510371  1.2894068  1.3407893       1.2025893  1.3884054\ntotal_TD  0.5530212  0.6578850  0.4994699       0.6914508  0.5530212\n\nrmsd\n\n         mal.rmsdS msn.rmsdS gnn.rmsdS Full_set.rmsdS ica.rmsdS\nPSME_TD  0.9742293 1.0028254 1.0430676      0.8780024 0.9760192\nABLA_TD  1.2163312 1.3051459 1.4111898      1.1805489 1.2163312\ncommon   0.9446253 1.0126262 0.8401424      0.7498232 0.9460919\nuncommon 1.4020282 1.3936819 1.4072269      1.0124991 1.4019150\nrare_TD  1.3471906 1.2835394 1.3637743      1.2004361 1.3613216\ntotal_TD 0.5857362 0.8211703 0.4994699      0.6581468 0.5857362\n\nzrmsd$zFull_set.rmsdS - rmsd$Full_set.rmsdS\n\n[1]  0.077954107  0.003595165 -0.007759937  0.001857819  0.002153193\n[6]  0.033303953"
  },
  {
    "objectID": "2_Imputation.html#checking-on-yaimpute-functions.",
    "href": "2_Imputation.html#checking-on-yaimpute-functions.",
    "title": "Imputation",
    "section": "Checking on yaImpute functions.",
    "text": "Checking on yaImpute functions.\nI think the yai objects have the data for nearest neighbors.\n\nrm(list = ls())\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n\nload(\"sp_prevalence.Rdata\")"
  },
  {
    "objectID": "2_Imputation.html#test-imp-full-set.",
    "href": "2_Imputation.html#test-imp-full-set.",
    "title": "Imputation",
    "section": "Test imp, full set.",
    "text": "Test imp, full set.\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\n# CDS &lt;- imp_data_FPA[imp_data_FPA$fpa == \"CDS\", ]\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n  common = rowSums(imp_data_FPA[,sp_prevalence$common]),\n  uncommon = rowSums(imp_data_FPA[,sp_prevalence$uncommon]),\n  rare_TD = rowSums(imp_data_FPA[,sp_prevalence$rare]),\n  total_TD = rowSums((imp_data_FPA[, 6:39]))\n) |&gt;\n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common)\n\n# imp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n#   total_TD = rowSums((imp_data_FPA[, 6:(ncol(imp_data_FPA)-1)]))\n# )\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; \n  relocate(fpa, .after = FPAG)\n\n\n# Here are the quantiles for most prevalent species with zeroes\n# apply(imp_data_FPA[,sp_prevalence$prevalent], 2, quantile, seq(0.99, 1, .001))\n\n# I am replacing the highest value with the next highest value\n# imp_data_FPA$PSME_TD[imp_data_FPA$PSME_TD &gt; 3148.5] &lt;- 3148.5\n# Removing an All zero column and a nearly empty one. \n# imp_data_FPA &lt;- imp_data_FPA |&gt; select(-c(ABAM_TD, TSHE_TD))\n\ncds &lt;- imp_data_FPA\n\nrefs &lt;- rownames(cds[1:(3*nrow(cds)/4),])\n\nx &lt;- cds |&gt; select(1:4)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- cds |&gt; select(1, 7:ncol(cds))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nmal &lt;- yai(x = x, y = y, method = \"mahalanobis\", k = k)\nmsn &lt;- yai(x = x, y = y, method = \"msn\", k = k)\ngnn &lt;- yai(x = x, y = y, method = \"gnn\", k = k)\n\nWarning in yai(x = x, y = y, method = \"gnn\", k = k): 8889 rows have y-variable\nrow sums &lt;= 0 were converted to target observations for method gnn\n\nica &lt;- yai(x = x, y = y, method = \"ica\", k = k)\n\nmsn_boot &lt;- yai(x = x, y = yfull, method = \"msn\", k = k, bootstrap = T)\n\n# error_full &lt;- errorStats(mal, msn, gnn, ica)\n# \nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n# \nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n# \n# frf2 &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n# save(frf, file = \"frf.Rdata\")\n# save(frf2, file = \"frf2.Rdata\")\nload(\"frf.Rdata\")\nload(\"frf2.Rdata\")\n\n# This won't run with rf in it? \n# error_full &lt;- errorStats(mal, msn, gnn, rf)\n\nFull_set &lt;- impute(frf, ancillaryData = y)\nfrf2_set &lt;- impute(frf2, ancillaryData = y)\nrmsd &lt;- compare.yai(mal, msn, gnn, Full_set, ica, msn_boot)\n\nWarning in compare.yai(mal, msn, gnn, Full_set, ica, msn_boot): not all scale\nfactors are the same.\n\nrmsd.yai(Full_set) |&gt; arrange(desc(rmsd)) |&gt; summary()\n\n      rmsd      \n Min.   :184.6  \n 1st Qu.:302.4  \n Median :321.5  \n Mean   :338.3  \n 3rd Qu.:359.6  \n Max.   :519.1  \n\n\nThese got messed up when I went back and tried to save a plot to compare the fpag as factor plot. The second one was originally for all species individually. It wasn’t anything special. Same as others, messy.\n\npar(mar = c(1,1,3.2,1))\n# jpeg(\"p_full_set.jpg\")\nplot(frf2_set)\n\n\n\n\n\npar(mar = c(1,1,3.2,1))\nplot(Full_set)\n\n\n\n\n\nplot(rmsd)"
  },
  {
    "objectID": "2_Imputation.html#stochastic-distribution",
    "href": "2_Imputation.html#stochastic-distribution",
    "title": "Imputation",
    "section": "Stochastic Distribution",
    "text": "Stochastic Distribution\n\nNotably dist example\n\n# data(iris)\n# \n# \n# # form some test data\n# refs=sample(rownames(iris),50)\n# x &lt;- iris[,1:3]      # Sepal.Length Sepal.Width Petal.Length\n# y &lt;- iris[refs,4:5]  # Petal.Width Species\n# \n# # build an msn run, first build dummy variables for species.\n# \n# sp1 &lt;- as.integer(iris$Species==\"setosa\")\n# sp2 &lt;- as.integer(iris$Species==\"versicolor\")\n# y2 &lt;- data.frame(cbind(iris[,4],sp1,sp2),row.names=rownames(iris))\n# y2 &lt;- y2[refs,]\n# \n# names(y2) &lt;- c(\"Petal.Width\",\"Sp1\",\"Sp2\")\n# \n# xmsn &lt;- yai(x=x,y=y2,method=\"msn\")\n# \n# notablyDistant(xmsn)\n\n\n# empty\n\nx &lt;- msn$neiDstTrgs\nx &lt;- as.data.frame(x)\nmax(x[,1])\n\n[1] 0.8838358\n\nhist(x[,1], breaks = 100)\n\n\n\nmean(x[,1]) + sd(x[,1])*2\n\n[1] 0.09517604\n\nhist(x[x$Dst.k1 &lt; (mean(x[,1]) + sd(x[,1])*2), \"Dst.k1\"], breaks = 100)\n\n\n\n\n\nhist(log(x[,1]), breaks = 100)\n\n\n\nhist(log(x[x$Dst.k1 &lt; (mean(x[,1]) + sd(x[,1])*2), \"Dst.k1\"]), breaks = 100)\n\n\n\nlog(0.04307483)\n\n[1] -3.144816\n\nnotablyDistant(msn, threshold = .134)\n\n$notablyDistantRefs\n                                use      dist\n22399018010497_3   22398703010497_3 1.6368786\n13009978010497_4   22399290010497_1 1.0888892\n216960325020004_4  22398703010497_3 0.5524446\n40220286010497_3  216961121020004_1 0.4377439\n13009978010497_2   22931069010497_3 0.3776544\n22398786010497_2   22954397010497_3 0.3629839\n22954397010497_3   22954586010497_1 0.3486320\n8605918010901_2   558630833126144_1 0.3471019\n22954397010497_4   22398585010497_3 0.3280782\n216961121020004_1 558629497126144_3 0.2915627\n22399290010497_1   29395670010497_3 0.2781671\n558629497126144_3 290008707489998_3 0.2550805\n22398779010497_4   13037626010497_1 0.2521472\n238861338489998_3  22954586010497_1 0.2470366\n13049707010497_3   22398621010497_4 0.2460680\n24853515010900_2  558630867126144_3 0.2393577\n558630867126144_3  24853515010900_2 0.2393577\n13037626010497_1   22398703010497_3 0.2357689\n22398703010497_3   13037626010497_1 0.2357689\n22399054010497_4   22398369010497_4 0.2353384\n22954484010497_4   22954384010497_4 0.2314548\n22398578010497_3   13050884010497_4 0.2307665\n174763283020004_3  22398573010497_3 0.2305093\n22398573010497_3  174763283020004_3 0.2305093\n238861440489998_2  22399037010497_1 0.2265928\n22398702010497_3   22954586010497_1 0.2199238\n22954586010497_1   22398702010497_3 0.2199238\n22954384010497_4   13037626010497_3 0.2153577\n238861440489998_1  22398784010497_3 0.2049274\n22399288010497_1   22399284010497_4 0.1986057\n22954777010497_4   13060802010497_3 0.1762695\n216960205020004_1  13004916010497_1 0.1761057\n22399284010497_3  290008704489998_3 0.1706586\n22933115010497_1   22954341010497_3 0.1693149\n13037626010497_3   22954372010497_2 0.1684734\n216959926020004_1  22827645010497_2 0.1668744\n13050884010497_2  238861251489998_2 0.1642187\n22827635010497_3  558630690126144_3 0.1641223\n558629658126144_1  40220467010497_3 0.1640346\n22954372010497_2   22827491010497_4 0.1622180\n238861047489998_4 238861293489998_4 0.1559969\n238861293489998_4 238861047489998_4 0.1559969\n174763488020004_1  22954429010497_1 0.1552325\n13204702010497_2   22398806010497_4 0.1528064\n22398786010497_1  216959763020004_1 0.1508395\n22399011010497_2   13036367010497_4 0.1490321\n22954688010497_3   22931146010497_2 0.1489400\n22931145010497_4  345936539489998_3 0.1420914\n13204702010497_4   22398784010497_4 0.1415597\n22398784010497_4   13204702010497_4 0.1415597\n13230130010497_3   22931069010497_3 0.1414399\n22931069010497_3   13230130010497_3 0.1414399\n22399282010497_4  412219998489998_1 0.1369255\n22827491010497_4  216960487020004_3 0.1366811\n22398784010497_1  558630833126144_1 0.1343229\n22398806010497_4   22399028010497_4 0.1341743\n490388032126144_2  22954341010497_3 0.1340595\n\n$notablyDistantTrgs\n                                use      dist\n444202329489998_2  22399018010497_3 0.8838358\n29881887010497_3   22399018010497_3 0.8735740\n558630963126144_3  22399290010497_1 0.4988810\n8642760010901_4    22398702010497_3 0.3745856\n40220846010497_2   22398702010497_3 0.3578139\n412223212489998_1  22399058010497_2 0.3287638\n558630922126144_2 412223101489998_4 0.3257559\n29394875010497_3   13230130010497_3 0.3097321\n558630922126144_1 412223101489998_4 0.3086052\n48206170010497_3   22399290010497_1 0.3054331\n29883273010497_3   22399290010497_1 0.2993880\n490388177126144_1  22954397010497_4 0.2982816\n30763967020004_1   29395670010497_3 0.2862008\n44541363020004_2  345933621489998_1 0.2804372\n412220475489998_4  22954777010497_4 0.2690961\n273641056489998_2  22399288010497_1 0.2689661\n558630977126144_4  22954760010497_3 0.2550543\n44541638020004_4   22398703010497_3 0.2549495\n44541638020004_2  238861158489998_3 0.2503243\n24499760010900_3   22399284010497_3 0.2494237\n273641056489998_4  13009978010497_4 0.2483758\n24543603010900_3  238861784489998_1 0.2416192\n40220150010497_3   22932909010497_1 0.2332969\n558630981126144_3  22954484010497_4 0.2311133\n30764876020004_3   22398786010497_2 0.2178295\n40220128010497_3   22954397010497_4 0.2116447\n48206606010497_2  238861585489998_1 0.1987157\n412223110489998_3  22954397010497_3 0.1986595\n30764893020004_1  412223101489998_4 0.1956262\n484819133489998_3  22398786010497_2 0.1925549\n24490736010900_1  216960205020004_1 0.1918436\n44541063020004_2   48206605010497_2 0.1913806\n484818953489998_3 216960205020004_1 0.1910648\n290008836489998_3  22932909010497_3 0.1879296\n24151714010900_1   44543461020004_3 0.1872123\n40220653010497_4  238861158489998_3 0.1864092\n273643053489998_3  22932909010497_1 0.1855042\n30763621020004_2  238861784489998_1 0.1847611\n412223111489998_3  22398784010497_3 0.1813624\n345934914489998_4 216961407020004_3 0.1781251\n48205092010497_2   13060802010497_3 0.1750833\n290008677489998_2  13230130010497_3 0.1738890\n558629234126144_2 238861293489998_4 0.1730680\n29395534010497_1   22954484010497_3 0.1721210\n24499760010900_1   44543461020004_3 0.1699613\n29881462010497_4   22954484010497_4 0.1644007\n412222533489998_3  22954760010497_3 0.1604215\n558629443126144_3  13230130010497_3 0.1596494\n29883336010497_4   22954760010497_3 0.1590602\n412221538489998_1 216958778020004_1 0.1588589\n484818886489998_1  22398823010497_4 0.1587919\n24494145010900_1  345933621489998_1 0.1576797\n40220860010497_2  238861440489998_1 0.1576258\n44541011020004_3   22954708010497_1 0.1575943\n29394734010497_3  174763543020004_1 0.1568008\n48202708010497_2   22933115010497_1 0.1564757\n273641739489998_4 216960176020004_1 0.1543169\n412220777489998_4  22399018010497_3 0.1498604\n290008677489998_1 558629497126144_3 0.1471938\n29395710010497_1   13050884010497_2 0.1451918\n558630949126144_3  22827572010497_3 0.1451220\n273639950489998_1 238861585489998_1 0.1450536\n412221076489998_2  22954372010497_2 0.1447240\n24163060010900_4   22954342010497_2 0.1436677\n558630931126144_1  22399054010497_3 0.1430704\n444202090489998_4 444202456489998_4 0.1417478\n24530286010900_2  216958778020004_1 0.1406567\n29883201010497_3   22954654010497_2 0.1404798\n412223212489998_3 238861188489998_1 0.1403676\n24846081010900_4  238861440489998_3 0.1391415\n273642539489998_1  22933115010497_1 0.1387503\n48204252010497_3  174763543020004_1 0.1387342\n48206050010497_1  558629497126144_3 0.1383256\n44541224020004_1   22954341010497_3 0.1379265\n30765041020004_2   13016117010497_3 0.1375495\n29881630010497_4   22827635010497_3 0.1372777\n8619726010901_2   174763686020004_4 0.1372125\n273641594489998_1  22954614010497_2 0.1369819\n48205582010497_2   22954373010497_3 0.1353704\n\n$threshold\n[1] 0.134\n\n$method\n[1] \"distribution\"\n\nsummary(x)\n\n     Dst.k1            Dst.k2            Dst.k3            Dst.k4       \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.01204   1st Qu.:0.01768   1st Qu.:0.02129   1st Qu.:0.02408  \n Median :0.02153   Median :0.02927   Median :0.03454   Median :0.03869  \n Mean   :0.02888   Mean   :0.03894   Mean   :0.04573   Mean   :0.05115  \n 3rd Qu.:0.03523   3rd Qu.:0.04694   3rd Qu.:0.05415   3rd Qu.:0.06018  \n Max.   :0.88384   Max.   :1.69366   Max.   :1.78612   Max.   :1.92789  \n     Dst.k5            Dst.k6            Dst.k7            Dst.k8       \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.02627   1st Qu.:0.02817   1st Qu.:0.02972   1st Qu.:0.03138  \n Median :0.04219   Median :0.04527   Median :0.04813   Median :0.05042  \n Mean   :0.05557   Mean   :0.05956   Mean   :0.06305   Mean   :0.06621  \n 3rd Qu.:0.06502   3rd Qu.:0.06961   3rd Qu.:0.07386   3rd Qu.:0.07754  \n Max.   :2.11432   Max.   :2.40130   Max.   :2.46419   Max.   :2.48889  \n     Dst.k9           Dst.k10       \n Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.03261   1st Qu.:0.03405  \n Median :0.05286   Median :0.05498  \n Mean   :0.06923   Mean   :0.07220  \n 3rd Qu.:0.08109   3rd Qu.:0.08490  \n Max.   :2.63022   Max.   :2.66556  \n\n\n\ntest &lt;- imp_data_FPA |&gt; filter(fpa == \"CWF\")\ntest &lt;- test[,2:4]\n\ntest2 &lt;- newtargets(msn, newdata = test)\ntest2\n\n\nCall:\nnewtargets(object = msn, newdata = test)\n0 observations dropped\nmethod used:  msn \nCancor report:\n      cor      F\n1 0.62757 464.71\n2 0.20890  64.51\n3 0.06102  11.49\n                                                                                                                                                                                        Pr.F\n1 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n2 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001775\n3 0.0000000000007045589223564445240446940665890451782615855336189270019531250000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n  Sig\n1    \n2    \n3    \n3 vectors used, pVal= 0.05 \ncancor$xcoef:\n          [,1]       [,2]       [,3]\nCC  -0.5930479 -0.8225699  1.2486928\nBA  -1.7605768  1.6025717 -0.1081934\nSDI  2.5606038 -0.2173132 -0.2471598\nProjector:\n          [,1]        [,2]         [,3]\nCC  -0.3721794 -0.17183725  0.076190649\nBA  -1.1048860  0.33478188 -0.006601565\nSDI  1.6069593 -0.04539735 -0.015080784\nCCA not run\nrandomForest not run\n0 y variables dropped   \n0 x variables dropped   \nNote: ann used\nFirst 10 targets:\n   Dst.k1      Dst.k2      Dst.k3     Dst.k4      Dst.k5     Dst.k6     Dst.k7\n1       0 0.022839131 0.024065301 0.02503445 0.027518941 0.02881239 0.02893608\n2       0 0.006833636 0.012532360 0.01348305 0.014832297 0.01727352 0.01826303\n3       0 0.011627065 0.013215233 0.01490622 0.015215686 0.02106584 0.02325435\n4       0 0.086915652 0.116651910 0.12766527 0.131262588 0.13309124 0.13377220\n5       0 0.005280908 0.009704220 0.01256398 0.012704678 0.01377202 0.01522488\n6       0 0.007397829 0.008049363 0.00863464 0.008844124 0.01264707 0.01301245\n7       0 0.007806150 0.012867828 0.02558227 0.026881552 0.02739568 0.02915953\n8       0 0.009487715 0.010230969 0.01516286 0.024068629 0.02695494 0.02706587\n9       0 0.008123271 0.033357538 0.03494585 0.043941166 0.04805847 0.05177362\n10      0 0.033440381 0.064661111 0.06648757 0.067584395 0.07127761 0.08327198\n       Dst.k8     Dst.k9    Dst.k10            Id.k1             Id.k2\n1  0.02899794 0.03009278 0.03176503 12964130010497_1 174763519020004_4\n2  0.02020276 0.02097464 0.02163351 12964130010497_2  48204206010497_2\n3  0.02391233 0.02428216 0.02613611 12964130010497_3  40220330010497_2\n4  0.13488224 0.13574756 0.14235163 12964130010497_4  24539823010900_3\n5  0.01568192 0.01861327 0.01911111 12966246010497_1 558630806126144_2\n6  0.01424728 0.01439073 0.01615086 12966246010497_2  22933087010497_3\n7  0.02985969 0.03253432 0.03301640 12966246010497_3  29881627010497_1\n8  0.02818138 0.02826890 0.03202578 12966246010497_4  22398485010497_4\n9  0.05481330 0.05506222 0.05621303 12992742010497_1  22827555010497_3\n10 0.08916667 0.10236031 0.10837711 12992742010497_2  29395694010497_3\n               Id.k3             Id.k4             Id.k5             Id.k6\n1   22399225010497_4 558629785126144_3 238861587489998_2  22827610010497_4\n2   24838588010900_4  22399221010497_3  29883411010497_1 444202393489998_4\n3   22398350010497_3  22398186010497_1  24199550010900_4  40220720010497_1\n4  345936102489998_2   8648137010901_4  29882757010497_2  29882045010497_3\n5   22398222010497_4   8603202010901_2 558630866126144_4  30763912020004_3\n6  273640495489998_1  22399225010497_3  24134547010900_2 193209107020004_3\n7  444202158489998_3  24195448010900_2  48202964010497_2 558629551126144_4\n8   29883214010497_2  22398995010497_2  22398261010497_1  22932917010497_1\n9   22399025010497_4  29883185010497_2  30764203020004_4  22398412010497_1\n10 490388204126144_3  22398585010497_2 174763488020004_2  22931272010497_4\n               Id.k7             Id.k8             Id.k9            Id.k10\n1  345934904489998_2  48206545010497_1 216959705020004_3 216958568020004_4\n2   40403568010497_1 412223102489998_3  44541780020004_4  29395607010497_3\n3  444202209489998_2  22398239010497_4  48206217010497_4  24833864010900_4\n4   22398806010497_3  48202991010497_4 273641507489998_3  22399205010497_3\n5   29883052010497_4  29395653010497_2  22931274010497_2  48203128010497_2\n6   40403580010497_3  40220779010497_1  22933263010497_2 273641521489998_1\n7   24488200010900_4  22399261010497_2  22954382010497_1  22398521010497_4\n8   40220254010497_3  29395646010497_2  22933264010497_2  22933304010497_3\n9  558629442126144_2 216958725020004_4 238861245489998_4  13039392010497_3\n10  13059631010497_4  22399040010497_4  22398574010497_2  22399032010497_2\nNo reference neighbors computed."
  },
  {
    "objectID": "2_Imputation.html#rf-with-categoricals",
    "href": "2_Imputation.html#rf-with-categoricals",
    "title": "Imputation",
    "section": "RF with categoricals",
    "text": "RF with categoricals\n\nKEEP &lt;- c(\"frf2_set\", \"KEEP\")\n\n\nrm(list = ls()[!ls() %in% KEEP])\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\nzimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\nrm(con)\n\nload(\"sp_prevalence.Rdata\")\n\n\nTest imp, full set.\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n  common = rowSums(imp_data_FPA[,sp_prevalence$common]),\n  uncommon = rowSums(imp_data_FPA[,sp_prevalence$uncommon]),\n  rare_TD = rowSums(imp_data_FPA[,sp_prevalence$rare]),\n  total_TD = rowSums((imp_data_FPA[, 6:39]))\n) |&gt;\n  select(-sp_prevalence$rare, -sp_prevalence$uncommon, -sp_prevalence$common)\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; \n  relocate(fpa, .after = FPAG)\n\n# I am removing the extra rows to speed up the imputation test. \nfpas &lt;- imp_data_FPA |&gt; \n  filter(\n    total_TD &gt; 0\n  )\n\nrefs &lt;- rownames(fpas[1:(3*nrow(fpas)/4),])\n\nx &lt;- fpas |&gt; select(1:5)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- fpas |&gt; select(1, 7:ncol(fpas))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\n\n\nas factor\nIt doesn’t like the categorical, but maybe I can do a dummy variable.\n\nx$FPAG &lt;- as.factor(x$FPAG)\n\nRunning the full set results in:\nError in randomForest.default(x = xRefs[, xN, FALSE], y = yone, proximity = FALSE, : Can not handle categorical predictors with more than 53 categories.\nNow I’ll use fewer categories.\n\nt &lt;- fpas |&gt; group_by(FPAG) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n)) |&gt; \n  filter(n &gt; 120)\nkeep &lt;- t$FPAG\n\nt2 &lt;- fpas |&gt; \n  filter(FPAG %in% keep)\n\nt2$FPAG &lt;- as.factor(t2$FPAG)\n\n\nrefs &lt;- rownames(t2[1:(3*nrow(t2)/4),])\n\nx &lt;- t2 |&gt; select(1:5)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- t2 |&gt; select(1, 7:ncol(t2))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\nyfull &lt;- remove_rownames(yfull)\nyfull &lt;- column_to_rownames(yfull, \"STANDPLOT_CN\")\n\nk = 10\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n# trf &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n\n# save(trf, file = \"trf.Rdata\")\nload(\"trf.Rdata\")\n\n\nplot(trf, vars = yvars(trf))\n# plot(rf, vars = yvars(rf))\n\ntrf_i &lt;- impute(trf, ancillaryData = y)"
  },
  {
    "objectID": "2_Imputation.html#plots",
    "href": "2_Imputation.html#plots",
    "title": "Imputation",
    "section": "Plots",
    "text": "Plots\nBest imp plot so far!\nThe first one (trf_i) is this imputation. It is using Fpag as a predictor on the those FPAGs that have at least 120 plots. The second is from the test imp. It is on the whole dataset without FPAG as a predictor.\nGenerally, I see the points coming away from the zero axis toward the 1:1 line. That is good news. I’d like to see these without the outliers.\n\npar(mar = c(1,2,3.2,1))\nplot(trf_i)\nplot(frf2_set)\n# xlim = c(1,10)\n\n\n\n\n\n\n\n\n\n\n\nUncommon and rare species seem to be mostly unaffected. total_TD might be a little worse.\n\npar(mar = c(1,2,3.2,1))\nplot(trf_i, \n     xlim = c(0, 10000),\n     ylim = c(0, 10000))\nplot(frf2_set, \n     xlim = c(0, 10000),\n     ylim = c(0, 10000))\n\n\n\n\n\n\n\n\n\n\n\n\npar(mar = c(1,2,3.2,1))\nplot(trf, vars = yvars(yrf))"
  },
  {
    "objectID": "4_Visualization.html",
    "href": "4_Visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "Take the k nn and make a distribution to get stochastic regen\n\nThe yai objects have the distances and nearest neighbors.\nyai$neiDstTrgs is a matrix of distances between a target and the k references.\nPick from those nn to get stochastic regen.\n\nTry to find the probability of regen in the RF tool, it may be from a different model.\n\nI must have been thinking of something else. I cannot find the probability.\n\n\nThere could be something in the idea of making a probability out of the distribution of nearest references that have regeneration. Say, if there were 10 NN and one had regen, but the others didn’t, it would be a ten percent chance of regen. Then recompute the yai distances for the stands with regen, but only include stands with seedlings.\n\nCan FPAG be a predictor in RF, it didn’t work in MSN. If so also try ecoregion.\n\n\nIt worked, and the imputed vs observed plots look pretty good.\nIt is better than the full set without FPAG as a predictor.\n\n\nCheck on using Climate water deficit?\n\nFind the data, consider the possibilities, and try to use it.\n\nCreate some visualizations for seedling density by predictor.\n\ndone:\n\nMake the FPAGs 3 digits, removing some specificity\n\nAt least in CDS6 vs CDS, it didn’t help much.\n\nAdd more data from eco-regions in the state and maybe further afield.\n\nIt doubled the number of plots available, but I only tested CDS\nIn both sets, about half the plots didn’t have seedlings.\nIt may be time to test more FPAGs.\n\n\nI am set up in the imputation page to try adding FPAG as a predictor in RF. If I can use categorical in RF, PHYSCLCD would probably be a good one. to try.\n\nThe knn distribution is in the"
  },
  {
    "objectID": "4_Visualization.html#to-do",
    "href": "4_Visualization.html#to-do",
    "title": "Visualization",
    "section": "",
    "text": "Take the k nn and make a distribution to get stochastic regen\n\nThe yai objects have the distances and nearest neighbors.\nyai$neiDstTrgs is a matrix of distances between a target and the k references.\nPick from those nn to get stochastic regen.\n\nTry to find the probability of regen in the RF tool, it may be from a different model.\n\nI must have been thinking of something else. I cannot find the probability.\n\n\nThere could be something in the idea of making a probability out of the distribution of nearest references that have regeneration. Say, if there were 10 NN and one had regen, but the others didn’t, it would be a ten percent chance of regen. Then recompute the yai distances for the stands with regen, but only include stands with seedlings.\n\nCan FPAG be a predictor in RF, it didn’t work in MSN. If so also try ecoregion.\n\n\nIt worked, and the imputed vs observed plots look pretty good.\nIt is better than the full set without FPAG as a predictor.\n\n\nCheck on using Climate water deficit?\n\nFind the data, consider the possibilities, and try to use it.\n\nCreate some visualizations for seedling density by predictor.\n\ndone:\n\nMake the FPAGs 3 digits, removing some specificity\n\nAt least in CDS6 vs CDS, it didn’t help much.\n\nAdd more data from eco-regions in the state and maybe further afield.\n\nIt doubled the number of plots available, but I only tested CDS\nIn both sets, about half the plots didn’t have seedlings.\nIt may be time to test more FPAGs.\n\n\nI am set up in the imputation page to try adding FPAG as a predictor in RF. If I can use categorical in RF, PHYSCLCD would probably be a good one. to try.\n\nThe knn distribution is in the"
  },
  {
    "objectID": "4_Visualization.html#species-per-subplots-per-fpag",
    "href": "4_Visualization.html#species-per-subplots-per-fpag",
    "title": "Visualization",
    "section": "Species per subplots per FPAG",
    "text": "Species per subplots per FPAG\n\n\nCode\n# Data tidying and access\nlibrary(tidyverse, quietly = T)\nlibrary(RSQLite)\n# library(readxl)\n# library(writexl)\n\n# yaImpute and related \nlibrary(yaImpute)\nlibrary(vegan)\nlibrary(randomForest)\n\n# plots and tables\nlibrary(esquisse)\nlibrary(knitr)\n\n# No sci-notation. \noptions(scipen = 999)\n\n\n\n\nCode\nload(\"dfs_0403/KEEP.Rdata\")\nrm(list = ls()[!ls() %in% KEEP])\n\nload(\"dfs_0403/fpas.Rdata\")\nload(\"dfs_0403/rf_all_ref2_i.Rdata\")\nload(\"dfs_0403/imp_data.Rdata\")\nload(\"dfs_0403/fpas_TD2900.Rdata\")\nload(\"dfs_0403/sp_prev_df.Rdata\")\n\n\n\n\nCode\ncon &lt;- dbConnect(RSQLite::SQLite(),  \"./attempt_032524.db\")\n# dbListTables(con)\ntree &lt;- dbGetQuery(con, \"select * from FVS_TREEINIT_PLOT\")\ndbDisconnect(con)\n\nseedling_densities &lt;- tree |&gt;  filter(startsWith(TREE_CN, \"S\")) |&gt; \n  group_by(STANDPLOT_CN, SPECIES) |&gt; \n  summarise(TPA = sum(TREE_COUNT))\n\n\n`summarise()` has grouped output by 'STANDPLOT_CN'. You can override using the\n`.groups` argument.\n\n\nCode\nclean_na_cols &lt;- function(df){\n  df &lt;- df[, colSums(is.na(df)) &lt; nrow(df)]\n}\nKEEP &lt;- append(KEEP, \"clean_na_cols\")\n\ntree &lt;- clean_na_cols(tree)\n\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"C:\\\\RxFire\\\\Data\\\\_FIADB_WA.db\")\n\n# Pulling in the species reference table\nplants_ref &lt;- dbGetQuery(\n  con, \"select SPECIES_SYMBOL, SPCD, COMMON_NAME, W_SPGRPCD from REF_SPECIES\"\n  )\nplant_gr_ref &lt;- dbGetQuery(\n  con, \"select SPGRPCD, NAME from REF_SPECIES_GROUP\"\n  )\ndbDisconnect(con)\n\n# Cleaning it up\nplants_ref &lt;- plants_ref |&gt; rename(SPGRPCD = W_SPGRPCD, SYMBL = SPECIES_SYMBOL)\nplants_ref &lt;- left_join(plants_ref, plant_gr_ref, by = join_by(SPGRPCD))\nplants &lt;- plants_ref |&gt; select(SYMBL, SPCD)\nseedling_densities &lt;- seedling_densities |&gt; mutate(SPECIES = as.numeric(SPECIES))\n\n# Getting plant codes for seedlings\nseedling_densities &lt;- left_join(seedling_densities, plants, join_by(\"SPECIES\" == \"SPCD\"))\n# Removing an extra col. \nseedling_densities &lt;- seedling_densities |&gt; select(-c(SPECIES))\n\n\nLook up the .groups argument. I always get that error when summarizing by two variables.\nThis will be the number of species per fpag for the fpags that are in the first set used in RF. It’s the 50 FPAGs with the most subplots. Off the top of my head it’s about 60 subplots to 2400 subplots.\n\n\nCode\nt &lt;- fpas |&gt; select(STANDPLOT_CN, FPAG)\nt &lt;- left_join(t, seedling_densities, by = join_by(STANDPLOT_CN))\n\nsum(is.na(t$TPA))\n\n\n[1] 11115\n\n\nCode\nt1 &lt;- t |&gt; mutate(\n  TPA = ifelse(is.na(TPA), 0, TPA), \n  SYMBL = ifelse(is.na(SYMBL), \"EMTY\", SYMBL)\n)\n\nnum_plts &lt;- t1\nnum_plts &lt;- num_plts |&gt; group_by(FPAG) |&gt; \n  summarise(n_plots = n_distinct(STANDPLOT_CN))\n\nt2 &lt;- t1 |&gt; group_by(FPAG, SYMBL) |&gt; \n  summarize(\n    n_plots_w_spp = n()\n  )\n\n\n`summarise()` has grouped output by 'FPAG'. You can override using the\n`.groups` argument.\n\n\nCode\nt2 &lt;- t2 |&gt; arrange(desc(n_plots_w_spp))\n\nfpags &lt;- t2$FPAG |&gt; unique()\n\nt2 |&gt; group_by(FPAG) |&gt; \n  summarise(num_spp_per_fpag = n_distinct(SYMBL)) |&gt; \n  arrange(desc(num_spp_per_fpag)) |&gt; head(n = 5)\n\n\n\n\n\n\nFPAG\nnum_spp_per_fpag\n\n\n\n\nCD\n23\n\n\nCHS1\n23\n\n\nCDS6\n22\n\n\nCES4\n21\n\n\nCH\n21\n\n\n\n\n\n\nCode\nt2 &lt;- left_join(t2, sp_prev_df, join_by(SYMBL, FPAG)) |&gt;\n  select(-sum_TPA, -TPA_all_spp, - percent) |&gt; \n    mutate(prev = ifelse(is.na(prev), \"empty\", prev),\n           color = ifelse(is.na(color), \"grey\", color))\n\n\n11115 of 29124 rows in t are NAs. I think those are the rows where there are no seedlings.\n\nPlots with emtpy subplots.\nThere are 50 graphs for 50 FPAGs with 22721 subplots in total. The bars represent the number of plots that have a given species in that FPAG. They’re small, but grey is for empty subplots, blue is for ubiquitous trees within that fpag, then green, orange, yellow, red for prevalent to rare. The cutoffs for these categories are 2.5, 10, 25, 55 percent of seedlings in the FPAG.\nThese categories are for prevalence per FPAG. Some of the other plots I made are by overall prevalence in the whole set.\n\n\nCode\nm &lt;- 1\nn &lt;- 50\n# \n# num_plts[num_plts$FPAG %in% fpags[m:n],] |&gt; arrange(desc(n_plots))\n\n\nfor (i in fpags[m:n]) {\n  # print(i)\n  p &lt;- t2[t2$FPAG == i,] |&gt;\n    ggplot() +\n    aes(x = reorder(SYMBL, desc(n_plots_w_spp)), y = n_plots_w_spp, fill = color) +\n    geom_col(show.legend = FALSE) +\n    scale_fill_identity(labels = c('Ubiq', 'Prev', 'Com', 'Uncom', 'Rare', \"Empty\"), guide = \"legend\") +\n    guides(fill = guide_legend(title = \"Prev\")) +\n    scale_x_discrete(guide = guide_axis(angle = 90)) +\n    labs(title = i,\n         subtitle = str_c(\"Total Num Plots = \", num_plts[num_plts$FPAG == i, 2])) +\n    xlab(\"Species per FPAG\")\n\n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlots without empties\nThis is the same as before, but I removed the empty plots to see the actual species per fpag.\n\n\nCode\nm &lt;- 1\nn &lt;- 50\n\n# num_plts[num_plts$FPAG %in% fpags[m:n],] |&gt; arrange(desc(n_plots))\n\nfor (i in fpags[m:n]) {\n  # print(i)\n  p &lt;- t2[t2$FPAG == i,] |&gt; filter(SYMBL != \"EMTY\") |&gt; \n    ggplot() +\n    aes(x = reorder(SYMBL, desc(n_plots_w_spp)), y = n_plots_w_spp, fill = color) +\n    geom_col()  +\n    scale_fill_identity(labels = c('Ubiq', 'Prev', 'Com', 'Uncom', 'Rare', \"Empty\"), guide = \"legend\") +\n    guides(fill = guide_legend(title = \"Prev\")) +\n    scale_x_discrete(guide = guide_axis(angle = 90)) +\n    labs(title = i,\n         subtitle = str_c(\"Total Num Plots = \", num_plts[num_plts$FPAG == i, 2])) +\n    xlab(\"Species per FPAG\")\n\n  print(p)\n\n}"
  },
  {
    "objectID": "4_Visualization.html#tpa-per-species-per-fpag",
    "href": "4_Visualization.html#tpa-per-species-per-fpag",
    "title": "Visualization",
    "section": "TPA per Species per FPAG",
    "text": "TPA per Species per FPAG\nSumming all the TPAs per FPAG and Species.\n\n\nCode\ntt &lt;- t |&gt; drop_na() |&gt; group_by(FPAG, SYMBL) |&gt; \n  summarize(sum_TPA = sum(TPA))\n\n\n`summarise()` has grouped output by 'FPAG'. You can override using the\n`.groups` argument.\n\n\nCode\ns &lt;- sp_prev_df |&gt; select(FPAG, SYMBL, prev, color)\ntt &lt;- left_join(tt, s, join_by(FPAG, SYMBL))\ntt |&gt; head()\n\n\n\n\n\n\nFPAG\nSYMBL\nsum_TPA\nprev\ncolor\n\n\n\n\nCAC1\nABAM\n2773.7155\nuncom\norange\n\n\nCAC1\nABLA\n43554.8291\nprev\ngreen\n\n\nCAC1\nLALY\n29011.5643\nprev\ngreen\n\n\nCAC1\nLAOC\n749.6528\nrare\nred\n\n\nCAC1\nPIAL\n4273.0211\nuncom\norange\n\n\nCAC1\nPIEN\n2623.7849\nuncom\norange\n\n\n\n\n\n\n\nPlots with rare trees\nThese will look almost identical to the Spp per subplot per FPAG ones, but now they show the total number of trees.\n\n\nCode\nm &lt;- 1\nn &lt;- 12\n\n# num_plts[num_plts$FPAG %in% fpags[m:n],] |&gt; arrange(desc(n_plots))\n\nfor (i in fpags[m:n]) {\n  # print(i)\n  p &lt;- tt[tt$FPAG == i,] |&gt; filter(SYMBL != \"EMTY\") |&gt; \n    ggplot() +\n    aes(x = reorder(SYMBL, desc(sum_TPA)), y = sum_TPA, fill = color) +\n    geom_col()  +\n    scale_fill_identity(labels = c('Ubiq', 'Prev', 'Com', 'Uncom', 'Rare', \"Empty\"), guide = \"legend\") +\n    guides(fill = guide_legend(title = \"Prev\")) +\n    scale_x_discrete(guide = guide_axis(angle = 90)) +\n    labs(title = i,\n         subtitle = str_c(\"Total Num Plots = \", unique(tt[tt$FPAG == i, 1]))) +\n    xlab(\"Species per FPAG\")\n\n  print(p)\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspp prevalence\nThis is not to be confused with what I did in a different document using quantiles. This is in an attempt to refine that, so that I am not adding garbage when/if I run the RF by FPAG. I want to know which species should be ignored in each FPAG.\nHere is the distribution of percent by all spp. Left to right, I am zooming in.\n\n\nCode\nttt &lt;- tt |&gt; group_by(FPAG) |&gt; summarise(TPA_all_spp = sum(sum_TPA))\nt4 &lt;- left_join(tt, ttt, by = 'FPAG')\nt4 &lt;- t4 |&gt; mutate(percent = (sum_TPA/TPA_all_spp)*100)\nt5 &lt;- t4 |&gt; filter(percent &gt; 2.5)\n\nhist(t4$percent, breaks = 100)\nhist(t4$percent, breaks = 100,\n     xlim = c(0,10))\nhist(t4$percent, breaks = 100,\n     xlim = c(10, 50))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is a list of species prevalence. The cutoffs are pretty arbitrary. Other than rare, I just wanted a nice amount in each list.\n\n\nCode\nr &lt;- 2.5\nu &lt;- 10\nc &lt;- 25\np &lt;- 55\n\nrare_spp_by_fpag &lt;- t4 |&gt; filter(percent &lt; 2.5) |&gt; group_by(FPAG) |&gt; \n  summarise(spp = list(unique(SYMBL))) |&gt; \n  unnest(cols = c(spp))\n\nuncommon &lt;- t4 |&gt; filter(percent &gt;= r & percent &lt; u) |&gt; group_by(FPAG) |&gt; \n  summarise(spp = list(unique(SYMBL))) |&gt; \n  unnest(cols = c(spp))\n\ncommon &lt;- t4 |&gt; filter(percent &gt;= u & percent &lt; c) |&gt; group_by(FPAG) |&gt; \n  summarise(spp = list(unique(SYMBL))) |&gt; \n  unnest(cols = c(spp))\n\nprevalent &lt;- t4 |&gt; filter(percent &gt;= c & percent &lt; p) |&gt; group_by(FPAG) |&gt; \n  summarise(spp = list(unique(SYMBL))) |&gt; \n  unnest(cols = c(spp))\n\nubiquitous &lt;- t4 |&gt; filter(percent &gt;= p) |&gt; group_by(FPAG) |&gt; \n  summarise(spp = list(unique(SYMBL))) |&gt; \n  unnest(cols = c(spp))\n\n\nrare &lt;- unique(rare_spp_by_fpag$spp) |&gt; sort()\nuncommon &lt;- unique(uncommon$spp) |&gt; sort()\ncommon &lt;- unique(common$spp) |&gt; sort()\nprevalent &lt;- unique(prevalent$spp) |&gt; sort()\nubiquitous &lt;- unique(ubiquitous$spp) |&gt; sort()\n\n\n\nprevalent &lt;- prevalent[!prevalent %in% ubiquitous]\n\ncommon &lt;- common[!common %in% ubiquitous]\ncommon &lt;- common[!common %in% prevalent]\n\nuncommon &lt;- uncommon[!uncommon %in% ubiquitous]\nuncommon &lt;- uncommon[!uncommon %in% common]\nuncommon &lt;- uncommon[!uncommon %in% prevalent]\n\nrare &lt;- rare[!rare %in% ubiquitous]\nrare &lt;- rare[!rare %in% uncommon]\nrare &lt;- rare[!rare %in% common]\nrare &lt;- rare[!rare %in% prevalent]\n\nsp_prev2 &lt;- list(\n  ubiquitous = ubiquitous,\n  prevalent = prevalent,\n  common = common,\n  uncommon = uncommon,\n  rare = rare)\n\nsp_prev2\n\n\n$ubiquitous\n[1] \"ABAM\" \"ABGR\" \"ABLA\" \"PIPO\" \"PSME\" \"TSHE\"\n\n$prevalent\n[1] \"ACGL\"  \"FRLA\"  \"LALY\"  \"PICO\"  \"PRVI\"  \"QUGA4\" \"THPL\" \n\n$common\n[1] \"LAOC\"  \"PIAL\"  \"PIEN\"  \"POTR5\" \"TSME\" \n\n$uncommon\n[1] \"ABPR\"  \"ACMA3\" \"ALRU2\" \"BEPA\"  \"CHNO\"  \"MAFU\"  \"PIMO3\" \"PREM\"  \"TABR2\"\n\n$rare\n [1] \"2TB\"   \"ABCO\"  \"ALRH2\" \"ARME\"  \"BEOC2\" \"CONU4\" \"JUOC\"  \"PISI\"  \"POBAT\"\n[10] \"PRAV\"  \"PRPE2\" \"PSMA\" \n\n\nThis is what I had for prevalence before. I added an extra level. Some stuff was moved around.\n\n\nCode\nload(\"sp_prevalence.Rdata\")\nsp_prevalence\n\n\n$prevalent\n[1] \"PSME_TD\" \"ABAM_TD\" \"ABLA_TD\" \"TSHE_TD\"\n\n$common\n[1] \"PIPO_TD\"  \"TSME_TD\"  \"ABGR_TD\"  \"THPL_TD\"  \"PIEN_TD\"  \"PICO_TD\"  \"PIMO3_TD\"\n\n$uncommon\n[1] \"PIAL_TD\"  \"ACGL_TD\"  \"LAOC_TD\"  \"TABR2_TD\" \"CHNO_TD\"  \"POTR5_TD\"\n\n$rare\n [1] \"LALY_TD\"  \"BEPA_TD\"  \"PREM_TD\"  \"ABPR_TD\"  \"PRVI_TD\"  \"ALRU2_TD\"\n [7] \"QUGA4_TD\" \"CONU4_TD\" \"ACMA3_TD\" \"JUOC_TD\"  \"FRLA_TD\"  \"2TB_TD\"  \n[13] \"POBAT_TD\" \"MAFU_TD\"  \"ARME_TD\"  \"ABCO_TD\"  \"PISI_TD\"  \"PSMA_TD\" \n[19] \"ALRH2_TD\" \"JUNI_TD\"  \"BEUT_TD\"  \"BEOC2_TD\" \"PRPE2_TD\" \"JUHI_TD\" \n[25] \"CHLA_TD\"  \"PRAV_TD\" \n\n\nThis is where I start to make a df, that I then add back in the beginning to color everything the same.\nsp_prev3 is prevalence across the whole dataset.\n\n\nCode\nsp_prev3 &lt;- tibble(SYMBL = sp_prev2) |&gt; unnest(SYMBL) |&gt; \n  mutate(\n    prev = ifelse(SYMBL %in% ubiquitous, \"Ubiq\", \"null\"),\n    prev = ifelse(SYMBL %in% prevalent, \"Prev\", prev),\n    prev = ifelse(SYMBL %in% common, \"Comm\", prev),\n    prev = ifelse(SYMBL %in% uncommon, \"Uncom\", prev),\n    prev = ifelse(SYMBL %in% rare, \"Rare\", prev)\n  )\n\nsp_prev3 &lt;- sp_prev3 |&gt; mutate(\n  color = ifelse(SYMBL %in% ubiquitous, \"blue\", \"null\"),\n  color = ifelse(SYMBL %in% prevalent, \"green\", color),\n  color = ifelse(SYMBL %in% common, \"yellow\", color),\n  color = ifelse(SYMBL %in% uncommon, \"orange\", color),\n  color = ifelse(SYMBL %in% rare, \"red\", color)\n)\n\n# save(sp_prev3, file = \"dfs_0403/sp_prev3.Rdata\")\n\n\n\n\n\nPlots without rare trees.\nThese plots do not contain species that represent less than 2.5% of the total TPA for a given FPAG. They are arranged in order of decreasing number of plots per FPAG. Species are on the x axis and the sum of Trees per acre for that species is on the y.\n\n\nCode\nt5 &lt;- t4 |&gt; filter(percent &gt; 2.5)\n\n\nm &lt;- 1\nn &lt;- 50\n\n\nfor (i in fpags[m:n]) {\n  # print(i)\n  p &lt;- t5[t5$FPAG == i,] |&gt; filter(SYMBL != \"EMTY\") |&gt; \n    ggplot() +\n    aes(x = reorder(SYMBL, desc(sum_TPA)), y = sum_TPA, fill = color) +\n    geom_col()  +\n    scale_fill_identity(labels = c('Ubiq', 'Prev', 'Com', 'Uncom', 'Rare'), guide = \"legend\") +\n    scale_x_discrete(guide = guide_axis(angle = 90)) +\n    guides(fill = guide_legend(title = \"Prev\")) +\n    labs(title = i,\n         subtitle = str_c(\"Total Num Plots = \", unique(t5[t5$FPAG == i, 1]))) +\n    xlab(\"Species per FPAG\")\n\n  print(p)\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsaving prev by fpag\n\nr &lt;- 2.5\nu &lt;- 10\nc &lt;- 25\np &lt;- 55\n\n\nsp_prev_df &lt;- t4 |&gt; mutate(\n  prev = ifelse(percent &lt; r, \"rare\", \"null\"),\n  prev = ifelse(percent &gt;= r & percent &lt; u, \"uncom\", prev),\n  prev = ifelse(percent &gt;= u & percent &lt; c, \"com\", prev),\n  prev = ifelse(percent &gt;= c & percent &lt; p, \"prev\", prev),\n  prev = ifelse(percent &gt;= p, \"ubiq\", prev), \n  \n  color = ifelse(percent &lt; r, \"red\", NA),\n  color = ifelse(percent &gt;= r & percent &lt; u , \"orange\", color),\n  color = ifelse(percent &gt;= u & percent &lt; c , \"yellow\", color),\n  color = ifelse(percent &gt;= c & percent &lt; p , \"green\", color),\n  color = ifelse(percent &gt;= p, \"blue\", color)\n)\n# save(sp_prev_df, file = \"dfs_0403/sp_prev_df.Rdata\")"
  },
  {
    "objectID": "6_Model_Eval_2.html",
    "href": "6_Model_Eval_2.html",
    "title": "Model Eval 2",
    "section": "",
    "text": "Random Forests with all the predictors on a dataset that has the largest 2.5% fo values clipped seems to be a pretty good model. By good I mean that for a given species or species group, there is roughly as much variation from the imputation as there is within the species.\nThe only other thing I can think to try is to subset it by FPAG and run them without any crossover. I can’t help but think that would reduce the variation. RF is saying that the FPAGs aren’t a good predictor though.\nI still haven’t added ecoregion as a factor.\nMy options are:\n\nTo go ahead and see if I can now get this model to run in FVS (and maybe try and compare it against the inland empires full regen model),\nAdd eco-region and see how that compares.\nTry to run it as a series of subsets."
  },
  {
    "objectID": "6_Model_Eval_2.html#summary",
    "href": "6_Model_Eval_2.html#summary",
    "title": "Model Eval 2",
    "section": "",
    "text": "Random Forests with all the predictors on a dataset that has the largest 2.5% fo values clipped seems to be a pretty good model. By good I mean that for a given species or species group, there is roughly as much variation from the imputation as there is within the species.\nThe only other thing I can think to try is to subset it by FPAG and run them without any crossover. I can’t help but think that would reduce the variation. RF is saying that the FPAGs aren’t a good predictor though.\nI still haven’t added ecoregion as a factor.\nMy options are:\n\nTo go ahead and see if I can now get this model to run in FVS (and maybe try and compare it against the inland empires full regen model),\nAdd eco-region and see how that compares.\nTry to run it as a series of subsets."
  },
  {
    "objectID": "6_Model_Eval_2.html#notes",
    "href": "6_Model_Eval_2.html#notes",
    "title": "Model Eval 2",
    "section": "Notes",
    "text": "Notes\nThere were several peculiarities that popped up in the last Model Eval section.\nThe rmsds between the distance matrices and the random forests didn’t make a lot of sense. There were NAs in the RF imputations that I didn’t think should have been there. The physical cd that I added a while back is being listed as a negatively important variable. I think that means that it is hurting the process. I am going to get all of these onto the same page. That should take care of the NAs and give me a better understanding of the rmsds.\nyaImpute Paper\nyaImpute package info\nBreiman L (2001). “Random Forests.” Machine Learning, Breiman L 2001\nClassification and Regression by randomForest Liam & Wiener, p.18"
  },
  {
    "objectID": "6_Model_Eval_2.html#setup",
    "href": "6_Model_Eval_2.html#setup",
    "title": "Model Eval 2",
    "section": "Setup",
    "text": "Setup\n\n\nCode\n# Data tidying and access\nlibrary(tidyverse, quietly = T)\nlibrary(RSQLite)\n# library(readxl)\n# library(writexl)\n\n# yaImpute and related \nlibrary(yaImpute)\nlibrary(vegan)\nlibrary(randomForest)\n\n# plots and tables\nlibrary(esquisse)\nlibrary(knitr)\n\n# No sci-notation. \noptions(scipen = 999)\n\n\n\nPull in data\n\n\nCode\nKEEP &lt;- c(\"KEEP\")\nrm(list = ls()[!ls() %in% KEEP])\n\n# Pulling from my new interim save point\ncon &lt;- dbConnect(RSQLite::SQLite(), \"./attempt_032524.db\")\nimp_data &lt;- dbGetQuery(con, \"select * from imp_data\")\n# zimp_data &lt;- dbGetQuery(con, \"select * from regen_only_imp_data\")\nplots &lt;- dbGetQuery(con, \"select * from fvs_plotinit_plot\")\nplants_ref &lt;- dbGetQuery(con, \"select * from plants_ref\")\ndbDisconnect(con)\n\n# sp_prev was saved from imutation 1\nload(\"sp_prevalence.Rdata\")\n\ncon &lt;- dbConnect(RSQLite::SQLite(), \"../../Data/_FIADB_WA.db\")\ncond &lt;- dbGetQuery(con, \"select PLT_CN, CONDID, PHYSCLCD from cond\")\ndbDisconnect(con)\n\nKEEP &lt;- append(KEEP, c(\"cond\", 'plots', 'plants_ref', 'imp_data', \"sp_prevalence\"))\n\ng &lt;- read_csv(\"./good_SUB_plots2.csv\", \n              col_types = c(\"cccci\"))\n\n\n\nAdd predictors\n\n\nCode\npred_topo &lt;- plots |&gt; select(STANDPLOT_CN, ELEVFT, SLOPE, ASPECT)\n\npred_Kral &lt;- imp_data |&gt; select(STANDPLOT_CN, CC, BA, SDI, FPAG)\n\nresponse &lt;- imp_data |&gt; select(-c(CC, BA, SDI, FPAG))\n\npredictors &lt;- left_join(pred_Kral, pred_topo, join_by(STANDPLOT_CN))|&gt; \n  relocate(FPAG, .after = STANDPLOT_CN)\n\ng &lt;- left_join(g, cond, join_by(PLT_CN, CONDID))\n\ng &lt;- g |&gt; mutate(\n  STANDPLOT_CN = str_c(PLT_CN, \"_\", SUBP)) |&gt; \n  select(-SUBPLOT_CN)\n\nx &lt;- left_join(plots, g, join_by(STANDPLOT_CN))\ny &lt;- x |&gt; select(STANDPLOT_CN, PHYSCLCD)\n\nimp_data &lt;- left_join(imp_data, y, join_by(STANDPLOT_CN))\nimp_data &lt;- imp_data |&gt; relocate(PHYSCLCD, .after = FPAG)\n\ny &lt;- predictors |&gt; select(STANDPLOT_CN, ELEVFT, SLOPE, ASPECT)\nimp_data &lt;- left_join(imp_data, y, join_by(STANDPLOT_CN))\nimp_data &lt;- imp_data |&gt; relocate(ELEVFT, SLOPE, ASPECT, .after = SDI)\n\n\n\n\nfpa and species\n\n\nCode\nrm(list = ls()[!ls() %in% KEEP])\n\nimp_data_FPA &lt;- imp_data |&gt; \n  mutate(\n    fpa = str_sub(FPAG, 1, 3)\n  )\n\nKEEP &lt;- append(KEEP, \"imp_data_FPA\")\n\nimp_data_FPA &lt;- imp_data_FPA |&gt;  mutate(\n  # common = rowSums(imp_data_FPA[,sp_prevalence$common]),\n  uncommon = rowSums(imp_data_FPA[,sp_prevalence$uncommon]),\n  rare = rowSums(imp_data_FPA[,sp_prevalence$rare]),\n  total_TD = rowSums(imp_data_FPA[grep(\"_TD\", names(imp_data_FPA))])\n) |&gt;\n  select(-sp_prevalence$rare, -sp_prevalence$uncommon) #, -sp_prevalence$common\n\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; \n  relocate(fpa, .after = FPAG)\n\nimp_data_FPA &lt;- imp_data_FPA |&gt; relocate(PHYSCLCD, .before = FPAG)\n\n\n\n\nCorrecting for levels.\n\n\nCode\nfpas &lt;- imp_data_FPA\n\n\nKEEP &lt;- append(KEEP, \"fpas\")\n\n# Removing the fpags with less than 120 plots. \n# This needs to happen for RF. Must be less than 53. \nt &lt;- fpas |&gt; group_by(FPAG) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(desc(n)) |&gt; \n  filter(n &gt; 64)\n\nkeep &lt;- t$FPAG\n\nfpas &lt;- fpas |&gt; \n  filter(FPAG %in% keep)\n\n# I am not sure this is the way to set levels. \nfpas$FPAG &lt;- factor(fpas$FPAG, levels = keep)\nfpas$fpa &lt;- as.factor(fpas$fpa)\nfpas$PHYSCLCD &lt;- as.factor(fpas$PHYSCLCD)\n\n\nI could do it via fpa instead of FPAG.\n1900 rows lost due to factor levels."
  },
  {
    "objectID": "6_Model_Eval_2.html#yai-objects",
    "href": "6_Model_Eval_2.html#yai-objects",
    "title": "Model Eval 2",
    "section": "yai objects",
    "text": "yai objects\nK is being set to one for this iteration. I don’t want there to be additional error due to the averaging of y variables. I just want to know which imputation has the smallest difference.\n\n\nCode\nrm(list = ls()[!ls() %in% KEEP])\n\nrefs &lt;- rownames(fpas[1:(3*nrow(fpas)/4),])\n\n# X variables\nnames(fpas)[1:10]\n\n\n [1] \"STANDPLOT_CN\" \"CC\"           \"BA\"           \"SDI\"          \"ELEVFT\"      \n [6] \"SLOPE\"        \"ASPECT\"       \"PHYSCLCD\"     \"FPAG\"         \"fpa\"         \n\n\nCode\nx &lt;- fpas |&gt; select(STANDPLOT_CN, CC, BA, SDI, ELEVFT, SLOPE, ASPECT, PHYSCLCD, FPAG)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\n# Y variables\nnames(fpas)[11:ncol(fpas)]\n\n\n [1] \"ABGR_TD\"  \"PIPO_TD\"  \"PSME_TD\"  \"ABLA_TD\"  \"TSME_TD\"  \"ABAM_TD\" \n [7] \"THPL_TD\"  \"PIEN_TD\"  \"TSHE_TD\"  \"PICO_TD\"  \"PIMO3_TD\" \"uncommon\"\n[13] \"rare\"     \"total_TD\"\n\n\nCode\nyfull &lt;- fpas |&gt; select(1, 11:ncol(fpas))\ny &lt;- yfull[refs,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\n# can't have factors in msn or mal\nx6 &lt;- x |&gt; select(-FPAG, -PHYSCLCD)\n\nk = 1\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\n\n\nmsn & mal 6\n\n\nCode\nmsn_x6_ps &lt;- yai(x = x6, y = y, method = \"msn\", k = k)\nmal_x6_ps &lt;- yai(x = x6, y = y, method = \"mahalanobis\", k = k)\n\nKEEP &lt;- KEEP |&gt; append(c(\"refs\", 'msn_x6_ps', 'mal_x6_ps', 'rf_all_ps', 'k'))\nKEEP &lt;- KEEP |&gt; unique() |&gt; sort()\n\n\n\n\nRF all\n\n# Separating this because it takes a long time and I don't want to run in by accident. \n# rf_all_ps &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n# save(rf_all_ps, file = \"imps_0402/rf_all_ps.Rdata\")\n\n\n\nRF 6\n\n# Separating this because it takes a long time and I don't want to run in by accident. \n# rf_k6_ps &lt;- yai(x = x6, y = yrf, method = \"randomForest\", k = k)\n# save(rf_k6_ps, file = \"imps_0402/rf_k6_ps.Rdata\")\n\n\n\nKralicek 3 msn & mal\n\n\nCode\nx3 &lt;- x |&gt; select(CC, BA, SDI)\n\nmsn_k3_ps &lt;- yai(x = x3, y = y, method = \"msn\", k = k)\nmal_k3_ps &lt;- yai(x = x3, y = y, method = \"mahalanobis\", k = k)\n\nKEEP &lt;- KEEP |&gt; append(c('mal_k3_ps', 'msn_k3_ps', 'rf_k3_ps'))\n\n\n\nRF k3\n\n# Separating this because it takes a long time and I don't want to run in by accident. \n# rf_k3_ps &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n# save(rf_k3_ps, file = \"imps_0402/rf_k3_ps.Rdata\")"
  },
  {
    "objectID": "6_Model_Eval_2.html#imputations",
    "href": "6_Model_Eval_2.html#imputations",
    "title": "Model Eval 2",
    "section": "imputations",
    "text": "imputations\n\n\nCode\nload(\"imps_0402/rf_all_ps.Rdata\")\nload(\"imps_0402/rf_k6_ps.Rdata\")\nload(\"imps_0402/rf_k3_ps.Rdata\")\n\nrf_all_ps_i &lt;- impute(rf_all_ps, ancillaryData = y)\nrf_x6_ps_i &lt;- impute(rf_k6_ps, ancillaryData = y)\nrf_k3_ps_i &lt;- impute(rf_k3_ps, ancillaryData = y)\n\n\nKEEP &lt;- append(KEEP, c('rf_k3_ps_i', 'rf_all_ps_i', 'rf_x6_ps_i'))\nKEEP &lt;- KEEP |&gt; unique() |&gt; sort()\nrm(list = ls()[!ls() %in% KEEP])\n\n\n\n\nCode\nmsn_x6_i &lt;- impute(msn_x6_ps)\nmsn_k3_i &lt;- impute(msn_k3_ps)\n\nmal_x6_i &lt;- impute(mal_x6_ps)\nmal_k3_i &lt;- impute(mal_k3_ps)"
  },
  {
    "objectID": "6_Model_Eval_2.html#checking-for-nas",
    "href": "6_Model_Eval_2.html#checking-for-nas",
    "title": "Model Eval 2",
    "section": "Checking for NAs",
    "text": "Checking for NAs\n\n\nCode\nsum(is.na(rf_all_ps_i$PSME_TD))\n\n\n[1] 0\n\n\nCode\nsum(is.na(rf_k3_ps_i$PSME_TD))\n\n\n[1] 0\n\n\nCode\nsum(is.na(rf_x6_ps_i$PSME_TD))\n\n\n[1] 0\n\n\nCode\nsum(is.na(msn_k3_i$PSME_TD))\n\n\n[1] 0\n\n\nCode\nsum(is.na(msn_x6_i$PSME_TD))\n\n\n[1] 0\n\n\nCode\nsum(is.na(mal_k3_i$PSME_TD))\n\n\n[1] 0\n\n\nCode\nsum(is.na(mal_x6_i$PSME_TD))\n\n\n[1] 0\n\n\nWhatever happened on the last page, isn’t on this one. Crisis averted!"
  },
  {
    "objectID": "6_Model_Eval_2.html#evaluation",
    "href": "6_Model_Eval_2.html#evaluation",
    "title": "Model Eval 2",
    "section": "Evaluation",
    "text": "Evaluation\n\nmsn and mal\n\n\nCode\nt_ns &lt;- compare.yai(msn_k3_i, mal_k3_i, msn_x6_i, mal_x6_i,  scale = F)\nt &lt;- compare.yai(msn_k3_i, mal_k3_i, msn_x6_i, mal_x6_i)\n\n\n\n\nCode\nplot(t_ns, main = \"Not Scaled\")\nplot(t, main = \"Scaled\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nt_ns$min &lt;- names(t_ns)[apply(t_ns, 1, which.min)]\nt_ns$min &lt;- t_ns$min |&gt; str_sub(1, 6)\nt_ns|&gt; arrange(min)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmsn_k3_i.rmsdS\nmal_k3_i.rmsdS\nmsn_x6_i.rmsdS\nmal_x6_i.rmsdS\nmin\n\n\n\n\ntotal_TD\n585.07073\n461.64113\n701.41423\n754.46481\nmal_k3\n\n\nABGR_TD\n319.72928\n304.96928\n309.58660\n277.73063\nmal_x6\n\n\nPSME_TD\n299.15199\n319.17541\n289.30718\n274.08248\nmal_x6\n\n\nABLA_TD\n354.62707\n364.07637\n282.62389\n261.73287\nmal_x6\n\n\nTSME_TD\n100.29573\n95.66929\n98.06111\n88.05078\nmal_x6\n\n\nABAM_TD\n350.82582\n355.36147\n318.73906\n289.84361\nmal_x6\n\n\nTHPL_TD\n216.63917\n218.29978\n231.77892\n183.14742\nmal_x6\n\n\nPICO_TD\n351.38847\n324.29968\n325.26841\n315.22969\nmal_x6\n\n\nPIMO3_TD\n53.32482\n55.05028\n52.79650\n51.02393\nmal_x6\n\n\nrare\n197.38858\n203.64440\n206.30725\n190.10477\nmal_x6\n\n\nuncommon\n264.60082\n323.76737\n301.79829\n309.27698\nmsn_k3\n\n\nPIPO_TD\n115.15612\n113.16129\n106.67592\n125.99836\nmsn_x6\n\n\nPIEN_TD\n300.69036\n299.00754\n293.53857\n300.22660\nmsn_x6\n\n\nTSHE_TD\n521.38882\n402.57062\n401.49311\n508.01034\nmsn_x6\n\n\n\n\n\n\nCode\nqplot(t_ns$min)\n\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\nRFs\n\n\nCode\n# msn_k3_i, mal_k3_i, msn_x6_i, mal_x6_i, msn_all_i, mal_all_i,\nt_ns &lt;- compare.yai(rf_k3_ps_i, rf_x6_ps_i, rf_all_ps_i , scale = F)\nt &lt;- compare.yai(rf_k3_ps_i, rf_x6_ps_i, rf_all_ps_i)\nt\n\n\n\n\n\n\n\nrf_k3_ps_i.rmsdS\nrf_x6_ps_i.rmsdS\nrf_all_ps_i.rmsdS\n\n\n\n\nABGR_TD\n0.9357818\n0.9561259\n0.9303990\n\n\nPIPO_TD\n0.9525472\n1.0574433\n0.9735447\n\n\nPSME_TD\n1.0336982\n1.0387179\n1.0214409\n\n\nABLA_TD\n0.8715753\n0.9154921\n0.8826580\n\n\nTSME_TD\n1.0695598\n1.1640388\n1.0426396\n\n\nABAM_TD\n0.8400696\n0.8292489\n0.8588616\n\n\nTHPL_TD\n0.8931089\n0.9433035\n0.9146314\n\n\nPIEN_TD\n0.9913967\n1.0137402\n0.9795178\n\n\nTSHE_TD\n0.9908758\n0.9478163\n0.9972419\n\n\nPICO_TD\n0.8409484\n0.9047692\n0.8193283\n\n\nPIMO3_TD\n1.3297653\n1.2056393\n1.2933039\n\n\nuncommon\n1.0322185\n1.2693361\n1.0582116\n\n\nrare\n1.0215080\n1.2091474\n1.0251585\n\n\ntotal_TD\n0.8804059\n0.7769208\n0.8819280\n\n\n\n\n\n\n\n\nCode\nplot(t_ns, main = \"Not Scaled\")\nplot(t, main = \"Scaled\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nt_ns$min &lt;- names(t_ns)[apply(t_ns, 1, which.min)]\nt_ns$min &lt;- t_ns$min |&gt; str_sub(1, 6)\nt_ns|&gt; arrange(min)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrf_k3_ps_i.rmsdS\nrf_x6_ps_i.rmsdS\nrf_all_ps_i.rmsdS\nmin\n\n\n\n\nABGR_TD\n239.49222\n244.69883\n238.11462\nrf_all\n\n\nPSME_TD\n243.54849\n244.73117\n240.66058\nrf_all\n\n\nTSME_TD\n77.74687\n84.61460\n75.79003\nrf_all\n\n\nPIEN_TD\n279.91061\n286.21907\n276.55670\nrf_all\n\n\nPICO_TD\n269.42713\n289.87433\n262.50039\nrf_all\n\n\nPIPO_TD\n92.76392\n102.97923\n94.80876\nrf_k3_\n\n\nABLA_TD\n259.30735\n272.37329\n262.60464\nrf_k3_\n\n\nTHPL_TD\n167.83196\n177.26447\n171.87645\nrf_k3_\n\n\nuncommon\n280.03253\n344.36063\n287.08426\nrf_k3_\n\n\nrare\n152.21296\n180.17276\n152.75692\nrf_k3_\n\n\nABAM_TD\n257.22524\n253.91199\n262.97926\nrf_x6_\n\n\nTSHE_TD\n479.05363\n458.23585\n482.13140\nrf_x6_\n\n\nPIMO3_TD\n52.03200\n47.17511\n50.60531\nrf_x6_\n\n\ntotal_TD\n874.71763\n771.90113\n876.22994\nrf_x6_\n\n\n\n\n\n\nCode\nqplot(t_ns$min)\n\n\n\n\n\n\n\nrf vs msn\n\n\nCode\n# msn_k3_i, mal_k3_i, msn_x6_i, mal_x6_i, msn_all_i, mal_all_i,\nt_ns &lt;- compare.yai(rf_k3_ps_i, rf_all_ps_i, msn_x6_i, mal_x6_i, scale = F)\nt &lt;- compare.yai(rf_k3_ps_i, rf_all_ps_i, msn_x6_i, mal_x6_i)\n\n\n\n\nCode\nplot(t_ns, main = \"Not Scaled\")\nplot(t, main = \"Scaled\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nt_ns$min &lt;- names(t_ns)[apply(t_ns, 1, which.min)]\nt_ns$min &lt;- t_ns$min |&gt; str_sub(1, 6)\nt_ns |&gt; arrange(min)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrf_k3_ps_i.rmsdS\nrf_all_ps_i.rmsdS\nmsn_x6_i.rmsdS\nmal_x6_i.rmsdS\nmin\n\n\n\n\nTSHE_TD\n479.05363\n482.13140\n401.49311\n508.01034\nmsn_x6\n\n\ntotal_TD\n874.71763\n876.22994\n701.41423\n754.46481\nmsn_x6\n\n\nABGR_TD\n239.49222\n238.11462\n309.58660\n277.73063\nrf_all\n\n\nPSME_TD\n243.54849\n240.66058\n289.30718\n274.08248\nrf_all\n\n\nTSME_TD\n77.74687\n75.79003\n98.06111\n88.05078\nrf_all\n\n\nPIEN_TD\n279.91061\n276.55670\n293.53857\n300.22660\nrf_all\n\n\nPICO_TD\n269.42713\n262.50039\n325.26841\n315.22969\nrf_all\n\n\nPIMO3_TD\n52.03200\n50.60531\n52.79650\n51.02393\nrf_all\n\n\nPIPO_TD\n92.76392\n94.80876\n106.67592\n125.99836\nrf_k3_\n\n\nABLA_TD\n259.30735\n262.60464\n282.62389\n261.73287\nrf_k3_\n\n\nABAM_TD\n257.22524\n262.97926\n318.73906\n289.84361\nrf_k3_\n\n\nTHPL_TD\n167.83196\n171.87645\n231.77892\n183.14742\nrf_k3_\n\n\nuncommon\n280.03253\n287.08426\n301.79829\n309.27698\nrf_k3_\n\n\nrare\n152.21296\n152.75692\n206.30725\n190.10477\nrf_k3_\n\n\n\n\n\n\nCode\nqplot(t_ns$min)"
  },
  {
    "objectID": "6_Model_Eval_2.html#narrative-summary",
    "href": "6_Model_Eval_2.html#narrative-summary",
    "title": "Model Eval 2",
    "section": "Narrative Summary",
    "text": "Narrative Summary\nWithin the msn and mal imputations, The plot comparisons are messy. The scaled version looks to me like mal x6 is best. For the un-scaled one, they mostly look the same.\nmal_x6 had the most species with the lowest rmsd. However, there were no major winners. All of the imputations had similar outcomes by category. mal k3 was pretty far below the others in total TD.\nIn Random Forests, The scaled plots look to favor the all predictors rf or the Kralicek 3 with the all set winning. The un-scaled one doesn’t tell me anything.\nIn the versus plots, it seems that rf_all is the winner by a hair. rf_k3 is a close runner up."
  },
  {
    "objectID": "6_Model_Eval_2.html#what-does-it-all-mean",
    "href": "6_Model_Eval_2.html#what-does-it-all-mean",
    "title": "Model Eval 2",
    "section": "What does it all mean",
    "text": "What does it all mean"
  },
  {
    "objectID": "6_Model_Eval_2.html#scratch",
    "href": "6_Model_Eval_2.html#scratch",
    "title": "Model Eval 2",
    "section": "Scratch",
    "text": "Scratch\nLooking at rmsd for the full set and where total_TD isn’t zero.\n\n\nCode\nall_dist &lt;- rmsd(rf_all_ps_i) \nzall_dist &lt;- rmsd(rf_all_ps_i[rf_all_ps_i$total_TD.o &gt; 0,]) \n\nall_dist |&gt; arrange(rmsd)\n\n\n\n\n\n\n\nrmsd\n\n\n\n\nPIMO3_TD\n50.60531\n\n\nTSME_TD\n75.79003\n\n\nPIPO_TD\n94.80876\n\n\nrare\n152.75692\n\n\nTHPL_TD\n171.87645\n\n\nABGR_TD\n238.11462\n\n\nPSME_TD\n240.66058\n\n\nPICO_TD\n262.50039\n\n\nABLA_TD\n262.60464\n\n\nABAM_TD\n262.97926\n\n\nPIEN_TD\n276.55670\n\n\nuncommon\n287.08426\n\n\nTSHE_TD\n482.13140\n\n\ntotal_TD\n876.22994\n\n\n\n\n\n\nCode\nzall_dist |&gt; arrange(rmsd)\n\n\n\n\n\n\n\nrmsd\n\n\n\n\nPIMO3_TD\n68.31418\n\n\nTSME_TD\n105.63613\n\n\nPIPO_TD\n128.84170\n\n\nrare\n212.66540\n\n\nTHPL_TD\n238.03004\n\n\nABGR_TD\n326.77793\n\n\nPSME_TD\n332.61066\n\n\nABAM_TD\n360.38604\n\n\nABLA_TD\n360.87860\n\n\nPICO_TD\n361.21077\n\n\nPIEN_TD\n386.07111\n\n\nuncommon\n398.04037\n\n\nTSHE_TD\n661.18279\n\n\ntotal_TD\n1202.28214\n\n\n\n\n\n\nRmsd increases when there are less zeroes.\n\nPulling summary stats for the reference set.\n\n\nCode\nobserved &lt;- rf_all_ps_i |&gt; select(ends_with(\".o\")) |&gt; drop_na()\nzobserved &lt;- rf_all_ps_i[rf_all_ps_i$total_TD.o &gt; 0,] |&gt; select(ends_with(\".o\")) |&gt; drop_na()\n# names(observed)\n\nall_dist$sd &lt;- apply(observed, 2, sd)\nall_dist$mean &lt;- apply(observed, 2, mean)\nall_dist$iqr &lt;- apply(observed, 2, IQR)\nall_dist$q75 &lt;- apply(observed, 2, quantile, .75)\nall_dist$q85 &lt;- apply(observed, 2, quantile, .85)\nall_dist$q95 &lt;- apply(observed, 2, quantile, .95)\n\nzall_dist$sd &lt;- apply(zobserved, 2, sd)\nzall_dist$mean &lt;- apply(zobserved, 2, mean)\nzall_dist$iqr &lt;- apply(zobserved, 2, IQR)\nzall_dist$q75 &lt;- apply(zobserved, 2, quantile, .75)\nzall_dist$q85 &lt;- apply(zobserved, 2, quantile, .85)\nzall_dist$q95 &lt;- apply(zobserved, 2, quantile, .95)\n\n\nstd dev is uniformly higher than the mean. Makes sense because of zeroes dragging down the mean.\nThere was something in the documentation about these types of count data being assumed to follow a log-normal dist. I played with that a little earlier, but it may be time to see if I can make anything of it.\n\n\nCode\nall_dist\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrmsd\nsd\nmean\niqr\nq75\nq85\nq95\n\n\n\n\nABGR_TD\n238.11462\n255.92742\n37.500239\n0.0000\n0.0000\n0.00000\n149.93057\n\n\nPIPO_TD\n94.80876\n97.38511\n8.600770\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nPSME_TD\n240.66058\n235.60890\n42.255959\n0.0000\n0.0000\n74.96528\n224.89585\n\n\nABLA_TD\n262.60464\n297.51573\n53.685525\n0.0000\n0.0000\n0.00000\n224.89585\n\n\nTSME_TD\n75.79003\n72.69053\n5.895157\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nABAM_TD\n262.97926\n306.19517\n50.284811\n0.0000\n0.0000\n0.00000\n224.89585\n\n\nTHPL_TD\n171.87645\n187.91881\n21.662503\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nPIEN_TD\n276.55670\n282.33965\n13.096928\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nTSHE_TD\n482.13140\n483.46485\n30.531635\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nPICO_TD\n262.50039\n320.38485\n27.438877\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nPIMO3_TD\n50.60531\n39.12871\n3.343522\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nuncommon\n287.08426\n271.29191\n22.687556\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nrare\n152.75692\n149.00810\n11.992685\n0.0000\n0.0000\n0.00000\n0.00000\n\n\ntotal_TD\n876.22994\n993.53904\n328.976167\n299.8611\n299.8611\n599.72226\n1499.30565\n\n\n\n\n\n\n\n\nCode\nzall_dist\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrmsd\nsd\nmean\niqr\nq75\nq85\nq95\n\n\n\n\nABGR_TD\n326.77793\n354.16540\n73.31391\n0.00000\n0.00000\n74.96528\n374.82641\n\n\nPIPO_TD\n128.84170\n135.66169\n16.81472\n0.00000\n0.00000\n0.00000\n74.96528\n\n\nPSME_TD\n332.61066\n324.34297\n82.61147\n74.96528\n74.96528\n149.93057\n449.79170\n\n\nABLA_TD\n360.87860\n409.48517\n104.95656\n0.00000\n0.00000\n74.96528\n599.72226\n\n\nTSME_TD\n105.63613\n101.32062\n11.52518\n0.00000\n0.00000\n0.00000\n0.00000\n\n\nABAM_TD\n360.38604\n422.59081\n98.30807\n0.00000\n0.00000\n74.96528\n524.75698\n\n\nTHPL_TD\n238.03004\n261.08687\n42.35074\n0.00000\n0.00000\n0.00000\n224.89585\n\n\nPIEN_TD\n386.07111\n394.37875\n25.60482\n0.00000\n0.00000\n0.00000\n74.96528\n\n\nTSHE_TD\n661.18279\n674.72153\n59.69012\n0.00000\n0.00000\n0.00000\n224.89585\n\n\nPICO_TD\n361.21077\n446.40986\n53.64370\n0.00000\n0.00000\n0.00000\n149.93057\n\n\nPIMO3_TD\n68.31418\n54.52106\n6.53667\n0.00000\n0.00000\n0.00000\n0.00000\n\n\nuncommon\n398.04037\n378.06799\n44.35475\n0.00000\n0.00000\n0.00000\n149.93057\n\n\nrare\n212.66540\n207.70677\n23.44600\n0.00000\n0.00000\n0.00000\n74.96528\n\n\ntotal_TD\n1202.28214\n1314.48158\n643.15671\n524.75698\n674.68754\n1049.51395\n2323.92376\n\n\n\n\n\n\n\n\nCode\nsp_prevalence$uncommon |&gt; length()\nsp_prevalence$rare |&gt; length()\n\n\nThere are 6 species in uncommon and 26 in rare.\nEven removing subplots where there are no seedlings from the reference set doesn’t fix the distribution issue.\nThis is the best I’ve done, lol. Feeling a bit defeated. rmsd is very close to sd. Perhaps a bit better in total TD.\nThere is a chance that running the rf or msn x6 per FPAG would work better.\n\ntesting rmsd\nJust making sure that I understand how rmsd is calculated.\n\n\nCode\nt &lt;- rf_all_ps_i |&gt; select(total_TD, total_TD.o) |&gt; drop_na() |&gt; \n  mutate(diff = (total_TD - total_TD.o),\n         squared = diff^2\n) \n\ntr &lt;- sqrt((sum(t$squared))/nrow(t))\ntr\n\n\n[1] 876.2299\n\n\nThat is the correct value of rmsd. 0.8819280 is the scaled one. 993.53904 is the sd of the reference rows above.\n\n\nCode\ntr/993.53904\n\n\n[1] 0.881928\n\n\nNormalizing by the sd in this case isn’t great. There is just too many zeroes.\nObviously what I am about to do isn’t great. However, it’s easier than running another imputation. I am going to get an idea of the rmsd per fpag by adding the CNs and summarizing by fpag.\nID ranks rmsd total TD low to high.\n\n\nCode\ncns_ref &lt;- rownames_to_column(t, \"STANDPLOT_CN\")\nref_fpags &lt;- left_join(cns_ref, imp_data, by = \"STANDPLOT_CN\")\n\nref_fpags &lt;- ref_fpags |&gt; select(STANDPLOT_CN, FPAG)\n# ref_fpags &lt;- unique(ref_fpags$FPAG)\n\nx &lt;- rownames_to_column(t, \"STANDPLOT_CN\")\nx &lt;- left_join(ref_fpags, x, by = \"STANDPLOT_CN\")\n\nx2 &lt;- x |&gt; group_by(FPAG) |&gt; \n  summarise(\n    n = n(),\n    rmsd_t_TD = sqrt((sum(squared))/n),\n    mean = mean(total_TD.o), \n    sd = sd(total_TD.o), \n    iqr = IQR(total_TD.o)) |&gt; \n  arrange(rmsd_t_TD)\n\nx2 &lt;- x2 |&gt; mutate(id = row_number())\n\nhead(x2)\n\n\n\n\n\n\nFPAG\nn\nrmsd_t_TD\nmean\nsd\niqr\nid\n\n\n\n\nCPS2\n257\n137.4518\n49.58793\n197.2045\n0.00000\n1\n\n\nCHS3\n32\n189.7414\n60.90929\n178.0505\n74.96528\n2\n\n\nCP\n195\n203.1489\n96.49377\n176.7064\n74.96528\n3\n\n\nCDG3\n293\n232.6922\n85.71116\n249.4038\n74.96528\n4\n\n\nCPG1\n169\n326.8678\n112.22613\n318.0638\n74.96528\n5\n\n\nCES1\n236\n369.2902\n190.90735\n403.6852\n149.93057\n6\n\n\n\n\n\n\nCode\ntail(x2)\n\n\n\n\n\n\nFPAG\nn\nrmsd_t_TD\nmean\nsd\niqr\nid\n\n\n\n\nCEF4\n397\n1232.219\n451.6800\n1307.486\n374.82641\n45\n\n\nCFS5\n239\n1346.715\n734.9107\n1535.391\n749.65282\n46\n\n\nCHF1\n416\n1371.617\n231.7436\n1389.242\n74.96528\n47\n\n\nCFS2\n877\n1613.041\n610.4926\n1907.733\n674.68754\n48\n\n\nCES2\n464\n1780.572\n749.8144\n1863.135\n749.65283\n49\n\n\nCH\n118\n1865.804\n536.1924\n1407.621\n299.86113\n50\n\n\n\n\n\n\nI was wishing I could scale by iqr due to the outliers. Normalizing by iqr is done when there are significant outliers.\n\n\nCode\nx2 &lt;- x2 |&gt; mutate(\n  scaled = rmsd_t_TD/sd, \n  sc_iqr = rmsd_t_TD/iqr\n)\nx2 |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFPAG\nn\nrmsd_t_TD\nmean\nsd\niqr\nid\nscaled\nsc_iqr\n\n\n\n\nCPS2\n257\n137.4518\n49.58793\n197.2045\n0.00000\n1\n0.6970016\nInf\n\n\nCHS3\n32\n189.7414\n60.90929\n178.0505\n74.96528\n2\n1.0656606\n2.531057\n\n\nCP\n195\n203.1489\n96.49377\n176.7064\n74.96528\n3\n1.1496409\n2.709906\n\n\nCDG3\n293\n232.6922\n85.71116\n249.4038\n74.96528\n4\n0.9329938\n3.103999\n\n\nCPG1\n169\n326.8678\n112.22613\n318.0638\n74.96528\n5\n1.0276800\n4.360256\n\n\nCES1\n236\n369.2902\n190.90735\n403.6852\n149.93057\n6\n0.9147974\n2.463075\n\n\n\n\n\n\n\n\nploting differences.\n\n\nCode\nt2 &lt;- x |&gt; arrange(desc(diff))\n\n\n\n\nCode\nplot(t2$diff)\n\n\n\n\n\nCode\nhist(t2$diff, breaks = 100)\n\n\n\n\n\nCode\nhist(t2$diff, breaks = 100,\n     xlim = c(-3000, 3000),\n     ylim = c(0, 200))\n\n\n\n\n\nThe -40k difference is crazy. 10k is more reasonable, but what percent of the data would I have to clip to remove the worst outliers? What percent is essentailly zero?\n\n\nCode\nt5000 &lt;- t2 |&gt; filter(total_TD.o &lt; 5000 & total_TD &lt; 5000)\nplot(t5000$diff)\n\n\n\n\n\nCode\nhist(t5000$diff, breaks = 100)\n\n\n\n\n\nrmsd for t5000, T_TD.\n\n\nCode\nsqrt((sum(t5000$squared))/nrow(t5000))\n\n\n[1] 526.5958\n\n\nrmsd could be as low as 526 if there weren’t so many outliers.\n\n\nCode\nt2000 &lt;- t2 |&gt; filter(diff &lt; 2000 & diff &gt; -2000)\nplot(t2000$diff)\n\n\n\n\n\nCode\nhist(t2000$diff, breaks = 100)"
  },
  {
    "objectID": "6_Model_Eval_2.html#ci-on-diff",
    "href": "6_Model_Eval_2.html#ci-on-diff",
    "title": "Model Eval 2",
    "section": "CI on diff",
    "text": "CI on diff\n\n\nCode\nmean &lt;- mean(t2$diff)\nsd &lt;- sd(t2$diff)\nts &lt;- sd/sqrt(nrow(t2))\ndfr &lt;- nrow(t2)-1\n\n\nz &lt;- qt(p = (.05/2), df =dfr, )\nmar &lt;- z*ts\n\nci &lt;- c(mean+mar, mean-mar)\nci\n\n\n[1] -83.64118 -57.41146\n\n\nWith 95% confidence for the full dataset, the true average difference is between -84 and -57. Since this is count data, that means the true difference is -75, or one tree counted on a microplot.\nI am reading this as, there are usually no seedlings and therefore no differences, but even when there are, the difference is small. However, there are occasionally large influxes of seedlings that throw off this type distribution.\nWe probably need the large differences, but only in a very small percentage of regeneration events. I assume it is also the case that only some species reproduce like this.\n\n\n\nCode\nmed &lt;- median(t2$diff)\n\n# t2 |&gt; filter(near(diff, 0, tol = .5)) |&gt; nrow()\n# t2 |&gt; filter(near(diff, 0, tol = 75*30)) |&gt; nrow()\n\n\nof 17,040 reference plots, here are the number of plots per difference in counted trees. 98% of plots are within 30, 91% within 10.\n\n\n\nnum subplots\ndiff of trees\n\n\n\n\n8293\n0\n\n\n10751\n1\n\n\n12051\n2\n\n\n13013\n3\n\n\n13667\n4\n\n\n14141\n5\n\n\n14593\n6\n\n\n15572\n10\n\n\n16455\n20\n\n\n16746\n30\n\n\n\n\n\nCode\n# 16746/nrow(t2)\n((1-.975)/2)*nrow(t2)\n\n\n[1] 213\n\n\nIf I sort the list and clip 1.25% of the references from each end, that is 213 rows on each side. 426 rows removed in total.\n\n\nCode\ntt &lt;- t2[213:(nrow(t2)-213),]\nlook &lt;- t2[c(1:213, (nrow(t2)-213):nrow(t2)),]\nhist(tt$diff, breaks = 100)\n\n\n\n\n\nCode\nrange(tt$diff)\n\n\n[1] -2248.958  1499.306\n\n\nCode\nmean(tt$diff)\n\n\n[1] -42.87211\n\n\nThat is even better than I hoped. It leans a bit negative though.\n\n\nCode\nmean &lt;- mean(t2$diff)\nsd &lt;- sd(t2$diff)\nts &lt;- sd/sqrt(nrow(t2))\ndfr &lt;- nrow(t2)-1\n\nz &lt;- qt(p = (.05/2), df = dfr, )\nmar &lt;- z*ts\n\nci &lt;- c(mean+mar, mean-mar)\nci\n\n\n[1] -83.64118 -57.41146\n\n\nCode\nmean(t2$diff) + 2*sd(t2$diff)\n\n\n[1] 1676.299\n\n\nCode\nmean(t2$diff) - 2*sd(t2$diff)\n\n\n[1] -1817.352\n\n\nLooks like the imputation is biased. The 95% confidence interval is -33 to -22, or half a tree. Diff is imputed minus observed, so there is 22 to 33 less trees on average in the imputed data."
  },
  {
    "objectID": "6_Model_Eval_2.html#imp-fix",
    "href": "6_Model_Eval_2.html#imp-fix",
    "title": "Model Eval 2",
    "section": "Imp fix?",
    "text": "Imp fix?\nThe issue I think I need to solve here is that rmsd and sd are so high in each set that any imputation is going to give us too much variation. However, looking at the differences, it seems like we are mostly getting close to the mark. I would like rmsd to be less than sd. That is, I would like the variation from imputation to be within the bounds of natural variation. Surpisingly, most of the predictors that I have tried are not getting us closer. The Phys code is being used as a factor, but it is also a scale of moisture conditions. I could run it as a numeric and see if that helps the imputation. I also have not added eco-region as a category yet. That could help. I am hesitent to go looking for more predictors at this time. I want to get this model running, then come back and tune it later. As long as the model is somewhat reasonable, it is good enough for now. Reasonable, in this case, means that the model predicts seedlings within the level of natural variation.\nThere is a tool in yaImpute to correct bias. I will have to look into that tool. I think that an interesting test would be to do this for a section of Idaho and run the set in here and in FVS. The IE variant has the full regen model and it could give me an idea of accuracy.\nRunning another imputation. This time I have removed total TD greater than 2900. This was done by trial and error to clip 426 rows with the highest densities from the reference set. It actually clipped 423 rows.\nThen I repeated what was done before.\n\n\nCode\nrm(list = ls()[!ls() %in% KEEP])\n\nfpas2 &lt;- fpas  |&gt; filter(total_TD &lt; 2900)\n\nrefs2 &lt;- rownames(fpas2[1:(3*nrow(fpas2)/4),])\n\nx &lt;- fpas2 |&gt; select(STANDPLOT_CN, CC, BA, SDI, ELEVFT, SLOPE, ASPECT, PHYSCLCD, FPAG)\nx &lt;- remove_rownames(x)\nx &lt;- column_to_rownames(x, \"STANDPLOT_CN\")\n\nyfull &lt;- fpas2 |&gt; select(1, 11:ncol(fpas2))\n# That is the same number of rows as the 95% of the data from before. \n\ny &lt;- yfull[refs2,]\ny &lt;- remove_rownames(y)\ny &lt;- column_to_rownames(y, \"STANDPLOT_CN\")\n# can't have factors in msn or mal\nx6 &lt;- x |&gt; select(-FPAG, -PHYSCLCD)\n\nk = 1\n\nyrf &lt;- cbind(whatsMax(y[ ,1:(ncol(y)-1)]), y[, ncol(y)])\n\nnames(yrf) &lt;- c('Max_SP', 'sp_max_TD', 'total_TD')\n\n\n\nmsn & mal 6\n\n\nCode\nmsn_x6_ref2 &lt;- yai(x = x6, y = y, method = \"msn\", k = k)\nmal_x6_ref2 &lt;- yai(x = x6, y = y, method = \"mahalanobis\", k = k)\n\nKEEP &lt;- KEEP |&gt; append(c('mal_x6_ref2', 'msn_x6_ref2'))\nKEEP &lt;- KEEP |&gt; unique() |&gt; sort()\n\n\n\n\nRF all\n\n\nCode\n# Separating this because it takes a long time and I don't want to run in by accident. \n# rf_all_ref2 &lt;- yai(x = x, y = yrf, method = \"randomForest\", k = k)\n# save(rf_all_ref2, file = \"imps_0402/rf_all_refs2.Rdata\")\n\n\n\n\nCode\nload(\"imps_0402/rf_all_refs2.Rdata\")\n\n# rf_all_ps_i &lt;- impute(rf_all_ps, ancillaryData = y)\nrf_all_ref2_i &lt;- impute(rf_all_ref2, ancillaryData = y)\nmal_x6_i &lt;- impute(mal_x6_ps)\n\n\n\n\nCode\nt_ns &lt;- compare.yai(rf_all_ps_i, rf_all_ref2_i, mal_x6_ref2, mal_x6_i,  scale = F)\nt &lt;- compare.yai(rf_all_ps_i, rf_all_ref2_i, mal_x6_ref2, mal_x6_i)\n\n\nWarning in compare.yai(rf_all_ps_i, rf_all_ref2_i, mal_x6_ref2, mal_x6_i): not\nall scale factors are the same.\n\n\n\n\neval\n\n\nCode\nplot(t_ns, main = \"Not Scaled\")\nplot(t, main = \"Scaled\")\n\n\n\n\n\n\n\n\n\n\n\n\nBig differences between the last set and this one. I don’t trust the scaled plots to mean anything. Due to the outliers, I don’t think normalizing by sd is the way to go. Un-scaled rmsd is way less in the ref2 set, this imp.\n\n\nCode\nt_ns$min &lt;- names(t_ns)[apply(t_ns, 1, which.min)]\nt_ns$min &lt;- t_ns$min |&gt; str_sub(1, 9)\nt_ns|&gt; arrange(min)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrf_all_ps_i.rmsdS\nrf_all_ref2_i.rmsdS\nmal_x6_ref2.rmsdS\nmal_x6_i.rmsdS\nmin\n\n\n\n\ntotal_TD\n876.22994\n302.94122\n278.77710\n754.46481\nmal_x6_re\n\n\nABGR_TD\n238.11462\n118.50571\n165.01598\n277.73063\nrf_all_re\n\n\nPIPO_TD\n94.80876\n64.25259\n74.33279\n125.99836\nrf_all_re\n\n\nPSME_TD\n240.66058\n137.84547\n161.28575\n274.08248\nrf_all_re\n\n\nABLA_TD\n262.60464\n145.62121\n174.54931\n261.73287\nrf_all_re\n\n\nTSME_TD\n75.79003\n52.54523\n62.06037\n88.05078\nrf_all_re\n\n\nABAM_TD\n262.97926\n138.25686\n182.11707\n289.84361\nrf_all_re\n\n\nTHPL_TD\n171.87645\n89.87215\n132.15119\n183.14742\nrf_all_re\n\n\nPIEN_TD\n276.55670\n54.79619\n63.74589\n300.22660\nrf_all_re\n\n\nTSHE_TD\n482.13140\n99.85822\n124.85768\n508.01034\nrf_all_re\n\n\nPICO_TD\n262.50039\n92.23968\n134.09621\n315.22969\nrf_all_re\n\n\nPIMO3_TD\n50.60531\n39.86885\n48.00670\n51.02393\nrf_all_re\n\n\nuncommon\n287.08426\n110.18565\n124.30876\n309.27698\nrf_all_re\n\n\nrare\n152.75692\n82.92543\n102.16046\n190.10477\nrf_all_re\n\n\n\n\n\n\nRf all predictors 2nd reference set is the best imputation in all but total. That one was the mahalanobis matrix, but rf was close.\n\nqplot(t_ns$min)"
  },
  {
    "objectID": "6_Model_Eval_2.html#now-what-does-it-mean.",
    "href": "6_Model_Eval_2.html#now-what-does-it-mean.",
    "title": "Model Eval 2",
    "section": "Now what does it mean.",
    "text": "Now what does it mean.\n\n\nCode\nall_dist &lt;- rmsd(rf_all_ref2_i)\nobserved &lt;- rf_all_ref2_i |&gt; select(ends_with(\".o\")) |&gt; drop_na()\n\nall_dist$sd &lt;- apply(observed, 2, sd)\nall_dist$mean &lt;- apply(observed, 2, mean)\nall_dist$iqr &lt;- apply(observed, 2, IQR)\nall_dist$q75 &lt;- apply(observed, 2, quantile, .75)\nall_dist$q85 &lt;- apply(observed, 2, quantile, .85)\nall_dist$q95 &lt;- apply(observed, 2, quantile, .95)\nall_dist\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrmsd\nsd\nmean\niqr\nq75\nq85\nq95\n\n\n\n\nABGR_TD\n118.50571\n146.27163\n28.214524\n0.0000\n0.0000\n0.00000\n149.93057\n\n\nPIPO_TD\n64.25259\n64.72799\n7.912081\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nPSME_TD\n137.84547\n141.46196\n36.400053\n0.0000\n0.0000\n74.96528\n224.89585\n\n\nABLA_TD\n145.62121\n195.80255\n40.963508\n0.0000\n0.0000\n0.00000\n224.89585\n\n\nTSME_TD\n52.54523\n51.19306\n4.523110\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nABAM_TD\n138.25686\n193.90993\n37.986952\n0.0000\n0.0000\n0.00000\n224.89585\n\n\nTHPL_TD\n89.87215\n118.11815\n18.307613\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nPIEN_TD\n54.79619\n50.97825\n5.625870\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nTSHE_TD\n99.85822\n117.51366\n17.756233\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nPICO_TD\n92.23968\n114.58934\n13.995193\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nPIMO3_TD\n39.86885\n36.79169\n2.967591\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nuncommon\n110.18565\n98.28547\n14.757263\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nrare\n82.92543\n84.99143\n9.328634\n0.0000\n0.0000\n0.00000\n0.00000\n\n\ntotal_TD\n302.94122\n444.63723\n238.738626\n299.8611\n299.8611\n524.75698\n1199.44452\n\n\n\n\n\n\nVariation is still on the border, but there are some spp. that fall within my arbitrary boundary.\n\nsp_prevalence$prevalent\n\n[1] \"PSME_TD\" \"ABAM_TD\" \"ABLA_TD\" \"TSHE_TD\"\n\nsp_prevalence$common\n\n[1] \"PIPO_TD\"  \"TSME_TD\"  \"ABGR_TD\"  \"THPL_TD\"  \"PIEN_TD\"  \"PICO_TD\"  \"PIMO3_TD\"\n\n\nTSME_TD in the prevalent set. Pipo, pien, and pimo3 in the common set. uncommon and rare look okay too. Total TD is worst, but that is mostly just there to make working with this set easier.\n\n\nCode\nsummary(all_dist)\n\n\n      rmsd              sd              mean              iqr        \n Min.   : 39.87   Min.   : 36.79   Min.   :  2.968   Min.   :  0.00  \n 1st Qu.: 68.92   1st Qu.: 69.79   1st Qu.:  8.266   1st Qu.:  0.00  \n Median : 96.05   Median :116.05   Median : 16.257   Median :  0.00  \n Mean   :109.27   Mean   :132.81   Mean   : 34.106   Mean   : 21.42  \n 3rd Qu.:133.01   3rd Qu.:145.07   3rd Qu.: 34.354   3rd Qu.:  0.00  \n Max.   :302.94   Max.   :444.64   Max.   :238.739   Max.   :299.86  \n      q75              q85              q95         \n Min.   :  0.00   Min.   :  0.00   Min.   :   0.00  \n 1st Qu.:  0.00   1st Qu.:  0.00   1st Qu.:   0.00  \n Median :  0.00   Median :  0.00   Median :  74.97  \n Mean   : 21.42   Mean   : 42.84   Mean   : 160.64  \n 3rd Qu.:  0.00   3rd Qu.:  0.00   3rd Qu.: 206.15  \n Max.   :299.86   Max.   :524.76   Max.   :1199.44  \n\n\n\n\nCode\nhist((rf_all_ref2_i$total_TD - rf_all_ref2_i$total_TD.o), breaks = 100)\n\n\n\n\n\nCode\nmean((rf_all_ref2_i$total_TD - rf_all_ref2_i$total_TD.o), na.rm = T)\n\n\n[1] -37.35488\n\n\n\n\nCode\nt &lt;- rf_all_ref2_i |&gt; select(total_TD, total_TD.o) |&gt; drop_na() |&gt; \n  mutate(diff = (total_TD - total_TD.o),\n         squared = diff^2\n) \n\n\nmean &lt;- mean(t$diff)\nsd &lt;- sd(t$diff)\nts &lt;- sd/sqrt(nrow(t))\ndfr &lt;- nrow(t)-1\n\n\nz &lt;- qt(p = (.05/2), df =dfr, )\nmar &lt;- z*ts\n\nci &lt;- c(mean+mar, mean-mar)\nci\n\n\n[1] -41.91175 -32.79801\n\n\n95% conf interval is between 33 and 42 more trees observed than imputed.\n\nsave(fpas, file = \"dfs_0403/fpas.Rdata\")\nsave(rf_all_ref2_i, file = \"dfs_0403/rf_all_ref2_i.Rdata\")\nsave(imp_data, file = \"dfs_0403/imp_data.Rdata\")\nsave(fpas2, file = \"dfs_0403/fpas_TD2900.Rdata\")\nsave(KEEP, file = \"dfs_0403/KEEP.Rdata\")"
  },
  {
    "objectID": "7_Predictors.html",
    "href": "7_Predictors.html",
    "title": "Predictors",
    "section": "",
    "text": "Apr 9th, pulling in new predictors."
  },
  {
    "objectID": "7_Predictors.html#eval",
    "href": "7_Predictors.html#eval",
    "title": "Predictors",
    "section": "eval",
    "text": "eval\n\n\nCode\nplot(t_ns, main = \"Not Scaled\")\nplot(t, main = \"Scaled\")\n\n\n\n\n\n\n\n\n\n\n\n\nI was hoping for something a little more striking. The plots don’t show a large difference. The bootstrap sample didn’t do as well as I hoped.\n\n\nCode\nt_ns$min &lt;- names(t_ns)[apply(t_ns, 1, which.min)]\nt_ns$min &lt;- t_ns$min |&gt; str_sub(1, 9)\nt_ns |&gt; arrange(min)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrf_f.p.a.g_i.rmsdS\nrf_fpag_bs_i.rmsdS\nrf_all_ref2_i.rmsdS\nmin\n\n\n\n\nABGR_TD\n118.95009\n132.47941\n118.50571\nrf_all_re\n\n\nTHPL_TD\n93.31725\n104.48730\n89.87215\nrf_all_re\n\n\nPIEN_TD\n57.18790\n62.63896\n54.79619\nrf_all_re\n\n\nTSHE_TD\n100.98928\n110.92989\n99.85822\nrf_all_re\n\n\nPIMO3_TD\n43.03465\n42.01216\n39.86885\nrf_all_re\n\n\nrare\n84.43939\n91.32773\n82.92543\nrf_all_re\n\n\nPSME_TD\n133.50725\n136.51469\n137.84547\nrf_f.p.a.\n\n\nABLA_TD\n138.66340\n157.14870\n145.62121\nrf_f.p.a.\n\n\nABAM_TD\n135.34840\n143.15201\n138.25686\nrf_f.p.a.\n\n\nPICO_TD\n86.08882\n87.73905\n92.23968\nrf_f.p.a.\n\n\nuncommon\n108.65930\n113.49455\n110.18565\nrf_f.p.a.\n\n\ntotal_TD\n290.29415\n313.93151\n302.94122\nrf_f.p.a.\n\n\nPIPO_TD\n62.38980\n56.55910\n64.25259\nrf_fpag_b\n\n\nTSME_TD\n54.68569\n47.50446\n52.54523\nrf_fpag_b\n\n\n\n\n\n\nSplitting FPAG into components was a mixed bag, it was better about half the time. No major decrease in rmsd.\n\n\nCode\nqplot(t_ns$min)\n\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0."
  },
  {
    "objectID": "7_Predictors.html#now-what",
    "href": "7_Predictors.html#now-what",
    "title": "Predictors",
    "section": "Now what?",
    "text": "Now what?\n\n\nCode\nall_dist &lt;- rmsd(rf_f.p.a.g_i)\nobserved &lt;- rf_f.p.a.g_i |&gt; select(ends_with(\".o\")) |&gt; drop_na()\n\nall_dist$sd &lt;- apply(observed, 2, sd)\nall_dist$mean &lt;- apply(observed, 2, mean)\nall_dist$iqr &lt;- apply(observed, 2, IQR)\nall_dist$q75 &lt;- apply(observed, 2, quantile, .75)\nall_dist$q85 &lt;- apply(observed, 2, quantile, .85)\nall_dist$q95 &lt;- apply(observed, 2, quantile, .95)\nall_dist\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrmsd\nsd\nmean\niqr\nq75\nq85\nq95\n\n\n\n\nABGR_TD\n118.95009\n146.27163\n28.214524\n0.0000\n0.0000\n0.00000\n149.93057\n\n\nPIPO_TD\n62.38980\n64.72799\n7.912081\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nPSME_TD\n133.50725\n141.46196\n36.400053\n0.0000\n0.0000\n74.96528\n224.89585\n\n\nABLA_TD\n138.66340\n195.80255\n40.963508\n0.0000\n0.0000\n0.00000\n224.89585\n\n\nTSME_TD\n54.68569\n51.19306\n4.523110\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nABAM_TD\n135.34840\n193.90993\n37.986952\n0.0000\n0.0000\n0.00000\n224.89585\n\n\nTHPL_TD\n93.31725\n118.11815\n18.307613\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nPIEN_TD\n57.18790\n50.97825\n5.625870\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nTSHE_TD\n100.98928\n117.51366\n17.756233\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nPICO_TD\n86.08882\n114.58934\n13.995193\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nPIMO3_TD\n43.03465\n36.79169\n2.967591\n0.0000\n0.0000\n0.00000\n0.00000\n\n\nuncommon\n108.65930\n98.28547\n14.757263\n0.0000\n0.0000\n0.00000\n74.96528\n\n\nrare\n84.43939\n84.99143\n9.328634\n0.0000\n0.0000\n0.00000\n0.00000\n\n\ntotal_TD\n290.29415\n444.63723\n238.738626\n299.8611\n299.8611\n524.75698\n1199.44452\n\n\n\n\n\n\n\n\nCode\nfp &lt;- yaiRFsummary(rf_f.p.a.g)\nfp$forestAttributes\n\n\n\n\n\n\n\nntree\nerror\nerrtag\nlevels\ntype\n\n\n\n\nMax_SP\n166\n0.2828440\nOOB error rate\n14\nclassification\n\n\nsp_max_TD\n166\n0.2327334\nOOB error rate\n15\nclassification\n\n\ntotal_TD\n166\n0.2495366\nOOB error rate\n15\nclassification\n\n\n\n\n\n\nCode\nfp$scaledImportance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBA\nSDI\nCC\nELEVFT\nP\nSLOPE\nPHYSCLCD\nG\nASPECT\nA\nf\n\n\n\n\nMax_SP\n1.695900\n1.600398\n0.2087437\n0.3894149\n0.4720483\n-0.3405607\n-0.5999133\n-0.5151475\n-0.5214716\n-0.8227028\n-1.566709\n\n\nsp_max_TD\n1.841399\n1.900765\n0.4871217\n-0.2517066\n-0.2906942\n-0.4332867\n-0.4589357\n-0.4696075\n-0.4883110\n-0.7352846\n-1.101460\n\n\ntotal_TD\n1.947821\n1.729480\n0.5146903\n-0.1381910\n-0.2019244\n-0.4598861\n-0.4173117\n-0.5432026\n-0.5208850\n-0.7176982\n-1.192892\n\n\n\n\n\n\nI do not know how to make a comparison for the out of bag error. I could compare apples to apples here, but I don’t have these values printed for previous runs.\n\n\nCode\nyaiVarImp(rf_all_ref2, \n          ylim = c(-2,2))\nyaiVarImp(rf_f.p.a.g, \n          ylim = c(-2,2))\nyaiVarImp(rf_fpag_bs, \n          ylim = c(-2,2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe best predictors in out dataset have been BA and SDI,\n\n\nCode\nbs &lt;- yaiRFsummary(rf_fpag_bs)\nbs$forestAttributes[,\"error\"]\n\n\n[1] 0.11433355 0.09256712 0.09759015\n\n\nCode\nfp$forestAttributes[,\"error\"]\n\n\n[1] 0.2828440 0.2327334 0.2495366\n\n\n\n\nCode\nbs$scaledImportance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBA\nSDI\nCC\nASPECT\nSLOPE\nELEVFT\nP\nPHYSCLCD\nG\nA\nf\n\n\n\n\nMax_SP\n1.597472\n1.433161\n-0.0574483\n0.5366522\n0.0994531\n0.2891431\n0.0706198\n-0.5180490\n-0.6205876\n-0.9997415\n-1.830674\n\n\nsp_max_TD\n1.820365\n1.584453\n0.2104118\n0.0771758\n0.1051297\n-0.0884000\n-0.1817940\n-0.4601136\n-0.4868689\n-0.9056247\n-1.674734\n\n\ntotal_TD\n1.867263\n1.462898\n0.2779086\n0.1996548\n-0.0586922\n0.0925954\n-0.2646747\n-0.4194267\n-0.5371534\n-0.9383904\n-1.681982\n\n\n\n\n\n\nCode\nfp$scaledImportance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBA\nSDI\nCC\nELEVFT\nP\nSLOPE\nPHYSCLCD\nG\nASPECT\nA\nf\n\n\n\n\nMax_SP\n1.695900\n1.600398\n0.2087437\n0.3894149\n0.4720483\n-0.3405607\n-0.5999133\n-0.5151475\n-0.5214716\n-0.8227028\n-1.566709\n\n\nsp_max_TD\n1.841399\n1.900765\n0.4871217\n-0.2517066\n-0.2906942\n-0.4332867\n-0.4589357\n-0.4696075\n-0.4883110\n-0.7352846\n-1.101460\n\n\ntotal_TD\n1.947821\n1.729480\n0.5146903\n-0.1381910\n-0.2019244\n-0.4598861\n-0.4173117\n-0.5432026\n-0.5208850\n-0.7176982\n-1.192892\n\n\n\n\n\n\nAdding bootstrap decreased the out-of-bag error, but didn’t do anything for rmsd? \n\n\nCode\nfpx &lt;- fp$scaledImportance\nbsx &lt;- bs$scaledImportance\n\norder &lt;- names(fpx)\n# order &lt;- c(\"SDI\", \"BA\",\"CC\",\"ELEVFT\", \"SLOPE\", \"ASPECT\",\"PHYSCLCD\",\"f\", \"P\", \"A\",\"G\")\n\nbsx &lt;- bsx[, order]\nfpx &lt;- fpx[, order]\n\n\nggplot(stack(fpx)) + \n  aes(x = values, y = ind, fill = ind) + \n  geom_boxplot() + \n  xlim(-2,2) + \n  labs(title = \"reg\")\n\n\n\n\n\nCode\nggplot(stack(bsx)) + \n  aes(x = values, y = ind, fill = ind) + \n  geom_boxplot()+ \n  xlim(-2,2)+ \n  labs(title = \"Bootstrap\")\n\n\n\n\n\nFrom the Brieman paper,\nFor guidance, internal estimates of the generalization error, classifier strength and dependence are computed. These are called out-of-bag estimates and are reviewed in Section 4.\n3.1:\nAssume a method for constructing a classifier from any training set. Given a specific training set T, form boostrap training sets Tk, (a subset of 2/3 of T) construct classifiers h(x, Tk) and let these vote to form the bagged predictor.\nFor each y, x in the training set, aggregate the votes only over those classifiers for which Tk does not containing y, x. Call this the out-of-bag classifier.\nThen the out-of-bag estimate for the generalization error is the error rate of the out-of-bag classifier on the training set\nFrom a video on youtube, the out-of-bag error is the proportion that were incorrectly classified.\nIf that’s the case, then it is odd that jumping form 20% incorrectly classified to 10% didn’t really reduce the difference in predicted vs observed y values, rmsd."
  },
  {
    "objectID": "7_Predictors.html#lets-see",
    "href": "7_Predictors.html#lets-see",
    "title": "Predictors",
    "section": "Let’s see",
    "text": "Let’s see\n\n\nCode\nload(\"imps_0402/rf_dia.Rdata\")\nrf_dia_i &lt;- impute(rf_dia, ancillaryData = y)\n\n\n\n\nCode\nt_ns &lt;- compare.yai(rf_f.p.a.g_i, rf_fpag_bs_i, rf_eco_i, rf_dia_i, rf_all_ref2_i,  scale = F)\nt &lt;- compare.yai(rf_f.p.a.g_i, rf_fpag_bs_i, rf_eco_i, rf_dia_i, rf_all_ref2_i)"
  },
  {
    "objectID": "7_Predictors.html#eval-1",
    "href": "7_Predictors.html#eval-1",
    "title": "Predictors",
    "section": "eval",
    "text": "eval\n\n\nCode\nplot(t_ns, main = \"Not Scaled\")\nplot(t, main = \"Scaled\")\n\n\n\n\n\n\n\n\n\n\n\n\nI am not sure this is going to work any better. I am having a hard time believing that didn’t do anything.\n\n\nCode\nt_ns$min &lt;- names(t_ns)[apply(t_ns, 1, which.min)]\nt_ns$min &lt;- t_ns$min |&gt; str_sub(1, 9)\nt_ns |&gt; arrange(min)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrf_f.p.a.g_i.rmsdS\nrf_fpag_bs_i.rmsdS\nrf_eco_i.rmsdS\nrf_dia_i.rmsdS\nrf_all_ref2_i.rmsdS\nmin\n\n\n\n\nABGR_TD\n118.95009\n132.47941\n131.40519\n127.40337\n118.50571\nrf_all_re\n\n\nTHPL_TD\n93.31725\n104.48730\n97.57319\n97.75719\n89.87215\nrf_all_re\n\n\nTSHE_TD\n100.98928\n110.92989\n107.33042\n107.40178\n99.85822\nrf_all_re\n\n\nrare\n84.43939\n91.32773\n87.29527\n82.98835\n82.92543\nrf_all_re\n\n\nTSME_TD\n54.68569\n47.50446\n51.30634\n44.46117\n52.54523\nrf_dia_i.\n\n\nPIEN_TD\n57.18790\n62.63896\n57.17974\n54.07475\n54.79619\nrf_dia_i.\n\n\nPIMO3_TD\n43.03465\n42.01216\n35.24496\n37.30043\n39.86885\nrf_eco_i.\n\n\nuncommon\n108.65930\n113.49455\n108.06836\n113.52918\n110.18565\nrf_eco_i.\n\n\nPSME_TD\n133.50725\n136.51469\n139.28826\n138.46690\n137.84547\nrf_f.p.a.\n\n\nABLA_TD\n138.66340\n157.14870\n159.31184\n164.11334\n145.62121\nrf_f.p.a.\n\n\nABAM_TD\n135.34840\n143.15201\n148.01245\n152.92036\n138.25686\nrf_f.p.a.\n\n\nPICO_TD\n86.08882\n87.73905\n87.32684\n95.80544\n92.23968\nrf_f.p.a.\n\n\ntotal_TD\n290.29415\n313.93151\n343.35150\n370.79256\n302.94122\nrf_f.p.a.\n\n\nPIPO_TD\n62.38980\n56.55910\n58.08051\n67.49800\n64.25259\nrf_fpag_b\n\n\n\n\n\n\n\n\nCode\nqplot(t_ns$min)\n\n\n\n\n\n\n\nCode\nep &lt;- yaiRFsummary(rf_f.p.a.g)\nep$forestAttributes\n\n\n\n\n\n\n\nntree\nerror\nerrtag\nlevels\ntype\n\n\n\n\nMax_SP\n166\n0.2828440\nOOB error rate\n14\nclassification\n\n\nsp_max_TD\n166\n0.2327334\nOOB error rate\n15\nclassification\n\n\ntotal_TD\n166\n0.2495366\nOOB error rate\n15\nclassification\n\n\n\n\n\n\nCode\nep$scaledImportance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBA\nSDI\nCC\nELEVFT\nP\nSLOPE\nPHYSCLCD\nG\nASPECT\nA\nf\n\n\n\n\nMax_SP\n1.695900\n1.600398\n0.2087437\n0.3894149\n0.4720483\n-0.3405607\n-0.5999133\n-0.5151475\n-0.5214716\n-0.8227028\n-1.566709\n\n\nsp_max_TD\n1.841399\n1.900765\n0.4871217\n-0.2517066\n-0.2906942\n-0.4332867\n-0.4589357\n-0.4696075\n-0.4883110\n-0.7352846\n-1.101460\n\n\ntotal_TD\n1.947821\n1.729480\n0.5146903\n-0.1381910\n-0.2019244\n-0.4598861\n-0.4173117\n-0.5432026\n-0.5208850\n-0.7176982\n-1.192892\n\n\n\n\n\n\n\n\nCode\ndp &lt;- yaiRFsummary(rf_fpag_bs)\ndp$forestAttributes[,\"error\"]\n\n\n[1] 0.11433355 0.09256712 0.09759015\n\n\nCode\nep$forestAttributes[,\"error\"]\n\n\n[1] 0.2828440 0.2327334 0.2495366\n\n\n\n\nCode\nyaiVarImp(rf_all_ref2, \n          ylim = c(-2,2))\nyaiVarImp(rf_f.p.a.g, \n          ylim = c(-2,2))\nyaiVarImp(rf_fpag_bs, \n          ylim = c(-2,2))\nyaiVarImp(rf_eco, \n          ylim = c(-2,2))\nyaiVarImp(rf_dia, \n          ylim = c(-2,2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntdia &lt;- yaiVarImp(rf_dia, \n          ylim = c(-2,2))\n\n\n\n\n\nCode\nt2 &lt;- yaiVarImp(rf_eco, \n          ylim = c(-2,2))\n\n\n\n\n\n\n\nCode\nggplot(stack(t2)) + \n  aes(x = values, y = ind, fill = ind) + \n  geom_boxplot() + \n  xlim(-2,2) + \n  labs(title = \"eco\") +\n  geom_vline(xintercept = 0)\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\nCode\nt3 &lt;- tdia |&gt; select(1:10)\nt4 &lt;- tdia |&gt; select(10:20)\n\n\nggplot(stack(t3)) + \n  aes(x = values, y = ind, fill = ind) + \n  geom_boxplot()+ \n  xlim(-2,2.2)+ \n  labs(title = \"dia1\")+\n  geom_vline(xintercept = 0)\n\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\nCode\nggplot(stack(t4)) + \n  aes(x = values, y = ind, fill = ind) + \n  geom_boxplot()+ \n  xlim(-2,2.2)+ \n  labs(title = \"dia2\")+\n  geom_vline(xintercept = 0)\n\n\n\n\n\n\n\nCode\ntdia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSDI\nBA\nECOREGION\nCC\nSLOPE\nASPECT\nPSME_dia\nPHYSCLCD\nELEVFT\nP\nG\nPICO_dia\nLAOC_dia\nABGR_dia\nPIEN_dia\nTHPL_dia\nA\nABLA_dia\nPIMO3_dia\nACGL_dia\n\n\n\n\nMax_SP\n1.972060\n2.315345\n1.388419\n1.627459\n1.610900\n3.227255\n1.161338\n0.9718119\n1.228096\n0.7128546\n0.4162654\n0.4830294\n0.2487614\n0.4523900\n-0.2539388\n0.2038247\n0.1872914\n0.3531449\n-0.0294391\n0.1827650\n\n\nsp_max_TD\n2.309091\n1.893425\n2.308549\n1.844762\n1.738563\n1.446530\n1.167131\n1.1300967\n1.003781\n0.6131874\n0.9665278\n0.8702458\n0.5257517\n0.5705896\n0.2687012\n0.0700969\n0.1912796\n0.1719856\n0.1560697\n0.0899448\n\n\ntotal_TD\n2.411675\n2.103923\n1.953972\n1.916024\n1.670769\n1.448258\n1.107379\n1.7302182\n1.001100\n0.8028473\n0.6375823\n0.6091290\n0.4594596\n0.4564329\n0.2114932\n0.4706413\n0.2308239\n0.1402233\n0.2316675\n-0.1211336\n\n\n\n\n\n\nI am not sure what to think about that. It didn’t perform better.\n\n\nCode\ntry &lt;- t3 |&gt; names()"
  }
]